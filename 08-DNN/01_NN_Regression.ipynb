{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div class=\"alert alert-info\" align=\"center\" font color=\"red\">  DNN Regression</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**1 Introduction**</font>\n",
    "\n",
    "This notebook is to apply DNN techniques to Regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <div class=\"alert alert-info\"> Setup </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**2.1. Import library**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mai\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <div class=\"alert alert-info\"> KC House </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color=red>**1. Data**</font>\n",
    "\n",
    "Dataset: https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "#### Feature Columns\n",
    "    \n",
    "* id - Unique ID for each home sold\n",
    "* date - Date of the home sale\n",
    "* price - Price of each home sold\n",
    "* bedrooms - Number of bedrooms\n",
    "* bathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower\n",
    "* sqft_living - Square footage of the apartments interior living space\n",
    "* sqft_lot - Square footage of the land space\n",
    "* floors - Number of floors\n",
    "* waterfront - A dummy variable for whether the apartment was overlooking the waterfront or not\n",
    "* view - An index from 0 to 4 of how good the view of the property was\n",
    "* condition - An index from 1 to 5 on the condition of the apartment,\n",
    "* grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design.\n",
    "* sqft_above - The square footage of the interior housing space that is above ground level\n",
    "* sqft_basement - The square footage of the interior housing space that is below ground level\n",
    "* yr_built - The year the house was initially built\n",
    "* yr_renovated - The year of the houseâ€™s last renovation\n",
    "* zipcode - What zipcode area the house is in\n",
    "* lat - Lattitude\n",
    "* long - Longitude\n",
    "* sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "* sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180      5650     1.0           0     0          3      7        1180              0      1955             0    98178  47.5112 -122.257           1340        5650\n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570      7242     2.0           0     0          3      7        2170            400      1951          1991    98125  47.7210 -122.319           1690        7639\n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770     10000     1.0           0     0          3      6         770              0      1933             0    98028  47.7379 -122.233           2720        8062\n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960      5000     1.0           0     0          5      7        1050            910      1965             0    98136  47.5208 -122.393           1360        5000\n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680      8080     1.0           0     0          3      8        1680              0      1987             0    98074  47.6168 -122.045           1800        7503"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('kc_house_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**2. Data Processing**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13832,), (3458,), (4323,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select features\n",
    "selected_features = df.drop(['id','zipcode','date','price'], axis=1).columns\n",
    "\n",
    "# Split data\n",
    "X = df[selected_features]\n",
    "y = df['price']\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=101)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_valid = X_valid.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_valid = y_valid.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train.shape, X_valid.shape, X_test.shape\n",
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**3. Model**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Define model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(99)\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "# Initialize\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Dense(30, kernel_initializer='uniform', activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(30, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(30, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Training model**\n",
    "    \n",
    "Below are some common definitions that are necessary to know and understand to correctly utilize Keras:\n",
    "\n",
    "* **Sample**: one element of a dataset.\n",
    "    * Example: one image is a sample in a convolutional network\n",
    "    * Example: one audio file is a sample for a speech recognition model\n",
    "* **Batch**: a set of N samples. The samples in a batch are processed independently, in parallel. If training, a batch results in only one update to the model.A batch generally approximates the distribution of the input data better than a single input. The larger the batch, the better the approximation; however, it is also true that the batch will take longer to process and will still result in only one update. For inference (evaluate/predict), it is recommended to pick a batch size that is as large as you can afford without going out of memory (since larger batches will usually result in faster evaluation/prediction).\n",
    "* **Epoch**: an arbitrary cutoff, generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation.\n",
    "* When using **validation_data or validation_split** with the fit method of Keras models, evaluation will be run at the end of every epoch.\n",
    "* Within Keras, **there is the ability to add callbacks specifically designed to be run at the end of an epoch**. Examples of these are learning rate changes and model checkpointing (saving).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 184759222272.0000 - val_loss: 104418959360.0000\n",
      "Epoch 2/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 92707782656.0000 - val_loss: 95198666752.0000\n",
      "Epoch 3/50\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 83185786880.0000 - val_loss: 84684718080.0000\n",
      "Epoch 4/50\n",
      "2767/2767 [==============================] - 11s 4ms/step - loss: 73980518400.0000 - val_loss: 74374643712.0000\n",
      "Epoch 5/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 65368010752.0000 - val_loss: 65255907328.0000\n",
      "Epoch 6/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 58161700864.0000 - val_loss: 59992018944.0000\n",
      "Epoch 7/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 56569270272.0000 - val_loss: 57767497728.0000\n",
      "Epoch 8/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 54282350592.0000 - val_loss: 55298457600.0000\n",
      "Epoch 9/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 52664569856.0000 - val_loss: 53742268416.0000\n",
      "Epoch 10/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 51888037888.0000 - val_loss: 52956553216.0000\n",
      "Epoch 11/50\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 50061815808.0000 - val_loss: 51620921344.0000\n",
      "Epoch 12/50\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 50802823168.0000 - val_loss: 50562486272.0000\n",
      "Epoch 13/50\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 49063100416.0000 - val_loss: 49967747072.0000\n",
      "Epoch 14/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 48932102144.0000 - val_loss: 48948285440.0000\n",
      "Epoch 15/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 47533998080.0000 - val_loss: 47977148416.0000\n",
      "Epoch 16/50\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 46699847680.0000 - val_loss: 47737966592.0000\n",
      "Epoch 17/50\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 45994889216.0000 - val_loss: 46901616640.0000\n",
      "Epoch 18/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 45853155328.0000 - val_loss: 46529515520.0000\n",
      "Epoch 19/50\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 45054087168.0000 - val_loss: 45821816832.0000\n",
      "Epoch 20/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 45230346240.0000 - val_loss: 45777321984.0000\n",
      "Epoch 21/50\n",
      "2767/2767 [==============================] - 10s 4ms/step - loss: 44879470592.0000 - val_loss: 45055512576.0000\n",
      "Epoch 22/50\n",
      "2767/2767 [==============================] - 11s 4ms/step - loss: 44386459648.0000 - val_loss: 44537118720.0000\n",
      "Epoch 23/50\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 44275249152.0000 - val_loss: 44442296320.0000\n",
      "Epoch 24/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 43654123520.0000 - val_loss: 43899285504.0000\n",
      "Epoch 25/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 43672584192.0000 - val_loss: 43225419776.0000\n",
      "Epoch 26/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 43711307776.0000 - val_loss: 42785951744.0000\n",
      "Epoch 27/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 42602840064.0000 - val_loss: 42382041088.0000\n",
      "Epoch 28/50\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 42959302656.0000 - val_loss: 42893733888.0000\n",
      "Epoch 29/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 43070181376.0000 - val_loss: 41827774464.0000\n",
      "Epoch 30/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 42994343936.0000 - val_loss: 41497804800.0000\n",
      "Epoch 31/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 42486325248.0000 - val_loss: 41345802240.0000\n",
      "Epoch 32/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 41974595584.0000 - val_loss: 40859049984.0000\n",
      "Epoch 33/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 40567984128.0000 - val_loss: 40291803136.0000\n",
      "Epoch 34/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 40392097792.0000 - val_loss: 39878541312.0000\n",
      "Epoch 35/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 41097121792.0000 - val_loss: 39284645888.0000\n",
      "Epoch 36/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 40528158720.0000 - val_loss: 39139024896.0000\n",
      "Epoch 37/50\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 40680079360.0000 - val_loss: 38872997888.0000\n",
      "Epoch 38/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 40153882624.0000 - val_loss: 38610333696.0000\n",
      "Epoch 39/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 39711440896.0000 - val_loss: 38807359488.0000\n",
      "Epoch 40/50\n",
      "2767/2767 [==============================] - 10s 4ms/step - loss: 39303688192.0000 - val_loss: 38037417984.0000\n",
      "Epoch 41/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 39124094976.0000 - val_loss: 37607419904.000037716082 - ETA\n",
      "Epoch 42/50\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 39590260736.0000 - val_loss: 37408862208.0000\n",
      "Epoch 43/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 40059625472.0000 - val_loss: 37251780608.0000\n",
      "Epoch 44/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 39620362240.0000 - val_loss: 37554704384.0000\n",
      "Epoch 45/50\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 39123791872.0000 - val_loss: 36938706944.0000\n",
      "Epoch 46/50\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 39150465024.0000 - val_loss: 37201838080.0000\n",
      "Epoch 47/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 38437543936.0000 - val_loss: 36977811456.0000\n",
      "Epoch 48/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 39454273536.0000 - val_loss: 36784087040.0000\n",
      "Epoch 49/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 38539993088.0000 - val_loss: 36320337920.0000\n",
      "Epoch 50/50\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 38518038528.0000 - val_loss: 36600606720.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x272b1874790>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train.values, \n",
    "          validation_data=(X_valid, y_valid.values), \n",
    "          batch_size=5, \n",
    "          epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Plot loss history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_hist = pd.DataFrame(model.history.history)\n",
    "loss_hist.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Performance Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 50, 'steps': 2767}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "['loss']\n"
     ]
    }
   ],
   "source": [
    "print(model.history.params)\n",
    "print(model.history.epoch)\n",
    "print(model.history.history.keys())\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33827072000.0, 32827187200.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "training_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  109556.68442867366\n",
      "RMSE:  181182.7312011364\n",
      "R-squared:  0.7615213743641792\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = model.predict(X_test)\n",
    "# MAE\n",
    "print('MAE: ', mean_absolute_error(y_test, y_test_pred))\n",
    "# RMSE\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "# R-square\n",
    "print('R-squared: ', explained_variance_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x272b62b3940>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "# Perfect prediction\n",
    "plt.plot(y_test, y_test, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = y_test.values - y_test_pred[:,0]\n",
    "sns.distplot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Prediction on a new object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[269293.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_house = df[selected_features].iloc[0]\n",
    "single_house = scaler.transform(single_house.values.reshape(1,len(single_house)))\n",
    "model.predict(single_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    469800.312500\n",
       "1    583413.500000\n",
       "2    490140.781250\n",
       "3    317482.718750\n",
       "4    133002.703125\n",
       "dtype: float32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(X_test),))\n",
    "test_predictions[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**4. Using checkpoint to save the best model**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Using checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                540       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,431\n",
      "Trainable params: 2,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(99)\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "# compile\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# using checkpoint to save the best model\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('training/kc_house.h5', save_best_only=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 185543933952.0000 - val_loss: 104456536064.0000\n",
      "Epoch 2/100\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 88374444032.0000 - val_loss: 95162736640.0000\n",
      "Epoch 3/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 79075082240.0000 - val_loss: 84753637376.0000\n",
      "Epoch 4/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 69416845312.0000 - val_loss: 74298253312.0000\n",
      "Epoch 5/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 60204171264.0000 - val_loss: 65077174272.0000\n",
      "Epoch 6/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 54019432448.0000 - val_loss: 59877986304.0000\n",
      "Epoch 7/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 50591698944.0000 - val_loss: 57032880128.0000\n",
      "Epoch 8/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 48742367232.0000 - val_loss: 55006658560.0000\n",
      "Epoch 9/100\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 47392854016.0000 - val_loss: 53508894720.0000\n",
      "Epoch 10/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 46291689472.0000 - val_loss: 52392857600.0000\n",
      "Epoch 11/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 45125926912.0000 - val_loss: 51071836160.0000\n",
      "Epoch 12/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 44015284224.0000 - val_loss: 49934909440.0000\n",
      "Epoch 13/100\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 43085922304.0000 - val_loss: 48743510016.0000\n",
      "Epoch 14/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 42119008256.0000 - val_loss: 48108666880.0000\n",
      "Epoch 15/100\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 41563807744.0000 - val_loss: 47048462336.0000\n",
      "Epoch 16/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 41054863360.0000 - val_loss: 46524940288.0000\n",
      "Epoch 17/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 40502464512.0000 - val_loss: 45655900160.0000\n",
      "Epoch 18/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 39905828864.0000 - val_loss: 44829724672.0000\n",
      "Epoch 19/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 39208071168.0000 - val_loss: 44092145664.0000\n",
      "Epoch 20/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 38678188032.0000 - val_loss: 43561295872.0000\n",
      "Epoch 21/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 38209064960.0000 - val_loss: 42689056768.0000\n",
      "Epoch 22/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 37679235072.0000 - val_loss: 42013650944.0000\n",
      "Epoch 23/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 37204451328.0000 - val_loss: 41502121984.0000\n",
      "Epoch 24/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 36820094976.0000 - val_loss: 40950312960.0000\n",
      "Epoch 25/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 36457369600.0000 - val_loss: 40217059328.0000\n",
      "Epoch 26/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 36239020032.0000 - val_loss: 39833554944.0000\n",
      "Epoch 27/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 35908362240.0000 - val_loss: 39388856320.0000\n",
      "Epoch 28/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 35629264896.0000 - val_loss: 39458795520.0000\n",
      "Epoch 29/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 35513511936.0000 - val_loss: 38876090368.0000\n",
      "Epoch 30/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 35256455168.0000 - val_loss: 38654566400.0000\n",
      "Epoch 31/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 35113771008.0000 - val_loss: 38358679552.0000\n",
      "Epoch 32/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 34918424576.0000 - val_loss: 37988671488.0000\n",
      "Epoch 33/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 34711396352.0000 - val_loss: 37627478016.0000\n",
      "Epoch 34/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 34622251008.0000 - val_loss: 37392637952.0000\n",
      "Epoch 35/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 34448138240.0000 - val_loss: 37080756224.0000\n",
      "Epoch 36/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 34242377728.0000 - val_loss: 36974354432.0000\n",
      "Epoch 37/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 34093115392.0000 - val_loss: 36777267200.0000\n",
      "Epoch 38/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 33958230016.0000 - val_loss: 36462501888.0000\n",
      "Epoch 39/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 33791363072.0000 - val_loss: 36511924224.0000\n",
      "Epoch 40/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 33670836224.0000 - val_loss: 36090949632.0000\n",
      "Epoch 41/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 33524496384.0000 - val_loss: 35914305536.0000\n",
      "Epoch 42/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 33338994688.0000 - val_loss: 35898503168.0000\n",
      "Epoch 43/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 33284694016.0000 - val_loss: 35498557440.0000\n",
      "Epoch 44/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 33172633600.0000 - val_loss: 35401154560.0000\n",
      "Epoch 45/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 32990359552.0000 - val_loss: 35054325760.0000\n",
      "Epoch 46/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32944599040.0000 - val_loss: 34952667136.0000\n",
      "Epoch 47/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32804360192.0000 - val_loss: 34993360896.0000\n",
      "Epoch 48/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 32683792384.0000 - val_loss: 34769154048.0000\n",
      "Epoch 49/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 32638509056.0000 - val_loss: 34452062208.0000\n",
      "Epoch 50/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 32530548736.0000 - val_loss: 34530758656.0000\n",
      "Epoch 51/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 32438601728.0000 - val_loss: 34412007424.0000\n",
      "Epoch 52/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32442886144.0000 - val_loss: 34124234752.0000\n",
      "Epoch 53/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 32294533120.0000 - val_loss: 34417897472.0000\n",
      "Epoch 54/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 32186021888.0000 - val_loss: 34087761920.0000\n",
      "Epoch 55/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 32110489600.0000 - val_loss: 33827889152.0000\n",
      "Epoch 56/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32021067776.0000 - val_loss: 33677000704.0000\n",
      "Epoch 57/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 31941330944.0000 - val_loss: 33661089792.0000\n",
      "Epoch 58/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31904991232.0000 - val_loss: 34095036416.0000\n",
      "Epoch 59/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 31830378496.0000 - val_loss: 33583245312.0000\n",
      "Epoch 60/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 31789936640.0000 - val_loss: 33339035648.0000\n",
      "Epoch 61/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 31705456640.0000 - val_loss: 33326424064.0000\n",
      "Epoch 62/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 31634178048.0000 - val_loss: 33215819776.0000\n",
      "Epoch 63/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 31620212736.0000 - val_loss: 33134080000.0000\n",
      "Epoch 64/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31534174208.0000 - val_loss: 33102077952.0000\n",
      "Epoch 65/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31448807424.0000 - val_loss: 33181466624.0000\n",
      "Epoch 66/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31322589184.0000 - val_loss: 32931715072.0000\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2767/2767 [==============================] - 9s 3ms/step - loss: 31315056640.0000 - val_loss: 32922826752.0000\n",
      "Epoch 68/100\n",
      "2767/2767 [==============================] - 9s 3ms/step - loss: 31328894976.0000 - val_loss: 32811857920.0000\n",
      "Epoch 69/100\n",
      "2767/2767 [==============================] - 10s 4ms/step - loss: 31106355200.0000 - val_loss: 33354758144.0000\n",
      "Epoch 70/100\n",
      "2767/2767 [==============================] - 13s 5ms/step - loss: 31237888000.0000 - val_loss: 32721727488.0000\n",
      "Epoch 71/100\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 31161513984.0000 - val_loss: 32913584128.0000\n",
      "Epoch 72/100\n",
      "2767/2767 [==============================] - 13s 5ms/step - loss: 31027474432.0000 - val_loss: 32636426240.0000\n",
      "Epoch 73/100\n",
      "2767/2767 [==============================] - 14s 5ms/step - loss: 31061237760.0000 - val_loss: 32990427136.0000\n",
      "Epoch 74/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 30955388928.0000 - val_loss: 32647761920.0000\n",
      "Epoch 75/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 30874832896.0000 - val_loss: 32428843008.0000\n",
      "Epoch 76/100\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 30885675008.0000 - val_loss: 32461635584.0000\n",
      "Epoch 77/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30791743488.0000 - val_loss: 32555816960.0000\n",
      "Epoch 78/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30732015616.0000 - val_loss: 32456914944.0000\n",
      "Epoch 79/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 30702807040.0000 - val_loss: 32289372160.0000\n",
      "Epoch 80/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30615758848.0000 - val_loss: 32220131328.0000\n",
      "Epoch 81/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30585098240.0000 - val_loss: 32210571264.0000\n",
      "Epoch 82/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30504519680.0000 - val_loss: 32404088832.0000\n",
      "Epoch 83/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30517864448.0000 - val_loss: 32167421952.0000\n",
      "Epoch 84/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30461700096.0000 - val_loss: 32158400512.0000\n",
      "Epoch 85/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30369406976.0000 - val_loss: 32201299968.0000\n",
      "Epoch 86/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30385160192.0000 - val_loss: 32048785408.0000\n",
      "Epoch 87/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30289408000.0000 - val_loss: 32092485632.0000\n",
      "Epoch 88/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 30328832000.0000 - val_loss: 32132173824.0000\n",
      "Epoch 89/100\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 30268876800.0000 - val_loss: 32058667008.0000\n",
      "Epoch 90/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30198118400.0000 - val_loss: 31886032896.0000\n",
      "Epoch 91/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30209064960.0000 - val_loss: 31843749888.0000\n",
      "Epoch 92/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30122715136.0000 - val_loss: 31802294272.0000\n",
      "Epoch 93/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30055321600.0000 - val_loss: 32517928960.0000\n",
      "Epoch 94/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30072010752.0000 - val_loss: 31934926848.0000\n",
      "Epoch 95/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30042761216.0000 - val_loss: 31856146432.0000\n",
      "Epoch 96/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 29986060288.0000 - val_loss: 31695581184.0000\n",
      "Epoch 97/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 29949726720.0000 - val_loss: 31690057728.0000\n",
      "Epoch 98/100\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 29932015616.0000 - val_loss: 31639853056.0000\n",
      "Epoch 99/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29881255936.0000 - val_loss: 31599816704.0000\n",
      "Epoch 100/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29841864704.0000 - val_loss: 31554889728.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train.values,\n",
    "                    validation_data = (X_valid, y_valid.values),\n",
    "                    batch_size=5,\n",
    "                    epochs=100,\n",
    "                    callbacks=[checkpoint_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  103425.43875780707\n",
      "RMSE:  168600.27782831254\n",
      "R-squared:  0.7916459835323286\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "# MAE\n",
    "print('MAE: ', mean_absolute_error(y_test, y_test_pred))\n",
    "# RMSE\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "# R-square\n",
    "print('R-squared: ', explained_variance_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                540       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,431\n",
      "Trainable params: 2,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(99)\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs['val_loss']/logs['loss']))\n",
    "        \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(30),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# using checkpoint to save the best model\n",
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('training/kc_house.h5', save_best_only=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 164956831744.0000\n",
      "val/train: 0.61\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 164769202176.0000 - val_loss: 101328584704.0000\n",
      "Epoch 2/100\n",
      "2761/2767 [============================>.] - ETA: 0s - loss: 84152311808.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 84057309184.0000 - val_loss: 88905342976.0000\n",
      "Epoch 3/100\n",
      "2765/2767 [============================>.] - ETA: 0s - loss: 71520231424.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 71556120576.0000 - val_loss: 74888880128.0000\n",
      "Epoch 4/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 59631230976.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 59918680064.0000 - val_loss: 63816110080.0000\n",
      "Epoch 5/100\n",
      "2760/2767 [============================>.] - ETA: 0s - loss: 52529950720.0000\n",
      "val/train: 1.10\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 52487790592.0000 - val_loss: 57781596160.0000\n",
      "Epoch 6/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 48852180992.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 49248124928.0000 - val_loss: 55221682176.0000\n",
      "Epoch 7/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 47261782016.0000\n",
      "val/train: 1.13\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 47144325120.0000 - val_loss: 53193940992.0000\n",
      "Epoch 8/100\n",
      "2742/2767 [============================>.] - ETA: 0s - loss: 45602504704.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 45346430976.0000 - val_loss: 50974515200.0000\n",
      "Epoch 9/100\n",
      "2760/2767 [============================>.] - ETA: 0s - loss: 43952619520.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 43881197568.0000 - val_loss: 49312534528.0000\n",
      "Epoch 10/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 42829320192.0000\n",
      "val/train: 1.13\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 42825256960.0000 - val_loss: 48269303808.0000\n",
      "Epoch 11/100\n",
      "2758/2767 [============================>.] - ETA: 0s - loss: 41925943296.0000\n",
      "val/train: 1.13\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 41863000064.0000 - val_loss: 47182299136.0000\n",
      "Epoch 12/100\n",
      "2743/2767 [============================>.] - ETA: 0s - loss: 40982638592.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 40979685376.0000 - val_loss: 46054928384.0000\n",
      "Epoch 13/100\n",
      "2743/2767 [============================>.] - ETA: 0s - loss: 40242298880.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 40082935808.0000 - val_loss: 44865777664.0000\n",
      "Epoch 14/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 39126740992.0000\n",
      "val/train: 1.13\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 39098691584.0000 - val_loss: 44367011840.0000\n",
      "Epoch 15/100\n",
      "2753/2767 [============================>.] - ETA: 0s - loss: 38527377408.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 38490947584.0000 - val_loss: 42998095872.0000\n",
      "Epoch 16/100\n",
      "2765/2767 [============================>.] - ETA: 0s - loss: 37916962816.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 37901590528.0000 - val_loss: 42308325376.0000\n",
      "Epoch 17/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 37408292864.0000\n",
      "val/train: 1.11\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 37318111232.0000 - val_loss: 41290166272.0000\n",
      "Epoch 18/100\n",
      "2754/2767 [============================>.] - ETA: 0s - loss: 36889202688.0000\n",
      "val/train: 1.10\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 36841656320.0000 - val_loss: 40597856256.0000\n",
      "Epoch 19/100\n",
      "2745/2767 [============================>.] - ETA: 0s - loss: 35983331328.0000\n",
      "val/train: 1.10\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 36366688256.0000 - val_loss: 40057954304.0000\n",
      "Epoch 20/100\n",
      "2753/2767 [============================>.] - ETA: 0s - loss: 36056367104.0000\n",
      "val/train: 1.11\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 36007387136.0000 - val_loss: 39868047360.0000\n",
      "Epoch 21/100\n",
      "2759/2767 [============================>.] - ETA: 0s - loss: 35681701888.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 35748442112.0000 - val_loss: 39066124288.0000\n",
      "Epoch 22/100\n",
      "2760/2767 [============================>.] - ETA: 0s - loss: 35423641600.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 35388338176.0000 - val_loss: 38582710272.0000\n",
      "Epoch 23/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 35074093056.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 35096215552.0000 - val_loss: 38234771456.0000\n",
      "Epoch 24/100\n",
      "2751/2767 [============================>.] - ETA: 0s - loss: 34889388032.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 34836541440.0000 - val_loss: 37869551616.0000\n",
      "Epoch 25/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 34632609792.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 34604081152.0000 - val_loss: 37290434560.0000\n",
      "Epoch 26/100\n",
      "2744/2767 [============================>.] - ETA: 0s - loss: 34487279616.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 34498994176.0000 - val_loss: 37034037248.0000\n",
      "Epoch 27/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 34193745920.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 34229772288.0000 - val_loss: 36690493440.0000\n",
      "Epoch 28/100\n",
      "2753/2767 [============================>.] - ETA: 0s - loss: 34018017280.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 33966772224.0000 - val_loss: 36902223872.0000\n",
      "Epoch 29/100\n",
      "2746/2767 [============================>.] - ETA: 0s - loss: 33992906752.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 33906688000.0000 - val_loss: 36351107072.0000\n",
      "Epoch 30/100\n",
      "2744/2767 [============================>.] - ETA: 0s - loss: 33714724864.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 33642352640.0000 - val_loss: 36191789056.0000\n",
      "Epoch 31/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 33522210816.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33526732800.0000 - val_loss: 35941994496.0000\n",
      "Epoch 32/100\n",
      "2750/2767 [============================>.] - ETA: 0s - loss: 33366497280.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 33337346048.0000 - val_loss: 35484749824.0000\n",
      "Epoch 33/100\n",
      "2740/2767 [============================>.] - ETA: 0s - loss: 33273073664.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 33135575040.0000 - val_loss: 35218513920.0000\n",
      "Epoch 34/100\n",
      "2765/2767 [============================>.] - ETA: 0s - loss: 33080557568.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 33073108992.0000 - val_loss: 34959372288.0000\n",
      "Epoch 35/100\n",
      "2748/2767 [============================>.] - ETA: 0s - loss: 33001846784.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32920938496.0000 - val_loss: 34707808256.0000\n",
      "Epoch 36/100\n",
      "2752/2767 [============================>.] - ETA: 0s - loss: 32756707328.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 32713226240.0000 - val_loss: 34675200000.0000\n",
      "Epoch 37/100\n",
      "2751/2767 [============================>.] - ETA: 0s - loss: 32725288960.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32617936896.0000 - val_loss: 34530537472.0000\n",
      "Epoch 38/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 32596717568.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32514033664.0000 - val_loss: 34321502208.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "2764/2767 [============================>.] - ETA: 0s - loss: 32325429248.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32372404224.0000 - val_loss: 34413334528.0000\n",
      "Epoch 40/100\n",
      "2746/2767 [============================>.] - ETA: 0s - loss: 32280031232.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 32278044672.0000 - val_loss: 34124527616.0000\n",
      "Epoch 41/100\n",
      "2764/2767 [============================>.] - ETA: 0s - loss: 32168560640.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 32151627776.0000 - val_loss: 33963270144.0000\n",
      "Epoch 42/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 31999260672.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 32007122944.0000 - val_loss: 33851412480.0000\n",
      "Epoch 43/100\n",
      "2762/2767 [============================>.] - ETA: 0s - loss: 31960258560.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31963539456.0000 - val_loss: 33653645312.0000\n",
      "Epoch 44/100\n",
      "2752/2767 [============================>.] - ETA: 0s - loss: 31910625280.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 31875616768.0000 - val_loss: 33604603904.0000\n",
      "Epoch 45/100\n",
      "2758/2767 [============================>.] - ETA: 0s - loss: 31675834368.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 31734831104.0000 - val_loss: 33361977344.0000\n",
      "Epoch 46/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 31753302016.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 31747946496.0000 - val_loss: 33296427008.0000\n",
      "Epoch 47/100\n",
      "2758/2767 [============================>.] - ETA: 0s - loss: 31568783360.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31630434304.0000 - val_loss: 33360918528.0000\n",
      "Epoch 48/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 31651952640.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31521839104.0000 - val_loss: 33213239296.0000\n",
      "Epoch 49/100\n",
      "2754/2767 [============================>.] - ETA: 0s - loss: 31491977216.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31509567488.0000 - val_loss: 32990484480.0000\n",
      "Epoch 50/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 31427887104.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31436197888.0000 - val_loss: 33156198400.0000\n",
      "Epoch 51/100\n",
      "2756/2767 [============================>.] - ETA: 0s - loss: 31259764736.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 31371722752.0000 - val_loss: 33246498816.0000\n",
      "Epoch 52/100\n",
      "2760/2767 [============================>.] - ETA: 0s - loss: 31438778368.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31412514816.0000 - val_loss: 32828241920.0000\n",
      "Epoch 53/100\n",
      "2753/2767 [============================>.] - ETA: 0s - loss: 31344359424.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31277682688.0000 - val_loss: 33090834432.0000\n",
      "Epoch 54/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 31059392512.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 31167967232.0000 - val_loss: 33025542144.0000\n",
      "Epoch 55/100\n",
      "2754/2767 [============================>.] - ETA: 0s - loss: 31181228032.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31112214528.0000 - val_loss: 32608358400.0000\n",
      "Epoch 56/100\n",
      "2742/2767 [============================>.] - ETA: 0s - loss: 30866790400.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31033401344.0000 - val_loss: 32529717248.0000\n",
      "Epoch 57/100\n",
      "2754/2767 [============================>.] - ETA: 0s - loss: 31020068864.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30954432512.0000 - val_loss: 32527271936.0000\n",
      "Epoch 58/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 31003666432.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30920169472.0000 - val_loss: 33033261056.0000\n",
      "Epoch 59/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 30752974848.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30843643904.0000 - val_loss: 32473323520.0000\n",
      "Epoch 60/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 30915139584.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 30821629952.0000 - val_loss: 32284880896.0000\n",
      "Epoch 61/100\n",
      "2759/2767 [============================>.] - ETA: 0s - loss: 30750484480.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30734940160.0000 - val_loss: 32324597760.0000\n",
      "Epoch 62/100\n",
      "2744/2767 [============================>.] - ETA: 0s - loss: 30771275776.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30652590080.0000 - val_loss: 32198883328.0000\n",
      "Epoch 63/100\n",
      "2742/2767 [============================>.] - ETA: 0s - loss: 30711586816.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30654668800.0000 - val_loss: 32147503104.0000\n",
      "Epoch 64/100\n",
      "2746/2767 [============================>.] - ETA: 0s - loss: 30571008000.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30563885056.0000 - val_loss: 32131063808.0000\n",
      "Epoch 65/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 30519697408.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30469328896.0000 - val_loss: 32375961600.0000\n",
      "Epoch 66/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 30389964800.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30334730240.0000 - val_loss: 31983134720.0000\n",
      "Epoch 67/100\n",
      "2766/2767 [============================>.] - ETA: 0s - loss: 30340876288.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30338623488.0000 - val_loss: 31999686656.0000\n",
      "Epoch 68/100\n",
      "2756/2767 [============================>.] - ETA: 0s - loss: 30314637312.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30347235328.0000 - val_loss: 31911280640.0000\n",
      "Epoch 69/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 30179235840.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30107277312.0000 - val_loss: 32369532928.0000\n",
      "Epoch 70/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 30166460416.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30253496320.0000 - val_loss: 31894384640.0000\n",
      "Epoch 71/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 30189330432.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 30185377792.0000 - val_loss: 32052254720.0000\n",
      "Epoch 72/100\n",
      "2767/2767 [==============================] - ETA: 0s - loss: 30029385728.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30029385728.0000 - val_loss: 31748857856.0000\n",
      "Epoch 73/100\n",
      "2750/2767 [============================>.] - ETA: 0s - loss: 30073778176.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30067877888.0000 - val_loss: 32392364032.0000\n",
      "Epoch 74/100\n",
      "2746/2767 [============================>.] - ETA: 0s - loss: 30042562560.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29957253120.0000 - val_loss: 31734482944.0000\n",
      "Epoch 75/100\n",
      "2740/2767 [============================>.] - ETA: 0s - loss: 29932777472.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29870923776.0000 - val_loss: 31613073408.0000\n",
      "Epoch 76/100\n",
      "2740/2767 [============================>.] - ETA: 0s - loss: 29980594176.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29887883264.0000 - val_loss: 31646791680.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100\n",
      "2759/2767 [============================>.] - ETA: 0s - loss: 29794217984.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29791559680.0000 - val_loss: 31756222464.0000\n",
      "Epoch 78/100\n",
      "2750/2767 [============================>.] - ETA: 0s - loss: 29769158656.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29731201024.0000 - val_loss: 31605450752.0000\n",
      "Epoch 79/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 29760958464.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 29700681728.0000 - val_loss: 31534155776.0000\n",
      "Epoch 80/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 29628391424.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29606473728.0000 - val_loss: 31431262208.0000\n",
      "Epoch 81/100\n",
      "2766/2767 [============================>.] - ETA: 0s - loss: 29579638784.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 29575600128.0000 - val_loss: 31400099840.0000\n",
      "Epoch 82/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 29535758336.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 29469014016.0000 - val_loss: 31560896512.0000\n",
      "Epoch 83/100\n",
      "2756/2767 [============================>.] - ETA: 0s - loss: 29251125248.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29476677632.0000 - val_loss: 31371237376.0000\n",
      "Epoch 84/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 29267838976.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 29407346688.0000 - val_loss: 31396745216.0000\n",
      "Epoch 85/100\n",
      "2752/2767 [============================>.] - ETA: 0s - loss: 29343145984.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29299056640.0000 - val_loss: 31366678528.0000\n",
      "Epoch 86/100\n",
      "2721/2767 [============================>.] - ETA: 0s - loss: 29255706624.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29293903872.0000 - val_loss: 31243063296.0000\n",
      "Epoch 87/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 29217658880.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29203421184.0000 - val_loss: 31376259072.0000\n",
      "Epoch 88/100\n",
      "2745/2767 [============================>.] - ETA: 0s - loss: 29240115200.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29222742016.0000 - val_loss: 31614062592.0000\n",
      "Epoch 89/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 29147852800.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29164351488.0000 - val_loss: 31349880832.0000\n",
      "Epoch 90/100\n",
      "2761/2767 [============================>.] - ETA: 0s - loss: 29109225472.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29071370240.0000 - val_loss: 31148417024.0000\n",
      "Epoch 91/100\n",
      "2767/2767 [==============================] - ETA: 0s - loss: 29070098432.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29070098432.0000 - val_loss: 31070015488.0000\n",
      "Epoch 92/100\n",
      "2739/2767 [============================>.] - ETA: 0s - loss: 28918329344.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 28952778752.0000 - val_loss: 31076218880.0000\n",
      "Epoch 93/100\n",
      "2767/2767 [==============================] - ETA: 0s - loss: 28870662144.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 28870662144.0000 - val_loss: 31595964416.0000\n",
      "Epoch 94/100\n",
      "2744/2767 [============================>.] - ETA: 0s - loss: 28687910912.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 28856700928.0000 - val_loss: 31277889536.0000\n",
      "Epoch 95/100\n",
      "2764/2767 [============================>.] - ETA: 0s - loss: 28762521600.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 28828157952.0000 - val_loss: 31300184064.0000\n",
      "Epoch 96/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 28818296832.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 28769892352.0000 - val_loss: 30923462656.0000\n",
      "Epoch 97/100\n",
      "2766/2767 [============================>.] - ETA: 0s - loss: 28707407872.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 28706613248.0000 - val_loss: 30942670848.0000\n",
      "Epoch 98/100\n",
      "2767/2767 [==============================] - ETA: 0s - loss: 28677879808.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 28677879808.0000 - val_loss: 30919550976.0000\n",
      "Epoch 99/100\n",
      "2740/2767 [============================>.] - ETA: 0s - loss: 28674533376.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 28614070272.0000 - val_loss: 30892810240.0000\n",
      "Epoch 100/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 28546791424.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 28529229824.0000 - val_loss: 30857459712.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train.values, \n",
    "                    validation_data=(X_valid, y_valid.values), \n",
    "                    batch_size=5, \n",
    "                    epochs=100,\n",
    "                    callbacks=[val_train_ratio_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 100, 'steps': 2767}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x272b767f700>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"training/my_keras_weights.ckpt\")\n",
    "model.load_weights(\"training/my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "VGOwsZjQcBVa",
    "outputId": "4bcec95b-b873-41c6-a514-1e191464f1c9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 28283637760.00, Test score: 27232856064.00\n",
      "RMSE: 165023.803\n",
      "MSE: 27232855538.651\n",
      "MAE: 101594.192\n",
      "r2: 0.800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "\n",
    "model = keras.models.load_model('training/kc_house.h5')  # roll back to the best model\n",
    "\n",
    "# Train score, test score\n",
    "training_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "test_predictions = model.predict(X_test)\n",
    "print(\"Train score: %.2f\" % training_score + \", Test score: %.2f\" % test_score)\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, test_predictions)\n",
    "print(\"MAE: %.3f\"  % mae)\n",
    "      \n",
    "# r2 - coefficient of determination\n",
    "r2 = explained_variance_score(y_test, test_predictions)\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jOKFUecc1wf",
    "outputId": "8fd4aa33-c456-46dc-f709-38a854790f7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[516705.38],\n",
       "       [602669.7 ],\n",
       "       [486389.  ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "woAMc1NrtPhj",
    "outputId": "92c0d3a7-30c9-4794-c69e-e84feca6c664"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>Model Prediction</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>349950.0</td>\n",
       "      <td>516705.375000</td>\n",
       "      <td>-166755.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450000.0</td>\n",
       "      <td>602669.687500</td>\n",
       "      <td>-152669.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635000.0</td>\n",
       "      <td>486389.000000</td>\n",
       "      <td>148611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355500.0</td>\n",
       "      <td>314836.906250</td>\n",
       "      <td>40663.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246950.0</td>\n",
       "      <td>237527.390625</td>\n",
       "      <td>9422.609375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  Model Prediction          Error\n",
       "0  349950.0     516705.375000 -166755.375000\n",
       "1  450000.0     602669.687500 -152669.687500\n",
       "2  635000.0     486389.000000  148611.000000\n",
       "3  355500.0     314836.906250   40663.093750\n",
       "4  246950.0     237527.390625    9422.609375"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate error\n",
    "pred_df = pd.DataFrame(y_test)\n",
    "pred_df['Model Prediction'] =pd.Series(test_predictions.reshape(len(test_predictions),))\n",
    "pred_df['Error'] = pred_df['price'] - pred_df['Model Prediction']\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Saving and Restoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmfeUJa5dF5f",
    "outputId": "4be48a96-245d-4458-c228-e63d5bc82677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[516705.38],\n",
       "       [602669.7 ],\n",
       "       [486389.  ]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"training/kc_house.h5\")\n",
    "model = keras.models.load_model(\"training/kc_house.h5\")\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjsuBbExfmqF",
    "outputId": "652c74b0-fbab-4d87-e286-7f9d80697917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x272b76d5d00>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"training/kc_house_weights.ckpt\")\n",
    "model.load_weights(\"training/kc_house_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**5. Tuning Model**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=3, \n",
    "                 n_neurons=30, \n",
    "                 learning_rate=3e-3, \n",
    "                 dropout_rate=0.2, \n",
    "                 activation='relu',\n",
    "                 init='uniform',\n",
    "                 input_shape=X_train.shape[1:]):\n",
    "    # clear old session\n",
    "    keras.backend.clear_session()\n",
    "    tf.keras.backend.clear_session()\n",
    "    np.random.seed(99)\n",
    "    tf.random.set_seed(99)\n",
    "   \n",
    "    # build model\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, kernel_initializer=init, activation=activation))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    \n",
    "    # compile the model\n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss='mse', optimizer=adam)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV] n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738/738 [==============================] - 2s 3ms/step - loss: 175423602688.0000 - val_loss: 95607939072.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 93743775744.0000 - val_loss: 69911838720.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 79846572032.0000 - val_loss: 59965976576.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 75461664768.0000 - val_loss: 54542659584.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 71453409280.0000 - val_loss: 54712238080.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 73569189888.0000 - val_loss: 51322052608.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 68245082112.0000 - val_loss: 50379952128.0000\n",
      "Epoch 8/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 68896407552.0000 - val_loss: 50430402560.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 67919396864.0000 - val_loss: 49399861248.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 66590879744.0000 - val_loss: 47964676096.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 1s 2ms/step - loss: 66078158848.0000 - val_loss: 49175965696.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 62242836480.0000 - val_loss: 42780794880.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 63030161408.0000 - val_loss: 43549413376.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 61892165632.0000 - val_loss: 44179714048.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 1s 2ms/step - loss: 61432565760.0000 - val_loss: 42357481472.0000\n",
      "Epoch 16/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 60868382720.0000 - val_loss: 41433653248.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 1s 2ms/step - loss: 64563560448.0000 - val_loss: 42148540416.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 1s 2ms/step - loss: 63433809920.0000 - val_loss: 39834636288.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 61618618368.0000 - val_loss: 39329140736.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59203305472.0000 - val_loss: 39751106560.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59654582272.0000 - val_loss: 37006143488.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58070892544.0000 - val_loss: 38280515584.0000\n",
      "Epoch 23/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59832860672.0000 - val_loss: 36445917184.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59163574272.0000 - val_loss: 38871449600.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59084398592.0000 - val_loss: 36150075392.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 57460355072.0000 - val_loss: 38625533952.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 58979049472.0000 - val_loss: 37445984256.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 59552374784.0000 - val_loss: 37302870016.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 55190171648.0000 - val_loss: 35093979136.0000\n",
      "Epoch 30/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56839147520.0000 - val_loss: 38044708864.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 54467715072.0000 - val_loss: 39509585920.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 58179514368.0000 - val_loss: 35500122112.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57224339456.0000 - val_loss: 38235123712.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 55663767552.0000 - val_loss: 35216867328.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 53328670720.0000 - val_loss: 35463778304.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53170266112.0000 - val_loss: 39736123392.0000\n",
      "Epoch 37/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 54059114496.0000 - val_loss: 36095819776.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 1s 2ms/step - loss: 55504191488.0000 - val_loss: 35783483392.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53383753728.0000 - val_loss: 34345369600.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55601795072.0000 - val_loss: 36578664448.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52070981632.0000 - val_loss: 33158561792.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 52338946048.0000 - val_loss: 37878730752.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52803678208.0000 - val_loss: 34228477952.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 52432924672.0000 - val_loss: 36375040000.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53941026816.0000 - val_loss: 32712529920.0000\n",
      "Epoch 46/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 53815123968.0000 - val_loss: 33754466304.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 51754582016.0000 - val_loss: 36130701312.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 51122786304.0000 - val_loss: 33487417344.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 52060733440.0000 - val_loss: 35779153920.0000\n",
      "Epoch 50/50\n",
      "738/738 [==============================] - 1s 2ms/step - loss: 50968784896.0000 - val_loss: 33324560384.0000\n",
      "185/185 [==============================] - 0s 849us/step - loss: 30550540288.0000\n",
      "[CV]  n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 1.5min\n",
      "[CV] n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.5min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738/738 [==============================] - 2s 2ms/step - loss: 172026970112.0000 - val_loss: 95652257792.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 91165384704.0000 - val_loss: 68518617088.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 77477478400.0000 - val_loss: 57985265664.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 74506952704.0000 - val_loss: 54148407296.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 71484571648.0000 - val_loss: 54595059712.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 73693429760.0000 - val_loss: 51719589888.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 67557466112.0000 - val_loss: 51785424896.0000\n",
      "Epoch 8/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 68614631424.0000 - val_loss: 53494714368.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 67743100928.0000 - val_loss: 50988044288.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 65567571968.0000 - val_loss: 49553268736.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 67185131520.0000 - val_loss: 47811117056.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 1s 2ms/step - loss: 63520034816.0000 - val_loss: 43163394048.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 1s 2ms/step - loss: 62268784640.0000 - val_loss: 43739500544.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 60211580928.0000 - val_loss: 42801471488.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 62631735296.0000 - val_loss: 42481942528.0000\n",
      "Epoch 16/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 61450170368.0000 - val_loss: 41849872384.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 63700590592.0000 - val_loss: 42028208128.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 62554533888.0000 - val_loss: 38204256256.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59918012416.0000 - val_loss: 39154335744.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 59637411840.0000 - val_loss: 40783147008.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 59983011840.0000 - val_loss: 37175054336.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56775565312.0000 - val_loss: 37388427264.0000\n",
      "Epoch 23/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 60310859776.0000 - val_loss: 36158238720.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - ETA: 0s - loss: 58476912640.000 - 2s 2ms/step - loss: 58360942592.0000 - val_loss: 40652201984.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 58826375168.0000 - val_loss: 36330045440.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58566225920.0000 - val_loss: 36276129792.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57530150912.0000 - val_loss: 36588744704.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 57764900864.0000 - val_loss: 36019732480.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 55984832512.0000 - val_loss: 35144400896.0000\n",
      "Epoch 30/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 56747077632.0000 - val_loss: 37998194688.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 55495696384.0000 - val_loss: 38873210880.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57355812864.0000 - val_loss: 34291361792.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 56595169280.0000 - val_loss: 39408340992.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 53453795328.0000 - val_loss: 36263735296.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 52416475136.0000 - val_loss: 35609751552.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 54123933696.0000 - val_loss: 38606249984.0000\n",
      "Epoch 37/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 53657821184.0000 - val_loss: 35843543040.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56821661696.0000 - val_loss: 35578380288.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 53958516736.0000 - val_loss: 33921009664.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56398323712.0000 - val_loss: 35368148992.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52924628992.0000 - val_loss: 35171340288.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53857267712.0000 - val_loss: 35979694080.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52880674816.0000 - val_loss: 33387829248.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52566581248.0000 - val_loss: 35906785280.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54954815488.0000 - val_loss: 32500819968.0000\n",
      "Epoch 46/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53347561472.0000 - val_loss: 32819023872.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53011636224.0000 - val_loss: 36399087616.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49047695360.0000 - val_loss: 32891277312.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51566862336.0000 - val_loss: 37001199616.0000\n",
      "Epoch 50/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50621308928.0000 - val_loss: 33350490112.0000\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 32565045248.0000\n",
      "[CV]  n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 1.5min\n",
      "[CV] n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 164669046784.0000 - val_loss: 90635919360.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 83553583104.0000 - val_loss: 63469543424.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 72366645248.0000 - val_loss: 60114362368.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 69319655424.0000 - val_loss: 51281637376.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 68219793408.0000 - val_loss: 50576715776.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 62106841088.0000 - val_loss: 47845658624.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 62205349888.0000 - val_loss: 46670262272.0000\n",
      "Epoch 8/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 63199731712.0000 - val_loss: 54005989376.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 61052166144.0000 - val_loss: 44629291008.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 61979537408.0000 - val_loss: 46198853632.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 59990392832.0000 - val_loss: 44562173952.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58395009024.0000 - val_loss: 43959410688.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 60864647168.0000 - val_loss: 42609831936.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 60357648384.0000 - val_loss: 41177333760.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58177200128.0000 - val_loss: 41708449792.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55008104448.0000 - val_loss: 39525453824.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58183725056.0000 - val_loss: 39175909376.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56734760960.0000 - val_loss: 40715427840.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56758386688.0000 - val_loss: 38105600000.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57074106368.0000 - val_loss: 37060919296.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57421094912.0000 - val_loss: 39925424128.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55160188928.0000 - val_loss: 36455809024.0000\n",
      "Epoch 23/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58801217536.0000 - val_loss: 37807677440.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52875218944.0000 - val_loss: 36922957824.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54983741440.0000 - val_loss: 39184416768.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54602964992.0000 - val_loss: 37332598784.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54345560064.0000 - val_loss: 36835409920.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55478104064.0000 - val_loss: 38612070400.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54681067520.0000 - val_loss: 38562078720.0000\n",
      "Epoch 30/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56455516160.0000 - val_loss: 34616872960.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53851250688.0000 - val_loss: 36448157696.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54284460032.0000 - val_loss: 34400440320.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52936400896.0000 - val_loss: 35568140288.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51312205824.0000 - val_loss: 34330748928.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52530302976.0000 - val_loss: 33425272832.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54882402304.0000 - val_loss: 35067080704.0000\n",
      "Epoch 37/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54788354048.0000 - val_loss: 38749237248.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50844160000.0000 - val_loss: 34862215168.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51429154816.0000 - val_loss: 32606320640.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51292262400.0000 - val_loss: 32310456320.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53762830336.0000 - val_loss: 34917457920.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51005775872.0000 - val_loss: 34222321664.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51258277888.0000 - val_loss: 38146265088.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53443878912.0000 - val_loss: 34866593792.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51136786432.0000 - val_loss: 33660934144.0000\n",
      "Epoch 46/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50805276672.0000 - val_loss: 37256503296.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50596528128.0000 - val_loss: 35986018304.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51133902848.0000 - val_loss: 33985167360.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51709054976.0000 - val_loss: 34806665216.0000\n",
      "Epoch 50/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49900007424.0000 - val_loss: 32328376320.0000\n",
      "Epoch 00050: early stopping\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 33328666624.0000\n",
      "[CV]  n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 1.9min\n",
      "[CV] n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 171319590912.0000 - val_loss: 92666593280.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 90269073408.0000 - val_loss: 67189669888.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 77264265216.0000 - val_loss: 58356150272.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 71669309440.0000 - val_loss: 53162397696.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 72607178752.0000 - val_loss: 53215068160.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 68108857344.0000 - val_loss: 51038535680.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 67329777664.0000 - val_loss: 47783620608.0000\n",
      "Epoch 8/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 64738951168.0000 - val_loss: 50959073280.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 64437030912.0000 - val_loss: 46433607680.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 65376010240.0000 - val_loss: 47096279040.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 62674583552.0000 - val_loss: 47777411072.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 62516170752.0000 - val_loss: 46481838080.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 63042101248.0000 - val_loss: 40962605056.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 64685035520.0000 - val_loss: 40536580096.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 60502904832.0000 - val_loss: 40612876288.0000\n",
      "Epoch 16/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58771828736.0000 - val_loss: 40243142656.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 63097004032.0000 - val_loss: 38318026752.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 60415643648.0000 - val_loss: 41051820032.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58951467008.0000 - val_loss: 38228090880.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59704037376.0000 - val_loss: 36058574848.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58655784960.0000 - val_loss: 38044131328.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56892518400.0000 - val_loss: 35188281344.0000\n",
      "Epoch 23/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 60331470848.0000 - val_loss: 43521458176.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54650789888.0000 - val_loss: 35722739712.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58477019136.0000 - val_loss: 40332996608.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 56316567552.0000 - val_loss: 35804094464.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56557948928.0000 - val_loss: 34072492032.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58682925056.0000 - val_loss: 44293259264.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 55141629952.0000 - val_loss: 37767503872.0000\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738/738 [==============================] - 3s 4ms/step - loss: 60616613888.0000 - val_loss: 34677723136.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 55675916288.0000 - val_loss: 38006095872.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 55618322432.0000 - val_loss: 33180813312.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 54551375872.0000 - val_loss: 34839711744.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 54986133504.0000 - val_loss: 33427324928.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 56180846592.0000 - val_loss: 32977817600.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 55507521536.0000 - val_loss: 35012698112.0000\n",
      "Epoch 37/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 53808738304.0000 - val_loss: 38160904192.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 51258290176.0000 - val_loss: 34704416768.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 52501262336.0000 - val_loss: 32414171136.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 52644646912.0000 - val_loss: 32730951680.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 54514053120.0000 - val_loss: 34195064832.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 54403764224.0000 - val_loss: 34094618624.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53712834560.0000 - val_loss: 34279477248.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 54364463104.0000 - val_loss: 35051761664.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53379596288.0000 - val_loss: 34107572224.0000\n",
      "Epoch 46/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54152826880.0000 - val_loss: 38846545920.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50687528960.0000 - val_loss: 35174555648.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53230108672.0000 - val_loss: 34739642368.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53042135040.0000 - val_loss: 34477486080.0000\n",
      "Epoch 00049: early stopping\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 32106356736.0000\n",
      "[CV]  n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 1.9min\n",
      "[CV] n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 166640386048.0000 - val_loss: 92666863616.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 88181645312.0000 - val_loss: 69018034176.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 72928993280.0000 - val_loss: 57668329472.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 69945253888.0000 - val_loss: 53786595328.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 68285050880.0000 - val_loss: 52543524864.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 64368742400.0000 - val_loss: 51576680448.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 65098604544.0000 - val_loss: 49295183872.0000\n",
      "Epoch 8/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 62946230272.0000 - val_loss: 49610297344.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 61808074752.0000 - val_loss: 45400092672.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 63796776960.0000 - val_loss: 47538810880.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59418791936.0000 - val_loss: 50195243008.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59189977088.0000 - val_loss: 46099030016.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 60342804480.0000 - val_loss: 41676156928.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 61952626688.0000 - val_loss: 41797455872.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 58818936832.0000 - val_loss: 43917324288.0000\n",
      "Epoch 16/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 57736417280.0000 - val_loss: 41725669376.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 60785004544.0000 - val_loss: 39718842368.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57538068480.0000 - val_loss: 39402848256.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59020439552.0000 - val_loss: 39239274496.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58345304064.0000 - val_loss: 38412992512.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57378574336.0000 - val_loss: 40104026112.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56421974016.0000 - val_loss: 37255647232.0000\n",
      "Epoch 23/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58737565696.0000 - val_loss: 46784323584.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55242395648.0000 - val_loss: 36942761984.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57068806144.0000 - val_loss: 42465361920.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 54985695232.0000 - val_loss: 36565819392.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 56717959168.0000 - val_loss: 35931488256.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57858981888.0000 - val_loss: 39702867968.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 54978625536.0000 - val_loss: 40280850432.0000\n",
      "Epoch 30/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 58325196800.0000 - val_loss: 36521218048.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53789638656.0000 - val_loss: 39359217664.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55540170752.0000 - val_loss: 35138371584.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 54921945088.0000 - val_loss: 35194343424.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 54327984128.0000 - val_loss: 34375577600.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 54945632256.0000 - val_loss: 34177067008.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 55715336192.0000 - val_loss: 36240404480.0000\n",
      "Epoch 37/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54592569344.0000 - val_loss: 40039034880.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51231092736.0000 - val_loss: 34968346624.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 52011012096.0000 - val_loss: 33795219456.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52889042944.0000 - val_loss: 33790343168.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52910997504.0000 - val_loss: 34028652544.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50346319872.0000 - val_loss: 34446376960.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53198716928.0000 - val_loss: 34530451456.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53177516032.0000 - val_loss: 35853578240.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 52649340928.0000 - val_loss: 34322077696.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 54405750784.0000 - val_loss: 43439902720.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 50639634432.0000 - val_loss: 33939851264.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 53694853120.0000 - val_loss: 35848011776.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 52453588992.0000 - val_loss: 34247256064.0000\n",
      "Epoch 50/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 53243551744.0000 - val_loss: 33916616704.0000\n",
      "Epoch 00050: early stopping\n",
      "185/185 [==============================] - 0s 2ms/step - loss: 33358063616.0000\n",
      "[CV]  n_neurons=20, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 1.9min\n",
      "[CV] n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 142048952320.0000 - val_loss: 80148283392.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 70054731776.0000 - val_loss: 57247916032.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58869817344.0000 - val_loss: 52128133120.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59977424896.0000 - val_loss: 48611975168.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57078718464.0000 - val_loss: 48557899776.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 56120197120.0000 - val_loss: 44107223040.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 53824024576.0000 - val_loss: 43812827136.0000\n",
      "Epoch 8/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 52068589568.0000 - val_loss: 42371985408.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 54715351040.0000 - val_loss: 43194093568.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 51863793664.0000 - val_loss: 40466857984.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 51019722752.0000 - val_loss: 42981732352.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 49825308672.0000 - val_loss: 38613491712.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 49524543488.0000 - val_loss: 37139046400.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 49961398272.0000 - val_loss: 36650647552.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 49601904640.0000 - val_loss: 38609399808.0000\n",
      "Epoch 16/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 48389939200.0000 - val_loss: 35876200448.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 47146983424.0000 - val_loss: 35557093376.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 48114274304.0000 - val_loss: 34813493248.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 49317629952.0000 - val_loss: 35484372992.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46153248768.0000 - val_loss: 34889814016.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 48657231872.0000 - val_loss: 33995575296.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 46962913280.0000 - val_loss: 33718972416.0000\n",
      "Epoch 23/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 47701823488.0000 - val_loss: 33685678080.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 46495715328.0000 - val_loss: 35250683904.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 3s 4ms/step - loss: 47718862848.0000 - val_loss: 34768670720.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 46613557248.0000 - val_loss: 34858737664.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 45808390144.0000 - val_loss: 33313150976.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 43806703616.0000 - val_loss: 33388513280.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46585212928.0000 - val_loss: 33094107136.0000\n",
      "Epoch 30/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46401056768.0000 - val_loss: 34670833664.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45183193088.0000 - val_loss: 34339467264.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44921503744.0000 - val_loss: 32773097472.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42261155840.0000 - val_loss: 32774588416.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45089751040.0000 - val_loss: 32831485952.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44895293440.0000 - val_loss: 32902057984.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43700793344.0000 - val_loss: 33388857344.0000\n",
      "Epoch 37/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44866985984.0000 - val_loss: 33814308864.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43131502592.0000 - val_loss: 32602167296.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45467168768.0000 - val_loss: 33317773312.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45229346816.0000 - val_loss: 31868682240.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43477602304.0000 - val_loss: 32735592448.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44694958080.0000 - val_loss: 31454760960.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44383711232.0000 - val_loss: 31571804160.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43634675712.0000 - val_loss: 33676075008.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42407161856.0000 - val_loss: 32000102400.0000\n",
      "Epoch 46/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44397297664.0000 - val_loss: 32748013568.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45100793856.0000 - val_loss: 32135258112.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42673733632.0000 - val_loss: 33575149568.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 42653159424.0000 - val_loss: 32091516928.0000\n",
      "Epoch 50/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 41996746752.0000 - val_loss: 31655684096.0000\n",
      "185/185 [==============================] - 0s 943us/step - loss: 29529681920.0000\n",
      "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 2.0min\n",
      "[CV] n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 142559051776.0000 - val_loss: 81498087424.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 72583888896.0000 - val_loss: 58493587456.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 60699533312.0000 - val_loss: 52088578048.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 61684752384.0000 - val_loss: 50230878208.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58242142208.0000 - val_loss: 51509886976.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 58091130880.0000 - val_loss: 46535086080.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55184482304.0000 - val_loss: 46608261120.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54086729728.0000 - val_loss: 44859875328.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55437463552.0000 - val_loss: 45191098368.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53061836800.0000 - val_loss: 41809154048.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53049286656.0000 - val_loss: 40947138560.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51489255424.0000 - val_loss: 37749141504.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 50973429760.0000 - val_loss: 36512649216.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51735347200.0000 - val_loss: 35973132288.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50149728256.0000 - val_loss: 37653090304.0000\n",
      "Epoch 16/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48642957312.0000 - val_loss: 35008323584.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48170758144.0000 - val_loss: 35801968640.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47391662080.0000 - val_loss: 34698801152.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49407053824.0000 - val_loss: 34136436736.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47315853312.0000 - val_loss: 34636451840.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47949496320.0000 - val_loss: 36427362304.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48491950080.0000 - val_loss: 33414240256.0000\n",
      "Epoch 23/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48592994304.0000 - val_loss: 33935536128.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46354944000.0000 - val_loss: 36838473728.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49033064448.0000 - val_loss: 33910259712.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47783374848.0000 - val_loss: 33828716544.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45308600320.0000 - val_loss: 33370972160.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46735175680.0000 - val_loss: 32985417728.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48520294400.0000 - val_loss: 32762724352.0000\n",
      "Epoch 30/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46240104448.0000 - val_loss: 33885741056.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45148045312.0000 - val_loss: 34344761344.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44669493248.0000 - val_loss: 32454803456.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44382142464.0000 - val_loss: 32553162752.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44349771776.0000 - val_loss: 33934446592.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45806501888.0000 - val_loss: 32165562368.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44404457472.0000 - val_loss: 33444753408.0000\n",
      "Epoch 37/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45845659648.0000 - val_loss: 36600975360.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45138698240.0000 - val_loss: 32212332544.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45358272512.0000 - val_loss: 32272799744.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45008338944.0000 - val_loss: 31805759488.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43234787328.0000 - val_loss: 34652688384.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44636258304.0000 - val_loss: 31293562880.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44023115776.0000 - val_loss: 32100270080.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45339488256.0000 - val_loss: 33321230336.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42934259712.0000 - val_loss: 31589390336.0000\n",
      "Epoch 46/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44770635776.0000 - val_loss: 32544010240.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45670404096.0000 - val_loss: 33436530688.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43889868800.0000 - val_loss: 32853880832.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45504450560.0000 - val_loss: 31938312192.0000\n",
      "Epoch 50/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42128138240.0000 - val_loss: 32158345216.0000\n",
      "185/185 [==============================] - 0s 931us/step - loss: 30585843712.0000\n",
      "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 1.8min\n",
      "[CV] n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 136243609600.0000 - val_loss: 76100640768.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 68169216000.0000 - val_loss: 54425391104.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 59116822528.0000 - val_loss: 54529728512.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57119322112.0000 - val_loss: 47139512320.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55304822784.0000 - val_loss: 46798512128.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 53052837888.0000 - val_loss: 44613959680.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52436299776.0000 - val_loss: 42476060672.0000\n",
      "Epoch 8/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 52216287232.0000 - val_loss: 45210832896.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 52996947968.0000 - val_loss: 39280541696.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 52012236800.0000 - val_loss: 39219486720.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49374904320.0000 - val_loss: 39531937792.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50440138752.0000 - val_loss: 37534826496.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 47528972288.0000 - val_loss: 39238737920.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48545202176.0000 - val_loss: 37741023232.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49132285952.0000 - val_loss: 35638984704.0000\n",
      "Epoch 16/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48261926912.0000 - val_loss: 34922774528.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47405973504.0000 - val_loss: 36681990144.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46564360192.0000 - val_loss: 36894232576.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49597558784.0000 - val_loss: 37440733184.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 46681714688.0000 - val_loss: 34282287104.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46040657920.0000 - val_loss: 34817712128.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46143590400.0000 - val_loss: 35160121344.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46180315136.0000 - val_loss: 33517672448.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45815881728.0000 - val_loss: 35204579328.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46343360512.0000 - val_loss: 33806483456.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45937598464.0000 - val_loss: 34300135424.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45753917440.0000 - val_loss: 33046790144.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46863974400.0000 - val_loss: 38278070272.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45202518016.0000 - val_loss: 34666070016.0000\n",
      "Epoch 30/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44724142080.0000 - val_loss: 32483579904.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45801000960.0000 - val_loss: 35428880384.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45447553024.0000 - val_loss: 33779720192.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44590972928.0000 - val_loss: 32947806208.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44955521024.0000 - val_loss: 32022300672.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44850421760.0000 - val_loss: 32981059584.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45866590208.0000 - val_loss: 32802562048.0000\n",
      "Epoch 37/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44672331776.0000 - val_loss: 35622727680.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44004610048.0000 - val_loss: 32129146880.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43687350272.0000 - val_loss: 31800213504.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 44955521024.0000 - val_loss: 31652458496.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43913818112.0000 - val_loss: 32420952064.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43225260032.0000 - val_loss: 31775819776.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44111347712.0000 - val_loss: 34318520320.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43814944768.0000 - val_loss: 34143404032.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44021620736.0000 - val_loss: 32161992704.0000\n",
      "Epoch 46/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42439847936.0000 - val_loss: 34188345344.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42154541056.0000 - val_loss: 33410035712.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43438149632.0000 - val_loss: 31815450624.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 41739300864.0000 - val_loss: 32337031168.0000\n",
      "Epoch 50/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44612534272.0000 - val_loss: 32685484032.0000\n",
      "Epoch 00050: early stopping\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 31780640768.0000\n",
      "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 1.7min\n",
      "[CV] n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n",
      "738/738 [==============================] - 3s 3ms/step - loss: 142277066752.0000 - val_loss: 77633626112.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 71622606848.0000 - val_loss: 55434047488.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 62215430144.0000 - val_loss: 51953598464.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 61284515840.0000 - val_loss: 46854115328.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 57580109824.0000 - val_loss: 46031921152.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54644559872.0000 - val_loss: 43538608128.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54798061568.0000 - val_loss: 42877939712.0000\n",
      "Epoch 8/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54539227136.0000 - val_loss: 44435431424.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53711613952.0000 - val_loss: 38863101952.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53171216384.0000 - val_loss: 37737451520.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50510282752.0000 - val_loss: 39897018368.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51609968640.0000 - val_loss: 38175375360.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49373908992.0000 - val_loss: 35991965696.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 50422226944.0000 - val_loss: 36966592512.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 50643324928.0000 - val_loss: 35787239424.0000\n",
      "Epoch 16/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 48087961600.0000 - val_loss: 34455400448.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 50380361728.0000 - val_loss: 34279835648.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 48200691712.0000 - val_loss: 37008916480.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50566115328.0000 - val_loss: 37778575360.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48612519936.0000 - val_loss: 33685098496.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48301457408.0000 - val_loss: 33406668800.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46083960832.0000 - val_loss: 34480328704.0000\n",
      "Epoch 23/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47702966272.0000 - val_loss: 36571017216.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46466961408.0000 - val_loss: 32867004416.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48121749504.0000 - val_loss: 33727512576.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46182580224.0000 - val_loss: 33525096448.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46327930880.0000 - val_loss: 32544411648.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46226046976.0000 - val_loss: 44579913728.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47090581504.0000 - val_loss: 32875458560.0000\n",
      "Epoch 30/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45941784576.0000 - val_loss: 32450441216.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47651082240.0000 - val_loss: 36847140864.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45188616192.0000 - val_loss: 32300750848.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45892521984.0000 - val_loss: 31948797952.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46335696896.0000 - val_loss: 32315092992.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44806225920.0000 - val_loss: 31818821632.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45740195840.0000 - val_loss: 32143781888.0000\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "738/738 [==============================] - 2s 3ms/step - loss: 45280821248.0000 - val_loss: 35671191552.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44837031936.0000 - val_loss: 31849705472.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44773969920.0000 - val_loss: 31813851136.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45088145408.0000 - val_loss: 34214045696.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43331162112.0000 - val_loss: 32145383424.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43137699840.0000 - val_loss: 32535554048.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43554979840.0000 - val_loss: 32988098560.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44418576384.0000 - val_loss: 33120280576.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44152078336.0000 - val_loss: 31647688704.0000\n",
      "Epoch 46/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43699830784.0000 - val_loss: 32571254784.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42093891584.0000 - val_loss: 31835795456.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43088998400.0000 - val_loss: 31624304640.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43916111872.0000 - val_loss: 33437272064.0000\n",
      "Epoch 50/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 45376339968.0000 - val_loss: 32859392000.0000\n",
      "185/185 [==============================] - 0s 911us/step - loss: 31301263360.0000\n",
      "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 1.7min\n",
      "[CV] n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu \n",
      "Epoch 1/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 141959839744.0000 - val_loss: 79880986624.0000\n",
      "Epoch 2/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 70853197824.0000 - val_loss: 58510888960.0000\n",
      "Epoch 3/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 62260129792.0000 - val_loss: 51247767552.0000\n",
      "Epoch 4/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 60527046656.0000 - val_loss: 47448944640.0000\n",
      "Epoch 5/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55839657984.0000 - val_loss: 46134423552.0000\n",
      "Epoch 6/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 53737857024.0000 - val_loss: 45251915776.0000\n",
      "Epoch 7/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 54472835072.0000 - val_loss: 43918000128.0000\n",
      "Epoch 8/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 55154737152.0000 - val_loss: 43814244352.0000\n",
      "Epoch 9/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51434614784.0000 - val_loss: 39574732800.0000\n",
      "Epoch 10/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 52893593600.0000 - val_loss: 39091122176.0000\n",
      "Epoch 11/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51434323968.0000 - val_loss: 40422289408.0000\n",
      "Epoch 12/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 51045740544.0000 - val_loss: 38144352256.0000\n",
      "Epoch 13/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49457655808.0000 - val_loss: 36596916224.0000\n",
      "Epoch 14/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50936299520.0000 - val_loss: 37485031424.0000\n",
      "Epoch 15/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 50050527232.0000 - val_loss: 39451811840.0000\n",
      "Epoch 16/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48534663168.0000 - val_loss: 36799795200.0000\n",
      "Epoch 17/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 49567518720.0000 - val_loss: 36066258944.0000\n",
      "Epoch 18/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48419962880.0000 - val_loss: 36665942016.0000\n",
      "Epoch 19/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48554151936.0000 - val_loss: 36319571968.0000\n",
      "Epoch 20/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 47888027648.0000 - val_loss: 34742337536.0000\n",
      "Epoch 21/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 48153804800.0000 - val_loss: 35787415552.0000\n",
      "Epoch 22/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 45661749248.0000 - val_loss: 37198929920.0000\n",
      "Epoch 23/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47282872320.0000 - val_loss: 37759475712.0000\n",
      "Epoch 24/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 46555521024.0000 - val_loss: 33968541696.0000\n",
      "Epoch 25/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 46849302528.0000 - val_loss: 35711889408.0000\n",
      "Epoch 26/50\n",
      "738/738 [==============================] - 2s 2ms/step - loss: 46564933632.0000 - val_loss: 33414234112.0000\n",
      "Epoch 27/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45777838080.0000 - val_loss: 33446676480.0000\n",
      "Epoch 28/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45219577856.0000 - val_loss: 38554574848.0000\n",
      "Epoch 29/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47448600576.0000 - val_loss: 34590863360.0000\n",
      "Epoch 30/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45389500416.0000 - val_loss: 34024691712.0000\n",
      "Epoch 31/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 47206404096.0000 - val_loss: 36426629120.0000\n",
      "Epoch 32/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45318172672.0000 - val_loss: 33606105088.0000\n",
      "Epoch 33/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45293264896.0000 - val_loss: 32478836736.0000\n",
      "Epoch 34/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45604188160.0000 - val_loss: 33004310528.0000\n",
      "Epoch 35/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44133363712.0000 - val_loss: 32956594176.0000\n",
      "Epoch 36/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45459460096.0000 - val_loss: 33153476608.0000\n",
      "Epoch 37/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45134209024.0000 - val_loss: 36102316032.0000\n",
      "Epoch 38/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44359782400.0000 - val_loss: 32429600768.0000\n",
      "Epoch 39/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44304506880.0000 - val_loss: 35280048128.0000\n",
      "Epoch 40/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45264773120.0000 - val_loss: 33935978496.0000\n",
      "Epoch 41/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42740621312.0000 - val_loss: 32754280448.0000\n",
      "Epoch 42/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42486583296.0000 - val_loss: 33061132288.0000\n",
      "Epoch 43/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42640797696.0000 - val_loss: 33039595520.0000\n",
      "Epoch 44/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43992936448.0000 - val_loss: 33028302848.0000\n",
      "Epoch 45/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42464083968.0000 - val_loss: 32418148352.0000\n",
      "Epoch 46/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 43890581504.0000 - val_loss: 33406246912.0000\n",
      "Epoch 47/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42060578816.0000 - val_loss: 32708298752.0000\n",
      "Epoch 48/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 42892357632.0000 - val_loss: 34454310912.0000\n",
      "Epoch 49/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 44246790144.0000 - val_loss: 32512110592.0000\n",
      "Epoch 50/50\n",
      "738/738 [==============================] - 2s 3ms/step - loss: 45095809024.0000 - val_loss: 33274759168.0000\n",
      "185/185 [==============================] - 0s 1ms/step - loss: 32447780864.0000\n",
      "[CV]  n_neurons=30, n_hidden=3, learning_rate=0.01, init=uniform, epochs=50, dropout_rate=0.2, batch_size=15, activation=relu, total= 1.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed: 17.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923/923 [==============================] - 3s 3ms/step - loss: 127075164160.0000 - val_loss: 71870971904.0000\n",
      "Epoch 2/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 66818699264.0000 - val_loss: 54746415104.0000\n",
      "Epoch 3/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 60380676096.0000 - val_loss: 53093740544.0000\n",
      "Epoch 4/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 60101038080.0000 - val_loss: 47756390400.0000\n",
      "Epoch 5/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 57792671744.0000 - val_loss: 48104849408.0000\n",
      "Epoch 6/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 54894526464.0000 - val_loss: 43343020032.0000\n",
      "Epoch 7/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 54868705280.0000 - val_loss: 43994927104.0000\n",
      "Epoch 8/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 52971614208.0000 - val_loss: 43254546432.0000\n",
      "Epoch 9/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 51697516544.0000 - val_loss: 43062398976.0000\n",
      "Epoch 10/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 52729958400.0000 - val_loss: 41745416192.0000\n",
      "Epoch 11/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 51050070016.0000 - val_loss: 40987496448.0000\n",
      "Epoch 12/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 51362684928.0000 - val_loss: 38611398656.0000\n",
      "Epoch 13/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 51856027648.0000 - val_loss: 35988381696.0000\n",
      "Epoch 14/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 48879620096.0000 - val_loss: 35777310720.0000\n",
      "Epoch 15/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 48996016128.0000 - val_loss: 36437856256.0000\n",
      "Epoch 16/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 49777676288.0000 - val_loss: 39678439424.0000\n",
      "Epoch 17/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 49511464960.0000 - val_loss: 34829836288.0000\n",
      "Epoch 18/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 49226133504.0000 - val_loss: 34204157952.0000\n",
      "Epoch 19/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 49557057536.0000 - val_loss: 34562093056.0000\n",
      "Epoch 20/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 49069641728.0000 - val_loss: 35890167808.0000\n",
      "Epoch 21/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 48230498304.0000 - val_loss: 36360695808.0000\n",
      "Epoch 22/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 46595452928.0000 - val_loss: 33076946944.0000\n",
      "Epoch 23/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 47556734976.0000 - val_loss: 34288748544.0000\n",
      "Epoch 24/50\n",
      "923/923 [==============================] - 2s 2ms/step - loss: 46770335744.0000 - val_loss: 35250724864.0000\n",
      "Epoch 25/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 46679764992.0000 - val_loss: 32967370752.0000\n",
      "Epoch 26/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 47719186432.0000 - val_loss: 32389836800.0000\n",
      "Epoch 27/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 45000491008.0000 - val_loss: 31974688768.0000\n",
      "Epoch 28/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 46076620800.0000 - val_loss: 33804107776.0000\n",
      "Epoch 29/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 45444608000.0000 - val_loss: 33740967936.0000\n",
      "Epoch 30/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 44939681792.0000 - val_loss: 31920957440.0000\n",
      "Epoch 31/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 45344854016.0000 - val_loss: 32487456768.0000\n",
      "Epoch 32/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 45482446848.0000 - val_loss: 31393542144.0000\n",
      "Epoch 33/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 45713698816.0000 - val_loss: 33432000512.0000\n",
      "Epoch 34/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 44968906752.0000 - val_loss: 31332958208.0000\n",
      "Epoch 35/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 43746177024.0000 - val_loss: 31860062208.0000\n",
      "Epoch 36/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 43731947520.0000 - val_loss: 31659661312.0000\n",
      "Epoch 37/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 43622039552.0000 - val_loss: 32623509504.0000\n",
      "Epoch 38/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 43348910080.0000 - val_loss: 31770750976.0000\n",
      "Epoch 39/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 43563085824.0000 - val_loss: 32294823936.0000\n",
      "Epoch 40/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 44155932672.0000 - val_loss: 32775579648.0000\n",
      "Epoch 41/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 42986201088.0000 - val_loss: 31513307136.0000\n",
      "Epoch 42/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 44672856064.0000 - val_loss: 33983281152.0000\n",
      "Epoch 43/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 43233710080.0000 - val_loss: 30700402688.0000\n",
      "Epoch 44/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 44340404224.0000 - val_loss: 33421217792.0000\n",
      "Epoch 45/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 42621120512.0000 - val_loss: 31965372416.0000\n",
      "Epoch 46/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 43435073536.0000 - val_loss: 31352944640.0000\n",
      "Epoch 47/50\n",
      "923/923 [==============================] - 2s 3ms/step - loss: 44578058240.0000 - val_loss: 30894043136.0000\n",
      "Epoch 48/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 43967778816.0000 - val_loss: 31061776384.0000\n",
      "Epoch 49/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 43307315200.0000 - val_loss: 30508392448.0000\n",
      "Epoch 50/50\n",
      "923/923 [==============================] - 3s 3ms/step - loss: 41604968448.0000 - val_loss: 32955408384.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=5, random_state=6, shuffle=False),\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x00000272B65B06D0>,\n",
       "                   param_distributions={'activation': ['relu'],\n",
       "                                        'batch_size': [15],\n",
       "                                        'dropout_rate': [0.2], 'epochs': [50],\n",
       "                                        'init': ['uniform'],\n",
       "                                        'learning_rate': [0.01],\n",
       "                                        'n_hidden': [3],\n",
       "                                        'n_neurons': [20, 30]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "seed = 6\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [3],\n",
    "    \"n_neurons\": [20,30],\n",
    "    #\"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "    'learning_rate': [0.01],\n",
    "    'dropout_rate': [0.2],\n",
    "    'batch_size': [15],\n",
    "    'epochs': [50],\n",
    "    #'activation': ['softmax', 'relu', 'tanh', 'linear'],\n",
    "    'activation': ['relu'],\n",
    "    #'init': ['uniform', 'normal', 'zero']\n",
    "    'init': ['uniform']   \n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, cv=KFold(5,random_state=seed), verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, \n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "923/923 [==============================] - 1s 1ms/step - loss: 30701248512.0000\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 29461327872.0000\n",
      "-30701248512.0 -29461327872.0\n",
      "RMSE: 171643.024\n",
      "MSE: 29461327557.539\n",
      "MAE: 105732.005\n",
      "r2: 0.796\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "\n",
    "model = rnd_search_cv.best_estimator_\n",
    "# Train score, test score\n",
    "training_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "test_predictions = model.predict(X_test)\n",
    "print(training_score, test_score)\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, test_predictions)\n",
    "print(\"MAE: %.3f\"  % mae)\n",
    "      \n",
    "# r2 - coefficient of determination\n",
    "r2 = explained_variance_score(y_test, test_predictions)\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4ZRgWyxq-iO",
    "outputId": "f05ce743-37a4-4295-b4c1-774aaf0b271f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 30,\n",
       " 'n_hidden': 3,\n",
       " 'learning_rate': 0.01,\n",
       " 'init': 'uniform',\n",
       " 'epochs': 50,\n",
       " 'dropout_rate': 0.2,\n",
       " 'batch_size': 15,\n",
       " 'activation': 'relu'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcHT7W_zKbaS",
    "outputId": "631692b6-62d5-4444-c553-4b782fd61641"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-31129042124.8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wYZAWg0KbaS",
    "outputId": "c12b7e54-d31e-410f-dbfe-df0d0035945f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x272bc091100>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUovM1pwKbaT",
    "outputId": "a866a3b4-7d01-424d-e1fb-6e06f1cb4249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 0s 1ms/step - loss: 29461327872.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-29461327872.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXOvffS0KbaT",
    "outputId": "c4c2229c-d415-4644-e107-bb9ba51f9ead"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x272b66329d0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlJtmGXEKbaT",
    "outputId": "8a6a5420-97b9-4c90-b4ee-ce042356c043",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step - loss: 29461323776.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29461323776.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**6. TensorBoard**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2025_04_13-05_48_42'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1509432439605151296207707963392.0000 - val_loss: 747683135647690366746886144.0000\n",
      "Epoch 2/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 356184934692300759272259584.0000 - val_loss: 132058608286836156723625984.0000\n",
      "Epoch 3/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 62910734483804888984715264.0000 - val_loss: 23324683478567835546943488.0000\n",
      "Epoch 4/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 11111517349556932134830080.0000 - val_loss: 4119685701478076660056064.0000\n",
      "Epoch 5/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1962555154839858382372864.0000 - val_loss: 727635927270333425385472.0000\n",
      "Epoch 6/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 346633776695392715407360.0000 - val_loss: 128517295025631329779712.0000\n",
      "Epoch 7/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 61223622184334786560000.0000 - val_loss: 22699175698061781368832.0000\n",
      "Epoch 8/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10813533392584235286528.0000 - val_loss: 4009209096976551903232.0000\n",
      "Epoch 9/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1909922699509787262976.0000 - val_loss: 708121798559739674624.0000\n",
      "Epoch 10/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 337338083885396787200.0000 - val_loss: 125071066140636086272.0000\n",
      "Epoch 11/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 59581809431507107840.0000 - val_loss: 22090580583740604416.0000\n",
      "Epoch 12/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10523568725955706880.0000 - val_loss: 3901726412570099712.0000\n",
      "Epoch 13/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1858707776641957888.0000 - val_loss: 689144751231860736.0000\n",
      "Epoch 14/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 328292594138218496.0000 - val_loss: 121722749012934656.0000\n",
      "Epoch 15/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 57984618296508416.0000 - val_loss: 21500524679397376.0000\n",
      "Epoch 16/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10241653386248192.0000 - val_loss: 3798186682482688.0000\n",
      "Epoch 17/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1809054183718912.0000 - val_loss: 671185813635072.0000\n",
      "Epoch 18/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 319622070927360.0000 - val_loss: 118749931765760.0000\n",
      "Epoch 19/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 56559975530496.0000 - val_loss: 21127365656576.0000\n",
      "Epoch 20/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10094672609280.0000 - val_loss: 3865662455808.0000\n",
      "Epoch 21/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1891601612800.0000 - val_loss: 810380427264.0000\n",
      "Epoch 22/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 442595082240.0000 - val_loss: 265459482624.0000\n",
      "Epoch 23/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 186436878336.0000 - val_loss: 168220344320.0000\n",
      "Epoch 24/30\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 141340475392.0000 - val_loss: 150146826240.0000\n",
      "Epoch 25/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 133258240000.0000 - val_loss: 146675597312.0000\n",
      "Epoch 26/30\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 131833675776.0000 - val_loss: 145922162688.0000\n",
      "Epoch 27/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131585482752.0000 - val_loss: 145770889216.0000\n",
      "Epoch 28/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131550453760.0000 - val_loss: 145734254592.0000\n",
      "Epoch 29/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131543851008.0000 - val_loss: 145714462720.0000\n",
      "Epoch 30/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131540385792.0000 - val_loss: 145704730624.0000\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the TensorBoard server, one option is to open a terminal, if needed activate the virtualenv where you installed TensorBoard, go to this notebook's directory, then type:\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=./my_logs --port=6006\n",
    "```\n",
    "\n",
    "You can then open your web browser to [localhost:6006](http://localhost:6006) and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server.\n",
    "\n",
    "Alternatively, you can load TensorBoard's Jupyter extension and run it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23820), started 3 days, 23:42:29 ago. (Use '!kill 23820' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c26990923cd49aa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c26990923cd49aa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2025_04_13-05_49_08'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1509432439605151296207707963392.0000 - val_loss: 747683135647690366746886144.0000\n",
      "Epoch 2/30\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 356184934692300759272259584.0000 - val_loss: 132058608286836156723625984.0000\n",
      "Epoch 3/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 62910734483804888984715264.0000 - val_loss: 23324683478567835546943488.0000\n",
      "Epoch 4/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 11111517349556932134830080.0000 - val_loss: 4119685701478076660056064.0000\n",
      "Epoch 5/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1962555154839858382372864.0000 - val_loss: 727635927270333425385472.0000\n",
      "Epoch 6/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 346633776695392715407360.0000 - val_loss: 128517295025631329779712.0000\n",
      "Epoch 7/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 61223622184334786560000.0000 - val_loss: 22699175698061781368832.0000\n",
      "Epoch 8/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10813533392584235286528.0000 - val_loss: 4009209096976551903232.0000\n",
      "Epoch 9/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1909922699509787262976.0000 - val_loss: 708121798559739674624.0000\n",
      "Epoch 10/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 337338083885396787200.0000 - val_loss: 125071066140636086272.0000\n",
      "Epoch 11/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 59581809431507107840.0000 - val_loss: 22090580583740604416.0000\n",
      "Epoch 12/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10523568725955706880.0000 - val_loss: 3901726412570099712.0000\n",
      "Epoch 13/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1858707776641957888.0000 - val_loss: 689144751231860736.0000\n",
      "Epoch 14/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 328292594138218496.0000 - val_loss: 121722749012934656.0000\n",
      "Epoch 15/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 57984618296508416.0000 - val_loss: 21500524679397376.0000\n",
      "Epoch 16/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10241653386248192.0000 - val_loss: 3798186682482688.0000\n",
      "Epoch 17/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1809054183718912.0000 - val_loss: 671185813635072.0000\n",
      "Epoch 18/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 319622070927360.0000 - val_loss: 118749931765760.0000\n",
      "Epoch 19/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 56559975530496.0000 - val_loss: 21127365656576.0000\n",
      "Epoch 20/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10094672609280.0000 - val_loss: 3865662455808.0000\n",
      "Epoch 21/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1891601612800.0000 - val_loss: 810380427264.0000\n",
      "Epoch 22/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 442595082240.0000 - val_loss: 265459482624.0000\n",
      "Epoch 23/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 186436878336.0000 - val_loss: 168220344320.0000\n",
      "Epoch 24/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 141340475392.0000 - val_loss: 150146826240.0000\n",
      "Epoch 25/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 133258240000.0000 - val_loss: 146675597312.0000\n",
      "Epoch 26/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131833675776.0000 - val_loss: 145922162688.0000\n",
      "Epoch 27/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131585482752.0000 - val_loss: 145770889216.0000\n",
      "Epoch 28/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131550453760.0000 - val_loss: 145734254592.0000\n",
      "Epoch 29/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131543851008.0000 - val_loss: 145714462720.0000\n",
      "Epoch 30/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131540385792.0000 - val_loss: 145704730624.0000\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539173376.0000 - val_loss: 145696817152.0000\n",
      "Epoch 2/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131540017152.0000 - val_loss: 145691557888.0000\n",
      "Epoch 3/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538165760.0000 - val_loss: 145697030144.0000\n",
      "Epoch 4/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539099648.0000 - val_loss: 145682644992.0000\n",
      "Epoch 5/30\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 131539337216.0000 - val_loss: 145674502144.0000\n",
      "Epoch 6/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538493440.0000 - val_loss: 145680465920.0000\n",
      "Epoch 7/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538509824.0000 - val_loss: 145671634944.0000\n",
      "Epoch 8/30\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 131538509824.0000 - val_loss: 145678843904.0000\n",
      "Epoch 9/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537682432.0000 - val_loss: 145682808832.0000\n",
      "Epoch 10/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538157568.0000 - val_loss: 145686069248.0000\n",
      "Epoch 11/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538067456.0000 - val_loss: 145687035904.0000\n",
      "Epoch 12/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537207296.0000 - val_loss: 145674190848.0000\n",
      "Epoch 13/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539435520.0000 - val_loss: 145686937600.0000\n",
      "Epoch 14/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131536838656.0000 - val_loss: 145698930688.0000\n",
      "Epoch 15/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538960384.0000 - val_loss: 145694588928.0000\n",
      "Epoch 16/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539255296.0000 - val_loss: 145697406976.0000\n",
      "Epoch 17/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539386368.0000 - val_loss: 145692344320.0000\n",
      "Epoch 18/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537690624.0000 - val_loss: 145684758528.0000\n",
      "Epoch 19/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539050496.0000 - val_loss: 145679794176.0000\n",
      "Epoch 20/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539165184.0000 - val_loss: 145678106624.0000\n",
      "Epoch 21/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537985536.0000 - val_loss: 145692065792.0000\n",
      "Epoch 22/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537788928.0000 - val_loss: 145680695296.0000\n",
      "Epoch 23/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538665472.0000 - val_loss: 145694277632.0000\n",
      "Epoch 24/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538993152.0000 - val_loss: 145688428544.0000\n",
      "Epoch 25/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538747392.0000 - val_loss: 145686151168.0000\n",
      "Epoch 26/30\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 131538698240.0000 - val_loss: 145676484608.0000\n",
      "Epoch 27/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539558400.0000 - val_loss: 145687576576.0000\n",
      "Epoch 28/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538001920.0000 - val_loss: 145700831232.0000\n",
      "Epoch 29/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539632128.0000 - val_loss: 145701191680.0000\n",
      "Epoch 30/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539066880.0000 - val_loss: 145699356672.0000\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how TensorBoard now sees two runs, and you can compare the learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the other available logging options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, write_steps_per_second=False, update_freq='epoch', profile_batch=0, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
