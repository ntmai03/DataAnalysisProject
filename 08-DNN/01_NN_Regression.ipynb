{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div class=\"alert alert-info\" align=\"center\" font color=\"red\">  DNN Regression</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**1 Introduction**</font>\n",
    "\n",
    "The goal is to group similar instances together into clusters. This is a great tool for data analysis, customer segmentation, recommender systems, search engines, image segmentation, semi-supervised learning, dimensionality reduction, and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <div class=\"alert alert-info\"> Setup </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**2.1. Import library**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mai\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 500)\n",
    "\n",
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# <div class=\"alert alert-info\"> KC House </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## <font color=red>**1. Data**</font>\n",
    "\n",
    "We will be using data from a Kaggle data set:\n",
    "\n",
    "https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "#### Feature Columns\n",
    "    \n",
    "* id - Unique ID for each home sold\n",
    "* date - Date of the home sale\n",
    "* price - Price of each home sold\n",
    "* bedrooms - Number of bedrooms\n",
    "* bathrooms - Number of bathrooms, where .5 accounts for a room with a toilet but no shower\n",
    "* sqft_living - Square footage of the apartments interior living space\n",
    "* sqft_lot - Square footage of the land space\n",
    "* floors - Number of floors\n",
    "* waterfront - A dummy variable for whether the apartment was overlooking the waterfront or not\n",
    "* view - An index from 0 to 4 of how good the view of the property was\n",
    "* condition - An index from 1 to 5 on the condition of the apartment,\n",
    "* grade - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design.\n",
    "* sqft_above - The square footage of the interior housing space that is above ground level\n",
    "* sqft_basement - The square footage of the interior housing space that is below ground level\n",
    "* yr_built - The year the house was initially built\n",
    "* yr_renovated - The year of the houseâ€™s last renovation\n",
    "* zipcode - What zipcode area the house is in\n",
    "* lat - Lattitude\n",
    "* long - Longitude\n",
    "* sqft_living15 - The square footage of interior housing living space for the nearest 15 neighbors\n",
    "* sqft_lot15 - The square footage of the land lots of the nearest 15 neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21613, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  condition  grade  sqft_above  sqft_basement  yr_built  yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180      5650     1.0           0     0          3      7        1180              0      1955             0    98178  47.5112 -122.257           1340        5650\n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570      7242     2.0           0     0          3      7        2170            400      1951          1991    98125  47.7210 -122.319           1690        7639\n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770     10000     1.0           0     0          3      6         770              0      1933             0    98028  47.7379 -122.233           2720        8062\n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960      5000     1.0           0     0          5      7        1050            910      1965             0    98136  47.5208 -122.393           1360        5000\n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680      8080     1.0           0     0          3      8        1680              0      1987             0    98074  47.6168 -122.045           1800        7503"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../00-Data/data/kc_house_data.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**2. Data Processing**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13832,), (3458,), (4323,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select features\n",
    "selected_features = df.drop(['id','zipcode','date','price'], axis=1).columns\n",
    "\n",
    "# Split data\n",
    "X = df[selected_features]\n",
    "y = df['price']\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=101)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_valid = X_valid.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_valid = y_valid.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "# Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train.shape, X_valid.shape, X_test.shape\n",
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**3. Model**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Define model Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(99)\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "# Initialize\n",
    "model = Sequential()\n",
    "\n",
    "# Add layers\n",
    "model.add(Dense(30, activation='relu', input_shape=X_train.shape[1:]))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Training model**\n",
    "    \n",
    "Below are some common definitions that are necessary to know and understand to correctly utilize Keras:\n",
    "\n",
    "* **Sample**: one element of a dataset.\n",
    "    * Example: one image is a sample in a convolutional network\n",
    "    * Example: one audio file is a sample for a speech recognition model\n",
    "* **Batch**: a set of N samples. The samples in a batch are processed independently, in parallel. If training, a batch results in only one update to the model.A batch generally approximates the distribution of the input data better than a single input. The larger the batch, the better the approximation; however, it is also true that the batch will take longer to process and will still result in only one update. For inference (evaluate/predict), it is recommended to pick a batch size that is as large as you can afford without going out of memory (since larger batches will usually result in faster evaluation/prediction).\n",
    "* **Epoch**: an arbitrary cutoff, generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation.\n",
    "* When using **validation_data or validation_split** with the fit method of Keras models, evaluation will be run at the end of every epoch.\n",
    "* Within Keras, **there is the ability to add callbacks specifically designed to be run at the end of an epoch**. Examples of these are learning rate changes and model checkpointing (saving).    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 185543933952.0000 - val_loss: 104456536064.0000\n",
      "Epoch 2/50\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 88374444032.0000 - val_loss: 95162736640.0000\n",
      "Epoch 3/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 79075082240.0000 - val_loss: 84753637376.0000\n",
      "Epoch 4/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 69416845312.0000 - val_loss: 74298253312.0000\n",
      "Epoch 5/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 60204171264.0000 - val_loss: 65077174272.0000\n",
      "Epoch 6/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 54019432448.0000 - val_loss: 59877986304.0000\n",
      "Epoch 7/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 50591698944.0000 - val_loss: 57032880128.0000\n",
      "Epoch 8/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 48742367232.0000 - val_loss: 55006658560.0000\n",
      "Epoch 9/50\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 47392854016.0000 - val_loss: 53508894720.0000\n",
      "Epoch 10/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 46291689472.0000 - val_loss: 52392857600.0000\n",
      "Epoch 11/50\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 45125926912.0000 - val_loss: 51071836160.0000\n",
      "Epoch 12/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 44015284224.0000 - val_loss: 49934909440.0000\n",
      "Epoch 13/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 43085922304.0000 - val_loss: 48743510016.0000\n",
      "Epoch 14/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 42119008256.0000 - val_loss: 48108666880.0000\n",
      "Epoch 15/50\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 41563807744.0000 - val_loss: 47048462336.0000\n",
      "Epoch 16/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 41054863360.0000 - val_loss: 46524940288.0000\n",
      "Epoch 17/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 40502464512.0000 - val_loss: 45655900160.0000\n",
      "Epoch 18/50\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 39905828864.0000 - val_loss: 44829724672.0000\n",
      "Epoch 19/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 39208071168.0000 - val_loss: 44092145664.0000\n",
      "Epoch 20/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 38678188032.0000 - val_loss: 43561295872.0000\n",
      "Epoch 21/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 38209064960.0000 - val_loss: 42689056768.0000\n",
      "Epoch 22/50\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 37679235072.0000 - val_loss: 42013650944.0000\n",
      "Epoch 23/50\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 37204451328.0000 - val_loss: 41502121984.0000\n",
      "Epoch 24/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 36820094976.0000 - val_loss: 40950312960.0000\n",
      "Epoch 25/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 36457369600.0000 - val_loss: 40217059328.0000\n",
      "Epoch 26/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 36239020032.0000 - val_loss: 39833554944.0000\n",
      "Epoch 27/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 35908362240.0000 - val_loss: 39388856320.0000\n",
      "Epoch 28/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 35629264896.0000 - val_loss: 39458795520.0000\n",
      "Epoch 29/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 35513511936.0000 - val_loss: 38876090368.0000\n",
      "Epoch 30/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 35256455168.0000 - val_loss: 38654566400.0000\n",
      "Epoch 31/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 35113771008.0000 - val_loss: 38358679552.0000\n",
      "Epoch 32/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 34918424576.0000 - val_loss: 37988671488.0000\n",
      "Epoch 33/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 34711396352.0000 - val_loss: 37627478016.0000\n",
      "Epoch 34/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 34622251008.0000 - val_loss: 37392637952.0000\n",
      "Epoch 35/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 34448138240.0000 - val_loss: 37080756224.0000\n",
      "Epoch 36/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 34242377728.0000 - val_loss: 36974354432.0000\n",
      "Epoch 37/50\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 34093115392.0000 - val_loss: 36777267200.0000\n",
      "Epoch 38/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33958230016.0000 - val_loss: 36462501888.0000\n",
      "Epoch 39/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33791363072.0000 - val_loss: 36511924224.0000\n",
      "Epoch 40/50\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 33670836224.0000 - val_loss: 36090949632.0000\n",
      "Epoch 41/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33524496384.0000 - val_loss: 35914305536.0000\n",
      "Epoch 42/50\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 33338994688.0000 - val_loss: 35898503168.0000\n",
      "Epoch 43/50\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 33284694016.0000 - val_loss: 35498557440.0000\n",
      "Epoch 44/50\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 33172633600.0000 - val_loss: 35401154560.0000\n",
      "Epoch 45/50\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 32990359552.0000 - val_loss: 35054325760.0000\n",
      "Epoch 46/50\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 32944599040.0000 - val_loss: 34952667136.0000\n",
      "Epoch 47/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32804360192.0000 - val_loss: 34993360896.0000\n",
      "Epoch 48/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32683792384.0000 - val_loss: 34769154048.0000\n",
      "Epoch 49/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32638509056.0000 - val_loss: 34452062208.0000\n",
      "Epoch 50/50\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32530548736.0000 - val_loss: 34530758656.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x234269fe5e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train.values, validation_data=(X_valid, y_valid.values), batch_size=5, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Plot loss history**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_hist = pd.DataFrame(model.history.history)\n",
    "loss_hist.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Performance Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 50, 'steps': 2767}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n",
      "dict_keys(['loss', 'val_loss'])\n",
      "['loss']\n"
     ]
    }
   ],
   "source": [
    "print(model.history.params)\n",
    "print(model.history.epoch)\n",
    "print(model.history.history.keys())\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32449710080.0, 31163226112.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "training_score, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  107048.54628585473\n",
      "RMSE:  176531.0988756957\n",
      "R-squared:  0.772215004968877\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = model.predict(X_test)\n",
    "# MAE\n",
    "print('MAE: ', mean_absolute_error(y_test, y_test_pred))\n",
    "# RMSE\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "# R-square\n",
    "print('R-squared: ', explained_variance_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2cc992727f0>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEQCAYAAACZYT5EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAAsTAAALEwEAmpwYAAAohElEQVR4nO3de5zWY/7H8ddnpimTVoMGGSW7bHaF0iBrD4rFLpsW65TdtbvE2qywkcPPYbHbCutstQibSNEgVhYRrahMVMhKSePQUFOqqabm+v3xvQ8z03343jP34Xvf834+Hh667uPnHnrf11zf62DOOUREJLiKcl2AiIgkpqAWEQk4BbWISMApqEVEAk5BLSIScApqEZGAy1hQm9n9ZrbCzBb4fPxJZvaumS00swmZqktEJN9YpuZRm9kPgbXAQ865PkkeuxfwGDDIObfKzHZyzq3ISGEiInkmYz1q59wMYGXT28zsW2b2nJnNNbNXzWzv0F1nAXc651aFnquQFhEJyfYY9VjgPOdcf+BPwF2h278NfNvMZprZLDM7Ost1iYgEVodsvZGZdQG+B0wys/DNnZrUsRdwGLAbMMPM9nXO1WWrPhGRoMpaUOP13uucc31j3LcceMM51wAsMbMP8IJ7dhbrExEJpKwNfTjn1uCF8C8AzLN/6O4qvN40ZtYNbyjko2zVJiISZJmcnvcI8DrQ28yWm9nvgKHA78zsbWAhcFzo4dOAr8zsXWA6MNI591WmahMRyScZm54nIiLpoZWJIiIBl5GLid26dXO9evXKxEuLiBSkuXPnfumcK491X0aCulevXsyZMycTLy0iUpDM7ON492noQ0Qk4BTUIiIBlzSozay3mc1r8s8aMxuRhdpERAQfY9TOuUVAXwAzKwZqgCmZLUtERMJSHfo4HFjsnIs76C0iIumValCfAjwS6w4zG2Zmc8xsTm1tbdsrExERIIWgNrOOwGBgUqz7nXNjnXOVzrnK8vKYUwFFRKQVUulR/wR4yzn3RaaKERHJW7fdBqNGZeSlU1nwcipxhj1ERNqtTz+Fiopoe/TotL+Frx61mW0L/Bh4Iu0ViIjkq/PPbx7Sn3+ekbfxFdTOuXXOuR2dc6szUoWISD753//AzBvuALj5ZnAOdt45I2+XzRNeRETym3Nw8skwqcmcitWrYbvtMvq2WkIuIuLH3LlQVBQN6X/9ywvuDIc0qEctIpJYYyP84Afw3/967Z12gmXLoFOnxM9LI/WoRUTiefFFKC6OhvQzz8AXX2Q1pEE9ahGRrTU0wF57wceh3TL69YPZs73QzgH1qEVEmpo0CTp2jIb066/DW2/lLKRBPWoREc+6dbD99l5vGuCYY+Dpp71peDmmHrWIyN13Q5cu0ZBeuBCmTg1ESIN61CLSnn31FXTrFm0PGwb33JO7euJQj1pE2qdrrmke0h9/HMiQBvWoRaS9+eQT6Nkz2r7ySi+0A0xBLSLtxznnNO8119Y271UHlIY+RKTwvfeed2EwHNJ33OEt/86DkAb1qEWkkDkHxx3nTbMDby50XZ03wyOPqEctIoVp1ixvE6VwSE+cCJs3511Ig3rUIlJotmyBgw7yVhOCd+Hwf//zVhvmKfWoRaRwPPccdOgQDen//MebdpfHIQ3qUYtIIdi4EXbf3dvZDuCQQ+C117yhjwJQGJ9CRNqvhx+GbbaJhvTs2d62pAUS0qAetYjkqzVroGvXaPuEE7yd7wKyP0c6+T2FvMzMJpvZ+2b2npkdkunCRETiuuWW5iG9aBFMnlyQIQ3+e9S3As855040s45A5wzWJCIS24oVzU/6Pu+86EngBSxpj9rMugI/BO4DcM5tcs7VZbguEZHmLr20eUgvX94uQhr8DX3sAdQC48ys2szuNbNtWz7IzIaZ2Rwzm1NbW5v2QkWknVq61BvSGD3aa19/vbfisKIip2Vlk5+g7gAcANztnOsHrANGtXyQc26sc67SOVdZXl6e5jJFpF064wzYY49oe+VKuOyynJWTK36Cejmw3Dn3Rqg9GS+4RUQy4513vF70gw967X/+0+tFb799buvKkaQXE51zn5vZJ2bW2zm3CDgceDfzpYlIu+McHHkkvPCC1+7SxbuAWFqa27pyzO+M8POAh83sHaAv8JeMVSQi7VN4JWE4pKdMga+/bvchDT6n5znn5gGVmS1FRNqlzZthv/28PaMBeveGBQu8PTsE0BJyEcmlp56CkpJoSL/8Mrz/vkK6Bf00RCT76uuhe3dYvdprDxwIL75YsCsL20o9ahHJrnHjoHPnaEjPmwcvvaSQTkA9ahHJjrq65tPrhg6F8eNzVk4+UY9aRDLvhhuah/TixQrpFKhHLSKZ89lnsOuu0fbIkV5oS0oU1CKSGRdeCH//e7T9+efNN1US3zT0ISLp9eGH3oXBcEjfeKO34lAh3WrqUYtIejgHp54KEydGb1u9GrbbLnc1FQj1qEWk7d56y1v+HQ7phx7yglshnRbqUYtI6zU2wo9+5O3TAdCtG3zyiXfYrKSNetQi0jrTp0NxcTSkp06F2lqFdAaoRy0iqWlo8DZOWrLEa++/P8yd64W2ZIR61CLi3+TJ0LFjNKRnzvSWgCukM0o9ahFJbt062GEH2LTJa//0p95Qh/bnyAr1qEUksXvu8U5aCYf0ggXwzDMK6SxSj1pEYvvqK28WR9iZZ3pnF0rWqUctIlv785+bh/THHyukc0g9ahGJWr4cevSItq+4Aq69Nnf1CKCgFpGwc8+Fu++Otmtrm/eqJWd8BbWZLQW+BrYAm51zOuhWpFC89x5897vR9u23w/DhuatHtpJKj3qgc+7LjFUiItnlHPz85/Dkk17bDNas8WZ4SKDoYqJIe/TGG94mSuGQfuQRb98OhXQg+e1RO+B5M3PAPc65sS0fYGbDgGEAPXv2TF+FIpI+W7bAwQd7S77Bu3D44YfeakMJLL896u875w4AfgL8wcx+2PIBzrmxzrlK51xleXl5WosUkTSYNg06dIiG9PPPw7JlCuk84KtH7ZyrCf17hZlNAQ4CZmSyMBFJk40bYY89vPMLwetR//e/3tCH5IWk/6XMbFsz+0b4z8CRwIJMFyYiaTBhgrftaDik33wTZs1SSOcZPz3qnYEp5q3r7wBMcM49l9GqRKRtvv66+ekqxx/v7Xyn/TnyUtKgds59BOyfhVpEJB1uuw3OPz/afv99b/9oyVtamShSKGprYaedou3hw73FK5L3NFAlUgguv7x5SC9frpAuIApqkXy2dKk37vyXv3jta6/1VhxWVOS0LEkvDX2I5Kvf/hbGjYu2V66E7bfPXT2SMepRi+Sb+fO9XnQ4pMeO9XrRCumCpR61SL5wDo4+2ltRCFBaCl9+CZ0757YuyTj1qEXywcyZ3iKVcEg//jisX6+QbifUoxYJss2boW9fWLjQa++1l/fnkpKcliXZpR61SFA9/bQXyOGQnj4dPvhAId0OqUctEjQbNkD37lBX57UPOwxeeknLv9sx9ahFguTBB72LhOGQrq72etIK6XZNPWqRIFi9GsrKou3TToOHH85ZORIs6lGL5NoNNzQP6Q8/VEhLM+pRi+TK5597Y9FhF10EN96Yu3oksBTUIrlw0UVw883R9mefwS675K4eCTQNfYhk04cfehcGwyF9ww3eikOFtCSgHrVItpx2GjzySLRdVwddu+asHMkf6lGLZFp1tdeLDof0Aw94vWiFtPikHrVIpjQ2wsCBMGOG195hB6ip8Q6bFUmBglokE15+2QvpsKefhmOPzVk5kllV1TWMmbaIT+vq2bWslJFH9WZIv/Qd3uA7qM2sGJgD1Djn9H+cSCwNDfCd78DixV57333hrbegg/pEhaqquoZLn5hPfcMWAGrq6rn0ifkAaQvrVMaozwfeS8u7ihSiJ56Ajh2jIf3aa/DOOwrpAjdm2qJISIfVN2xhzLRFaXsPX0FtZrsBxwD3pu2dRQpFeF/oE07w2kcd5Y1PH3pobuuSrPi0rj6l21vDb4/6FuBioDHeA8xsmJnNMbM5tbW16ahNJPjGjoVtt4X60F/K+fPhuee0iVI7smtZaUq3t0bSoDazY4EVzrm5iR7nnBvrnKt0zlWWl5enrUCRQFq50gvjs8/22r/9rTflrk+f3NYlWTfyqN6UlhQ3u620pJiRR/VO23v46VEfCgw2s6XAo8AgMxuftgpE8s3118OOO0bbS5bAffflrh7JqSH9Kvjr8ftSUVaKARVlpfz1+H3TOuvDnHP+H2x2GPCnZLM+Kisr3Zw5c9pWmUjQ1NTAbrtF25dd5oW2SBqY2VznXGWs+3Q5WnIm03NP02r4cLjzzmh7xQrQEJ9kSUpB7Zx7GXg5I5VIu5KNuadpsWgR7L13tH3rrfDHP+auHmmXtNeH5EQ25p62iXPw8583D+k1axTSkhMKasmJbMw9bbXZs6GoCKqqvPaECV5wf+MbOS1L2i+NUUtO7FpWSk2MUE7n3NOUNTbCgAFeUAPsuqs3o6Njx9zVJIJ61JIj2Zh7mpLnn4fi4mhIT5vmzfJQSEsAqEctORG+YJjzWR+bNsE3v+mFMsCBB8KsWd7Qh0hAKKglZ4b0q8jtDI9HH4VTT42233gDDjood/UEXF5NpywwCmppf9aubX5hcMgQb+c77c8RV95MpyxQ+v1O2pc77mge0u+9B1OmKKSTCPx0ygKnHrW0D7W1sNNO0fbvfw933ZW7evJMoKdTtgMKail8V1zRfE+OTz5pvmdHgAVlXDiQ0ynbEQ19SOH6+GNvSCMc0n/+s7dwJY9C+tIn5lNTV48jOi5cVV2T9VoCN52ynVFQS2E680zo1Sva/uor+L//y1k5rRGkceFsbOUp8WnoQwrLggXegbJh//hHdHP/PBO0ceGcT6dsxxTUUhCq3lrOzqcezyEfeCsLt3TqRPHKld5ZhnlK48ISpqEPyXszHniSIf17REL6nCGX0mdkFVWLVuW4srbRuLCEqUct+WvLFujXjx/O9xZeLC3rzhFn3s3m4g4QGsvN51/VA7PMXnJOQS15p6q6htdufZAbH7w8ctupp/yF13ffr9njCmGOr8aFBRTUkmeemrWYHw06gCH1awB4Y7d9OPW0v9JoW4/iaSxXCoWCWvLHQw8x+Ne/jjSP+fUtLNxlTwAMaHpMs8ZypZAoqCX4Vq+GsrJI88nv/IjzB49s9hCHN7dXY7lSiJIGtZltA8wAOoUeP9k5d1WmCxMB4Kab4E9/ijRPuugh3uyww1YPqygrZeaoQdmsTCRr/EzP2wgMcs7tD/QFjjazARmtSuTzz73l3+GQvuACcI7Thg7SlDVpd5L2qJ1zDlgbapaE/nHxnyHSRiNHwo03RtuffgrduwOasibtk68xajMrBuYCewJ3OufeiPGYYcAwgJ49e6azRmkvFi+GPfeMtv/2N7j44q0epilr0t74WpnonNvinOsL7AYcZGZ9YjxmrHOu0jlXWV5enuYypeANHdo8pFetihnSIu1RSkvInXN1wHTg6IxUI+3PvHneWPSECV573DhvK9ImszxE2js/sz7KgQbnXJ2ZlQI/Bv6W8cqksDkHAwfCK6947bIybyy6VItURFryM0bdHXgwNE5dBDzmnJua2bKkoL3yChx2WLT95JMweHDWywjK6SkiyfiZ9fEO0C8LtUgBahqGPb7RkWfHnk2XZUu8O/fZxxv66JD9dVc6VVvyibY5lYxpepTUkR/8lxlXHBkN6Vdf9Tb5z0FIQ7BOTxFJRkvIJWPGTFuEW7+Od28fSueGjQDM6NWPS4eNYeb3v5/T2oJ2eopIIgpqyZgfvFLF6Oduj7SP+u0dLCrvha3ekMOqPDo9RfKJhj4k/VatArNISE/uczi9LpnKovJeQDDCUKenSD5Rj1rarOkFw1HVT3D28/dH7jt8+AMs3rZbpB2UMNRSdMknCmppk/AFw+1WfsGSu86I3L7oN8Ppff/tnBfgKXBaii75QkFdgLI5P3jMtEVc/O+7+M3cpyO39R8+nm0qujOT3IVhNn8Gmo8tmaagLjBZnR+8aBEzLz080rzm8LMYV3kcAJbD2RPZ/BloPrZkgy4mFpiszA92Dk48EfbeO3LTPiMei4Q0tP6CYVV1DYeOfok9Rj3DoaNfoqq6JuXXyOYcac3HlmxQj7rAZHx+8Jw5cOCB0eZ1t/HLDXs1C6vWXjBMV+80m3OkNR9bskE96gITryfb5ilxjY0wYEA0pHfZBTZsoPLy8/jr8ftSUVaK4R2J9dfj923Vr/3p6p1m7GeQ4/eS9ktBXWAyMj/4hReguBjeCJ0X8e9/w2efQadOgNfbnTlqEEtGH8PMUYNaPTabrt5pNudIaz62ZIOGPvJQolkGaZ0fvGmTt5n/J5947f79vbAuLk78vFZK12rBbM6R1nxsyQbzjkRMr8rKSjdnzpy0v24QpWtqlt/XaTmOC14PrrXDDXFNnAinnBJtz5oFBx+cvtePIWufTSSAzGyuc64y5n0K6tZLV7DEeh3DO0G4okVoHzr6pZi9zoqyUmaOGtTqzxKxdi107eqNSQMMHkzVVXcy5vkPYn6JpHsOseYkS3uloE6TliGyftNmVq1v2OpxqYZmvPANaxr+e4x6JuYR8AYsGX2M7/eM6c47YfjwaPvdd6nasN1WXyIlxca2HTtQV98Q+UKJVauI+JcoqDVG7VOsqWPxpHrxK9njwzMfhvSrSGkc13fv9MsvoemBxOecA3ffDcCY0S9tNROjYYujrt77gmr5pdG01iBTz13yiWZ9+BRr6lg8qV788vP4cJj7nWXQdNN+R3RO8lYLSK68snlIL1sWCemm75uKoM8h9v2zEQkIBbVPfsOnNVOzYoVvS+EwH9Kvotm85bLSErYpKeKCifOareRLOid52TLv9O9rr/XaV1/trTjs0SPm+6airHMJkJ5Vhpmg1YSSbxTUPsULrLLSkjYv9mgavvEM3Lu82eNnjhrE30/uy8bNjaxa37BVzzDhnORhw2D33aM3fvklXHVVzMf7+RJpyblg91q1mlDyTdIxajPrATwE7Iw3JDnWOXdrpgsLmpFH9Y45w+Pqwfu0eWyz6XhpsRlbYlzgnf5+7Va3JeoZxhrL3vPLZbxw37nRG+6+2xuPTqDpPOFE4/JNra5vSFhbrseCdbqL5Bs/PerNwEXOue8CA4A/mNl3M1tW8LQccmjLUummWvY8Y4U0xO7tJeoZNusJO8e4SVdFQ7qkxJuGlySkw8I9+EQ9/qZ2LSvNea810bCLVhNKvknao3bOfQZ8Fvrz12b2HlABvJvh2gKnrXsrx5pp4PciZazeXqKeYbjOZ8c+wdh//DF656RJ3s53CWor61yCc17PuOmMiFi/VbQUDrx4PfBs9FqTbe6k1YSSb1KaR21mvYAZQB/n3JoW9w0DhgH07Nmz/8cff5zGMvNfrEUtJUVGQ2Pyn39pSTEn9K9g+vu1zYIFiLtQpsd2HZn64Ai6fhD6Pt1jD1i0yOtN+6it5fuHf3uoqq7hosfejtnzLzbjppP2jzzOz2KgTEyTy/iiIJEMSDSP2vfFRDPrAjwOjGgZ0gDOubHOuUrnXGV50+leAsQeT04U0sVmkSGWE/pX8PjcmmYX5i6YOI8RE+fRqUMR24dmWYRD+rDFs3n18iOjIf3ii/DRRzFDGuCapxcm7CU3nRExpF8FjXG+3Buda7bnSLKhokxdcMz1sItIuvla8GJmJXgh/bBz7onMlhRcben9pRISJcXGmBP3b7ZsvGWQhqOyrr6B0pJiykpLWP/1el6/69fsWO99j76523e58Pe38tqg+L3IquqamKsrW6qpq6equialRTfJhooydcFRFwul0PiZ9WHAfcB7zrmbM19SMF1RNZ+HZy2LBGTLcc+WIT5w7/JmQxVdS0siq/mSatFh9bNy8ejq//D3Z6L/eY799S0s2GVPbM3GhF8wqcwdDn/eeDNgUr0Yl6meb7rqEwkKPz3qQ4FfAvPNbF7otsucc89mrKqAqaquaRbSYU2HBFpevBo/a1nkcTV19ZQUm+/3a2h0XP3UwkiYxushAnTZuJ4Ft5wUaT+99w84b/DF3mIWvMUniS6spRKK4c8bHudt69hypnq+ulgohcbPrI/X8IY/AyvT+zaMmbYo5kZI4PX+/MzcaNiS2uZXdfUNkaGGgXuXx/yi+N2bU/i/6fdF2oeddQ9Ld4h+7tKSYpwj4fBCoi+BWMLBno7TxTPZ883V6ecimZD3mzJl4xToRL3ORHOG2yrcW398bk2zkO62bhVz7vhlpH1//8H8+YhhzZ4b3h71gonzYr52071DYoXlNiVFMceu0znOq56viD95H9TZWAEXb3zZIOGc4baK1Vsf9fI4znnj8Uj7wD88RG2XHbZ67rqNm4HkwwvxwhK2nvqXiXHedPd8tSueFKK8D2o/F6SS/eVNdH9VdQ1fh0KvpaEDekYel2whSGt0LS2JhGyPus959Z4zI/eN/tEZrB1xIV82GQtvqq6+gRGh3nSsPaObBm6isMyn0MvGb1ciuZD3QZ2sx5jsL2+y+695eiFb4sx3Hj9rGeNnLWP7ziUc0LMrsz5aFXcJeGus27QZA26cehMnLJweuX2/8x/l69IubNNiSCQeR/wTYxLJt3HeIO8vItIWeR/UyS5IJfvLm+x+P3OMV61vYObilWn4NM3t+dli/j0uuvx75E/+yKT9jvQaMS4SJhIO6fCMjWTTCROFuZ/l5rmghS5SqPI+qJNdkEr2lzfR/TnbktM5Jjx6Od9b9g4Aazp25sDh/2JjSac2vWz4s8b6LaLldMJ4QwYtn9v0iyzXQw1a6CKFKu+DGhL/ip7sL2+i+3OxkfxBnyzgsQmjIu2zjr+C/+w1oNljSoqNkiJjfUNjSq8d/sx+phPGGzJI9txcDjVooYsUqoI/OCDZlpaJ7s/mr8zFjVt48Z9nR0L6fzv24Fsjn9wqpAE2NzpfY9NNNf3Mfj9XywuyyQ7hbfq8XJzukqmtaEVyrV2cQu531kdNk437y0pLWLOhAR+b27XZkR+8ztgp10favzhtNLN79Gn16y0dfUzCz+w3cMOKQlci/fbfy0pL2Li5MenOeSISlWj3vHYR1H4k2+rTjyIjpWDv1LCRt24fyrYNGwB4bff9Of3k6yLLv1uj2IzFf/1pwsdUVddwwcR5KffK/Ui0WEbbjIrEl5ZtTgtdKqeMx5NKSJ/09vMsuvmESEgf/ZvbOf2U69sU0hD/hJimhvSrYOiAnlvtC9Cad96+cwllpSXNhhrq4syU0ewLkdYpiIuJifhdqZatENluw1reufWUSPvxPoO46JgL0/b6FU3mjyf63NcN2ZfK3XeIuSJxRJxl57HeK1YPOZenu4gUooIO6lRWqqW6OVFrnPv6Y1w846FI+/tn38vysl3S9vrhC4Z+P3fL2TLh56XyXrFo9oVIehV0UKeyUi3eDnXpsNPXX/HmXb+OtO8++ET+dtgZaX2PYjNO6O8Fb6yDBlp+7tac31haUsSGhsakC1u02ZJIehVMUMcKHr8r1aqqa7baoS5drnrhHn4z9+lIu//w8Xy1bVna32eLczw+t4bK3XdI+rnj9bgThfTpA3py3ZB9fdeTb8vPRYKsIC4mxjt7r2tp7DMCHTSb25uOC4kt9VpZw9K/HRsJ6WsHnUmvS6ZmJKTDwr3meGPBiRa81DdsoTjOhcyKstKUQlpE0qsgetTxgmebkiKKiyzmpkpNx23TeiHROe58cjTHLJoZuanPiMdY26lz+t4jgU/r6vn7yX0TjhHH+7xbnKO0pFhjyyIBUxA96njBU7e+gcYEc+bqG7YwYuI8ito4JS6sz+cfsvSGn0VCesSxF9HrkqmtCumSIlI6vits17LSpCv04vW4w4/Tyj6RYCmIHnWi/Tr8zORo69ak5hqZPP5i+n/6PgC1ncs49Pfj2NQh9tCLH43OuOkX+3P1Uwt9H4rbtPebaIw41qwMw/stY8y0RbrwJxIwBdGjjrdfR68dMz9v93tL57HkhsGRkD7jxKs58LzxbQppiH55bNyceOF2aUlRyr3fpj1uaH6wQHhIKGc7B4rIVpIuITez+4FjgRXOOV8bUORiCXms/ZXHxzn9JB06bNnMy2OHsduaFQAs2PlbDP7VzTQWFSd5pj/FZuzSdZukvxFUNFmo0prpcPH2/dByb5HsSrSE3M/QxwPAHcBDSR4XGOs2bmbi7E8y9vo/ff817npydKT989NvpLpi77S+xzfLO/PhinVJH1dTV8/ISW+DRU86T7YvdNMvtUSnq4tIMCQNaufcDDPrlYVaWq3lvGC/Y7qpKt20gfm3nEQH5w1HvPCtAznzhCvbvD9HLP9bsS6yk18yDTEumMZb2ON38ykt9xYJjrRdTDSzYcAwgJ49e6brZX3JxDzolk6vfpbrnr8r0j7id3fxYbfMfs62XuSM1Sv287PSlDyRYElbUDvnxgJjwRujTtfr+pHJX9PL6tcw77bTIu0J+x/NZUcPz9j7pVOsXnGin5WFnqNZHyLBUtDT89pqxGsPM2LmI5H2Ib8fx2fblaf9fdqqpMiajVFD/F5xvJ+VLh6KBFdBTM8buHd6w7P7mlqW/u3YSEjf+r1T6XXJ1ECGtAEnH9SDMSfu72uhSrKjyUQkeJL2qM3sEeAwoJuZLQeucs7dl+nC/KqqruHhN9I3De/6aXcwdN5zkXa/8x5mVeeuaXv9RLbtWEyjY6sl3InGlB0w/f1arhvifw41aGc7kXziZ9bHqdkoJBVV1TVc8/TCmMc9tdaeXy7jhfvOjbSv+PHvGX/AMWl7/WRKS4q5/ufexkexth9NNLST6hi9drYTyS95N0ZdVV3DRZPejrnRUqs4x72P/5kjFs8GoKGomP3On0h9x23S8/o+bN+5hKt+tk8kPGOFaKIpdZpKJ1LY8iqoq6prfB8T5Ue/mveZMv5PkfYfBl/CM9/5Qdpe348io1lIxxK+L9a+HxpfFil8eRPUVdU13gq8NChq3MJTD11Iny8WA7B8u50YOOweGorbtj9HazQ6Eq4iDAsPV/g9A1JECkfeBPXlU+bHXIGXqsMWz+GByVdH2qedfB3/7dW3za/bFvFWEcai8WWR9icvgnroP19n3aa2rTzsuLmBmXf/hvL1dQDM3XVvTjz9BpwFY4ai9tYQkXgCH9RV1TXMXLyyTa9x3MLp3Dr1pkj7Z7/6O/O779XW0tJKFwRFJJ7AB/XVTy1s9XO7bFzPgltOirSn9v4+w4+7JCObKLWFLgiKSCKBDuqq6ppW74T329lPcuVL/4y0B551D0t2CMbYbkmR0WWbDtStb9AFQRFJKtBBPWbaopSfs+O6OubecXqkPa7/z7jmiLPTWVbKtu9cQueOHTRTQ0RaJbBBXVVdk/JGSxe/8gDnzpocaR907oOs+MaO6S4tJSVFlnSetIhIIoEM6lQXtuxW9zmv3XNmpH3DD3/FXYeclOAZmVNk3txogLLSEq4erJAWkbYJXFCnGtI3PXMzJyx4KdLe7/xHWbNNlwxUllxpSbHvA2ZFRPwKVFBXVdcwcrK/1Yfla1cy+85fRdoXH/1HHtv/yEyVFlf4BO8KjT2LSIYEKqgvnzK/2eb3MTnH8Qtf4soXvRkdazuW0n/4eDaWdMpobWWlJayub6BraQlmaMaGiGRNYILaz+rDitUruH7anRy2ZC5zKr7DJT/5I4t37JHRugwYOqAn1w3ZN6PvIyISTyCCOtnqQ3ONnF79LJe88iDmHFcecTb/OuCYjC//brn9qIhILgQiqBPNl/7mV8sZ/dxtHLT8XWb06sdlRw9neded0/r+23cuYUPDFuobGiNtBbSIBEUggjrWfOkOWzZz1uwpjHhtAvUlnbjopxfweJ9BaV3+rVkaIpIPAhHULf3inf8w5t+3AvBM70O5+ohzqO2yfVpeu6KsVCsERSSvBCqot9uwlnduPSXSHv2jM/jHgBPT+h4zRw1K6+uJiGSar6txZna0mS0ysw/NbFSmimka0j84+96UQ7rYjNMH9KSsNPZJLfFuFxEJsqQ9ajMrBu4EfgwsB2ab2VPOuXfTXcz5x15Ej9VfcMf3Tkn+4JBYy7Qrd9+BkZPebnYiTEmRcfXgfdJar4hINvgZ+jgI+NA59xGAmT0KHAekLaiLDbY4eHKfgb6fc8vJfeOOL4dv19mCIlII/AR1BfBJk/Zy4OCWDzKzYcAwgJ49e6ZUxE0n9U1pf4/TB/RMGro6W1BECkXaVow458Y65yqdc5Xl5eUpPXdIvwpuObkvFaHjqIrizMArMi+ktUpQRNoTPz3qGqDpOu3dQrellXrAIiKx+elRzwb2MrM9zKwjcArwVGbLEhGRsKQ9aufcZjMbDkwDioH7nXOtP3FWRERS4mvBi3PuWeDZDNciIiIxZHb7ORERaTMFtYhIwJlzSU5Uac2LmtUCH/t8eDfgy7QXkVmqOfPyrV5QzdmSbzX7rXd351zMuc0ZCepUmNkc51xlTotIkWrOvHyrF1RztuRbzemoV0MfIiIBp6AWEQm4IAT12FwX0AqqOfPyrV5QzdmSbzW3ud6cj1GLiEhiQehRi4hIAgpqEZGAy2lQZ+uIr3Qxs/vNbIWZLch1LX6YWQ8zm25m75rZQjM7P9c1JWNm25jZm2b2dqjma3Jdkx9mVmxm1WY2Nde1+GFmS81svpnNM7M5ua7HDzMrM7PJZva+mb1nZofkuqZEzKx36Ocb/meNmY1o1Wvlaow6dMTXBzQ54gs4NRNHfKWLmf0QWAs85Jzrk+t6kjGz7kB359xbZvYNYC4wJOA/YwO2dc6tNbMS4DXgfOfcrByXlpCZXQhUAts5547NdT3JmNlSoNI5lzcLR8zsQeBV59y9oZ08Ozvn6nJcli+hvKsBDnbO+V0MGJHLHnXkiC/n3CYgfMRXYDnnZgArc12HX865z5xzb4X+/DXwHt6JPYHlPGtDzZLQP4G+4m1muwHHAPfmupZCZWZdgR8C9wE45zblS0iHHA4sbk1IQ26DOtYRX4EOkXxmZr2AfsAbOS4lqdAwwjxgBfAf51zQa74FuBhozHEdqXDA82Y2N3SMXtDtAdQC40JDTPea2ba5LioFpwCPtPbJupjYDphZF+BxYIRzbk2u60nGObfFOdcX7zShg8wssMNMZnYssMI5NzfXtaTo+865A4CfAH8IDesFWQfgAOBu51w/YB0Q+OtaAKFhmsHApNa+Ri6DOitHfLV3oXHex4GHnXNP5LqeVIR+tZ0OHJ3jUhI5FBgcGvN9FBhkZuNzW1Jyzrma0L9XAFPwhiKDbDmwvMlvV5Pxgjsf/AR4yzn3RWtfIJdBrSO+Mix0Ye4+4D3n3M25rscPMys3s7LQn0vxLja/n9OiEnDOXeqc28051wvv/+GXnHOn57ishMxs29DFZULDB0cCgZ7J5Jz7HPjEzHqHbjocCOxF8RZOpQ3DHuDzhJdMyMcjvszsEeAwoJuZLQeucs7dl9uqEjoU+CUwPzTmC3BZ6MSeoOoOPBi6Sl4EPOacy4spb3lkZ2CK9z1OB2CCc+653Jbky3nAw6GO3UfAb3JcT1KhL8IfA2e36XW0hFxEJNh0MVFEJOAU1CIiAaegFhEJOAW1iEjAKahFRNoo1Q3bzOykJpulTUj6eM36EBFpm1Q2bDOzvYDHgEHOuVVmtlNo4VFc6lGLiLRRrA3bzOxbZvZcaD+VV81s79BdZwF3OudWhZ6bMKRBQS0ikiljgfOcc/2BPwF3hW7/NvBtM5tpZrPMLOkWCTlbmSgiUqhCG6F9D5gUWgEK0Cn07w7AXnirnHcDZpjZvom2bVVQi4ikXxFQF9oFsqXlwBvOuQZgiZl9gBfcsxO9mIiIpFFoO+ElZvYL8DZIM7P9Q3dX4fWmMbNueEMhHyV6PQW1iEgbhTZsex3obWbLzex3wFDgd2b2NrCQ6AlW04CvzOxdvG18Rzrnvkr4+pqeJyISbOpRi4gEnIJaRCTgFNQiIgGnoBYRCTgFtYhIwCmoRUQCTkEtIhJw/w/XX+bAyPB/HwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction\n",
    "plt.scatter(y_test, y_test_pred)\n",
    "# Perfect prediction\n",
    "plt.plot(y_test, y_test, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Density'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = y_test.values - y_test_pred[:,0]\n",
    "sns.distplot(errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Prediction on a new object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[277236.12]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_house = df[selected_features].iloc[0]\n",
    "single_house = scaler.transform(single_house.values.reshape(1,len(single_house)))\n",
    "model.predict(single_house)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    471332.5625\n",
       "1    597283.6250\n",
       "2    491034.8125\n",
       "3    320120.1250\n",
       "4    171197.6250\n",
       "dtype: float32"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = model.predict(X_test)\n",
    "test_predictions = pd.Series(test_predictions.reshape(len(X_test),))\n",
    "test_predictions[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**4. Using checkpoint to save the best model**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Using checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                540       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,431\n",
      "Trainable params: 2,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(99)\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "# compile\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# using checkpoint to save the best model\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('kc_house.h5', save_best_only=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 185543933952.0000 - val_loss: 104456536064.0000\n",
      "Epoch 2/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 88374444032.0000 - val_loss: 95162736640.0000\n",
      "Epoch 3/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 79075082240.0000 - val_loss: 84753637376.0000\n",
      "Epoch 4/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 69416845312.0000 - val_loss: 74298253312.0000\n",
      "Epoch 5/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 60204171264.0000 - val_loss: 65077174272.0000\n",
      "Epoch 6/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 54019432448.0000 - val_loss: 59877986304.0000\n",
      "Epoch 7/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 50591698944.0000 - val_loss: 57032880128.0000\n",
      "Epoch 8/100\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 48742367232.0000 - val_loss: 55006658560.0000\n",
      "Epoch 9/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 47392854016.0000 - val_loss: 53508894720.0000\n",
      "Epoch 10/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 46291689472.0000 - val_loss: 52392857600.0000\n",
      "Epoch 11/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 45125926912.0000 - val_loss: 51071836160.0000\n",
      "Epoch 12/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 44015284224.0000 - val_loss: 49934909440.0000\n",
      "Epoch 13/100\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 43085922304.0000 - val_loss: 48743510016.0000\n",
      "Epoch 14/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 42119008256.0000 - val_loss: 48108666880.0000\n",
      "Epoch 15/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 41563807744.0000 - val_loss: 47048462336.0000\n",
      "Epoch 16/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 41054863360.0000 - val_loss: 46524940288.0000\n",
      "Epoch 17/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 40502464512.0000 - val_loss: 45655900160.0000\n",
      "Epoch 18/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 39905828864.0000 - val_loss: 44829724672.0000\n",
      "Epoch 19/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 39208071168.0000 - val_loss: 44092145664.0000\n",
      "Epoch 20/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 38678188032.0000 - val_loss: 43561295872.0000\n",
      "Epoch 21/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 38209064960.0000 - val_loss: 42689056768.0000\n",
      "Epoch 22/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 37679235072.0000 - val_loss: 42013650944.0000\n",
      "Epoch 23/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 37204451328.0000 - val_loss: 41502121984.0000\n",
      "Epoch 24/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 36820094976.0000 - val_loss: 40950312960.0000\n",
      "Epoch 25/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 36457369600.0000 - val_loss: 40217059328.0000\n",
      "Epoch 26/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 36239020032.0000 - val_loss: 39833554944.0000\n",
      "Epoch 27/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 35908362240.0000 - val_loss: 39388856320.0000\n",
      "Epoch 28/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 35629264896.0000 - val_loss: 39458795520.0000\n",
      "Epoch 29/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 35513511936.0000 - val_loss: 38876090368.0000\n",
      "Epoch 30/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 35256455168.0000 - val_loss: 38654566400.0000\n",
      "Epoch 31/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 35113771008.0000 - val_loss: 38358679552.0000\n",
      "Epoch 32/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 34918424576.0000 - val_loss: 37988671488.0000\n",
      "Epoch 33/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 34711396352.0000 - val_loss: 37627478016.0000\n",
      "Epoch 34/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 34622251008.0000 - val_loss: 37392637952.0000\n",
      "Epoch 35/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 34448138240.0000 - val_loss: 37080756224.0000\n",
      "Epoch 36/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 34242377728.0000 - val_loss: 36974354432.0000\n",
      "Epoch 37/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 34093115392.0000 - val_loss: 36777267200.0000\n",
      "Epoch 38/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33958230016.0000 - val_loss: 36462501888.0000\n",
      "Epoch 39/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33791363072.0000 - val_loss: 36511924224.0000\n",
      "Epoch 40/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 33670836224.0000 - val_loss: 36090949632.0000\n",
      "Epoch 41/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33524496384.0000 - val_loss: 35914305536.0000\n",
      "Epoch 42/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33338994688.0000 - val_loss: 35898503168.0000\n",
      "Epoch 43/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33284694016.0000 - val_loss: 35498557440.0000\n",
      "Epoch 44/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33172633600.0000 - val_loss: 35401154560.0000\n",
      "Epoch 45/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32990359552.0000 - val_loss: 35054325760.0000\n",
      "Epoch 46/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32944599040.0000 - val_loss: 34952667136.0000\n",
      "Epoch 47/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32804360192.0000 - val_loss: 34993360896.0000\n",
      "Epoch 48/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32683792384.0000 - val_loss: 34769154048.0000\n",
      "Epoch 49/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32638509056.0000 - val_loss: 34452062208.0000\n",
      "Epoch 50/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32530548736.0000 - val_loss: 34530758656.0000\n",
      "Epoch 51/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32438601728.0000 - val_loss: 34412007424.0000\n",
      "Epoch 52/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32442886144.0000 - val_loss: 34124234752.0000\n",
      "Epoch 53/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 32294533120.0000 - val_loss: 34417897472.0000\n",
      "Epoch 54/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 32186021888.0000 - val_loss: 34087761920.0000\n",
      "Epoch 55/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32110489600.0000 - val_loss: 33827889152.0000\n",
      "Epoch 56/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32021067776.0000 - val_loss: 33677000704.0000\n",
      "Epoch 57/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 31941330944.0000 - val_loss: 33661089792.0000\n",
      "Epoch 58/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 31904991232.0000 - val_loss: 34095036416.0000\n",
      "Epoch 59/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 31830378496.0000 - val_loss: 33583245312.0000\n",
      "Epoch 60/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31789936640.0000 - val_loss: 33339035648.0000\n",
      "Epoch 61/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31705456640.0000 - val_loss: 33326424064.0000\n",
      "Epoch 62/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31634178048.0000 - val_loss: 33215819776.0000\n",
      "Epoch 63/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31620212736.0000 - val_loss: 33134080000.0000\n",
      "Epoch 64/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31534174208.0000 - val_loss: 33102077952.0000\n",
      "Epoch 65/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31448807424.0000 - val_loss: 33181466624.0000\n",
      "Epoch 66/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31322589184.0000 - val_loss: 32931715072.0000\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31315056640.0000 - val_loss: 32922826752.0000\n",
      "Epoch 68/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31328894976.0000 - val_loss: 32811857920.0000\n",
      "Epoch 69/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31106355200.0000 - val_loss: 33354758144.0000\n",
      "Epoch 70/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31237888000.0000 - val_loss: 32721727488.0000\n",
      "Epoch 71/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31161513984.0000 - val_loss: 32913584128.0000\n",
      "Epoch 72/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31027474432.0000 - val_loss: 32636426240.0000\n",
      "Epoch 73/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31061237760.0000 - val_loss: 32990427136.0000\n",
      "Epoch 74/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30955388928.0000 - val_loss: 32647761920.0000\n",
      "Epoch 75/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30874832896.0000 - val_loss: 32428843008.0000\n",
      "Epoch 76/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30885675008.0000 - val_loss: 32461635584.0000\n",
      "Epoch 77/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30791743488.0000 - val_loss: 32555816960.0000\n",
      "Epoch 78/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 30732015616.0000 - val_loss: 32456914944.0000\n",
      "Epoch 79/100\n",
      "2767/2767 [==============================] - 3s 1ms/step - loss: 30702807040.0000 - val_loss: 32289372160.0000\n",
      "Epoch 80/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 30615758848.0000 - val_loss: 32220131328.0000\n",
      "Epoch 81/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 30585098240.0000 - val_loss: 32210571264.0000\n",
      "Epoch 82/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30504519680.0000 - val_loss: 32404088832.0000\n",
      "Epoch 83/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 30517864448.0000 - val_loss: 32167421952.0000\n",
      "Epoch 84/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 30461700096.0000 - val_loss: 32158400512.0000\n",
      "Epoch 85/100\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 30369406976.0000 - val_loss: 32201299968.0000\n",
      "Epoch 86/100\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 30385160192.0000 - val_loss: 32048785408.0000\n",
      "Epoch 87/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30289408000.0000 - val_loss: 32092485632.0000\n",
      "Epoch 88/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30328832000.0000 - val_loss: 32132173824.0000\n",
      "Epoch 89/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30268876800.0000 - val_loss: 32058667008.0000\n",
      "Epoch 90/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30198118400.0000 - val_loss: 31886032896.0000\n",
      "Epoch 91/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30209064960.0000 - val_loss: 31843749888.0000\n",
      "Epoch 92/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30122715136.0000 - val_loss: 31802294272.0000\n",
      "Epoch 93/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30055321600.0000 - val_loss: 32517928960.0000\n",
      "Epoch 94/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30072010752.0000 - val_loss: 31934926848.0000\n",
      "Epoch 95/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30042761216.0000 - val_loss: 31856146432.0000\n",
      "Epoch 96/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29986060288.0000 - val_loss: 31695581184.0000\n",
      "Epoch 97/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29949726720.0000 - val_loss: 31690057728.0000\n",
      "Epoch 98/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29932015616.0000 - val_loss: 31639853056.0000\n",
      "Epoch 99/100\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29881255936.0000 - val_loss: 31599816704.0000\n",
      "Epoch 100/100\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29841864704.0000 - val_loss: 31554889728.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train.values,\n",
    "                    validation_data = (X_valid, y_valid.values),\n",
    "                    batch_size=5,\n",
    "                    epochs=100,\n",
    "                    callbacks=[checkpoint_cb]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  103425.43875780707\n",
      "RMSE:  168600.27782831254\n",
      "R-squared:  0.7916459835323286\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict(X_test)\n",
    "# MAE\n",
    "print('MAE: ', mean_absolute_error(y_test, y_test_pred))\n",
    "# RMSE\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test, y_test_pred)))\n",
    "# R-square\n",
    "print('R-squared: ', explained_variance_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 30)                540       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,431\n",
      "Trainable params: 2,431\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(99)\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "class PrintValTrainRatioCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print(\"\\nval/train: {:.2f}\".format(logs['val_loss']/logs['loss']))\n",
    "        \n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(30),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "# using checkpoint to save the best model\n",
    "val_train_ratio_cb = PrintValTrainRatioCallback()\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('kc_house.h5', save_best_only=True)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   1/2767 [..............................] - ETA: 15:56 - loss: 262616727552.0000WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0011s vs `on_train_batch_end` time: 0.0028s). Check your callbacks.\n",
      "2764/2767 [============================>.] - ETA: 0s - loss: 164815781888.0000\n",
      "val/train: 0.61\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 164769202176.0000 - val_loss: 101328584704.0000\n",
      "Epoch 2/100\n",
      "2741/2767 [============================>.] - ETA: 0s - loss: 84077723648.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 84057309184.0000 - val_loss: 88905342976.0000\n",
      "Epoch 3/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 71754620928.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 71556120576.0000 - val_loss: 74888880128.0000\n",
      "Epoch 4/100\n",
      "2745/2767 [============================>.] - ETA: 0s - loss: 59434090496.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 59918680064.0000 - val_loss: 63816110080.0000\n",
      "Epoch 5/100\n",
      "2746/2767 [============================>.] - ETA: 0s - loss: 52469551104.0000\n",
      "val/train: 1.10\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 52487790592.0000 - val_loss: 57781596160.0000\n",
      "Epoch 6/100\n",
      "2741/2767 [============================>.] - ETA: 0s - loss: 48817295360.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 49248124928.0000 - val_loss: 55221682176.0000\n",
      "Epoch 7/100\n",
      "2736/2767 [============================>.] - ETA: 0s - loss: 47358185472.0000\n",
      "val/train: 1.13\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 47144325120.0000 - val_loss: 53193940992.0000\n",
      "Epoch 8/100\n",
      "2753/2767 [============================>.] - ETA: 0s - loss: 45482196992.0000- ETA: 0s - loss: \n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 45346430976.0000 - val_loss: 50974515200.0000\n",
      "Epoch 9/100\n",
      "2726/2767 [============================>.] - ETA: 0s - loss: 44119982080.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 43881197568.0000 - val_loss: 49312534528.0000\n",
      "Epoch 10/100\n",
      "2739/2767 [============================>.] - ETA: 0s - loss: 42692997120.0000\n",
      "val/train: 1.13\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 42825256960.0000 - val_loss: 48269303808.0000\n",
      "Epoch 11/100\n",
      "2750/2767 [============================>.] - ETA: 0s - loss: 41999962112.0000\n",
      "val/train: 1.13\n",
      "2767/2767 [==============================] - 8s 3ms/step - loss: 41863000064.0000 - val_loss: 47182299136.0000\n",
      "Epoch 12/100\n",
      "2732/2767 [============================>.] - ETA: 0s - loss: 41087700992.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 40979685376.0000 - val_loss: 46054928384.0000\n",
      "Epoch 13/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 40230260736.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 40082935808.0000 - val_loss: 44865777664.0000\n",
      "Epoch 14/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 39126740992.0000\n",
      "val/train: 1.13\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 39098691584.0000 - val_loss: 44367011840.0000\n",
      "Epoch 15/100\n",
      "2742/2767 [============================>.] - ETA: 0s - loss: 38412468224.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 38490947584.0000 - val_loss: 42998095872.0000\n",
      "Epoch 16/100\n",
      "2741/2767 [============================>.] - ETA: 0s - loss: 37897424896.0000\n",
      "val/train: 1.12\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 37901590528.0000 - val_loss: 42308325376.0000\n",
      "Epoch 17/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 37389512704.0000\n",
      "val/train: 1.11\n",
      "2767/2767 [==============================] - 7s 2ms/step - loss: 37318111232.0000 - val_loss: 41290166272.0000\n",
      "Epoch 18/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 36906491904.0000\n",
      "val/train: 1.10\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 36841656320.0000 - val_loss: 40597856256.0000\n",
      "Epoch 19/100\n",
      "2754/2767 [============================>.] - ETA: 0s - loss: 36212400128.0000\n",
      "val/train: 1.10\n",
      "2767/2767 [==============================] - 7s 3ms/step - loss: 36366688256.0000 - val_loss: 40057954304.0000\n",
      "Epoch 20/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 36082130944.0000\n",
      "val/train: 1.11\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 36007387136.0000 - val_loss: 39868047360.0000\n",
      "Epoch 21/100\n",
      "2745/2767 [============================>.] - ETA: 0s - loss: 35721351168.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 35748442112.0000 - val_loss: 39066124288.0000\n",
      "Epoch 22/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 35452805120.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 35388338176.0000 - val_loss: 38582710272.0000\n",
      "Epoch 23/100\n",
      "2741/2767 [============================>.] - ETA: 0s - loss: 35232096256.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 35096215552.0000 - val_loss: 38234771456.0000\n",
      "Epoch 24/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 34846887936.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 34836541440.0000 - val_loss: 37869551616.0000\n",
      "Epoch 25/100\n",
      "2726/2767 [============================>.] - ETA: 0s - loss: 34641907712.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 34604081152.0000 - val_loss: 37290434560.0000\n",
      "Epoch 26/100\n",
      "2764/2767 [============================>.] - ETA: 0s - loss: 34520424448.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 34498994176.0000 - val_loss: 37034037248.0000\n",
      "Epoch 27/100\n",
      "2733/2767 [============================>.] - ETA: 0s - loss: 34159187968.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 34229772288.0000 - val_loss: 36690493440.0000\n",
      "Epoch 28/100\n",
      "2765/2767 [============================>.] - ETA: 0s - loss: 33954959360.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33966772224.0000 - val_loss: 36902223872.0000\n",
      "Epoch 29/100\n",
      "2723/2767 [============================>.] - ETA: 0s - loss: 33967820800.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 33906688000.0000 - val_loss: 36351107072.0000\n",
      "Epoch 30/100\n",
      "2742/2767 [============================>.] - ETA: 0s - loss: 33722359808.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33642352640.0000 - val_loss: 36191789056.0000\n",
      "Epoch 31/100\n",
      "2759/2767 [============================>.] - ETA: 0s - loss: 33488756736.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 33526732800.0000 - val_loss: 35941994496.0000\n",
      "Epoch 32/100\n",
      "2756/2767 [============================>.] - ETA: 0s - loss: 33324419072.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 33337346048.0000 - val_loss: 35484749824.0000\n",
      "Epoch 33/100\n",
      "2767/2767 [==============================] - ETA: 0s - loss: 33135575040.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33135575040.0000 - val_loss: 35218513920.0000\n",
      "Epoch 34/100\n",
      "2752/2767 [============================>.] - ETA: 0s - loss: 33049782272.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 33073108992.0000 - val_loss: 34959372288.0000\n",
      "Epoch 35/100\n",
      "2731/2767 [============================>.] - ETA: 0s - loss: 33001166848.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32920938496.0000 - val_loss: 34707808256.0000\n",
      "Epoch 36/100\n",
      "2752/2767 [============================>.] - ETA: 0s - loss: 32756707328.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32713226240.0000 - val_loss: 34675200000.0000\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2752/2767 [============================>.] - ETA: 0s - loss: 32714364928.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32617936896.0000 - val_loss: 34530537472.0000\n",
      "Epoch 38/100\n",
      "2756/2767 [============================>.] - ETA: 0s - loss: 32605368320.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32514033664.0000 - val_loss: 34321502208.0000\n",
      "Epoch 39/100\n",
      "2746/2767 [============================>.] - ETA: 0s - loss: 32448397312.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32372404224.0000 - val_loss: 34413334528.0000\n",
      "Epoch 40/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 32275697664.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 32278044672.0000 - val_loss: 34124527616.0000\n",
      "Epoch 41/100\n",
      "2748/2767 [============================>.] - ETA: 0s - loss: 32216739840.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32151627776.0000 - val_loss: 33963270144.0000\n",
      "Epoch 42/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 32021915648.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 32007122944.0000 - val_loss: 33851412480.0000\n",
      "Epoch 43/100\n",
      "2750/2767 [============================>.] - ETA: 0s - loss: 31939018752.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31963539456.0000 - val_loss: 33653645312.0000\n",
      "Epoch 44/100\n",
      "2765/2767 [============================>.] - ETA: 0s - loss: 31885223936.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31875616768.0000 - val_loss: 33604603904.0000\n",
      "Epoch 45/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 31751194624.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31734831104.0000 - val_loss: 33361977344.0000\n",
      "Epoch 46/100\n",
      "2744/2767 [============================>.] - ETA: 0s - loss: 31603445760.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 31747946496.0000 - val_loss: 33296427008.0000\n",
      "Epoch 47/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 31550332928.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31630434304.0000 - val_loss: 33360918528.0000\n",
      "Epoch 48/100\n",
      "2748/2767 [============================>.] - ETA: 0s - loss: 31648610304.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 31521839104.0000 - val_loss: 33213239296.0000\n",
      "Epoch 49/100\n",
      "2733/2767 [============================>.] - ETA: 0s - loss: 31405346816.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 31509567488.0000 - val_loss: 32990484480.0000\n",
      "Epoch 50/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 31427887104.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31436197888.0000 - val_loss: 33156198400.0000\n",
      "Epoch 51/100\n",
      "2750/2767 [============================>.] - ETA: 0s - loss: 31176935424.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 31371722752.0000 - val_loss: 33246498816.0000\n",
      "Epoch 52/100\n",
      "2759/2767 [============================>.] - ETA: 0s - loss: 31444623360.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 31412514816.0000 - val_loss: 32828241920.0000\n",
      "Epoch 53/100\n",
      "2760/2767 [============================>.] - ETA: 0s - loss: 31294402560.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31277682688.0000 - val_loss: 33090834432.0000\n",
      "Epoch 54/100\n",
      "2758/2767 [============================>.] - ETA: 0s - loss: 31154384896.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 31167967232.0000 - val_loss: 33025542144.0000\n",
      "Epoch 55/100\n",
      "2764/2767 [============================>.] - ETA: 0s - loss: 31121881088.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 31112214528.0000 - val_loss: 32608358400.0000\n",
      "Epoch 56/100\n",
      "2756/2767 [============================>.] - ETA: 0s - loss: 30873501696.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 31033401344.0000 - val_loss: 32529717248.0000\n",
      "Epoch 57/100\n",
      "2759/2767 [============================>.] - ETA: 0s - loss: 31002204160.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30954432512.0000 - val_loss: 32527271936.0000\n",
      "Epoch 58/100\n",
      "2741/2767 [============================>.] - ETA: 0s - loss: 31050723328.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30920169472.0000 - val_loss: 33033261056.0000\n",
      "Epoch 59/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 30752974848.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30843643904.0000 - val_loss: 32473323520.0000\n",
      "Epoch 60/100\n",
      "2741/2767 [============================>.] - ETA: 0s - loss: 30772887552.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30821629952.0000 - val_loss: 32284880896.0000\n",
      "Epoch 61/100\n",
      "2752/2767 [============================>.] - ETA: 0s - loss: 30740103168.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30734940160.0000 - val_loss: 32324597760.0000\n",
      "Epoch 62/100\n",
      "2758/2767 [============================>.] - ETA: 0s - loss: 30710257664.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30652590080.0000 - val_loss: 32198883328.0000\n",
      "Epoch 63/100\n",
      "2765/2767 [============================>.] - ETA: 0s - loss: 30666164224.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30654668800.0000 - val_loss: 32147503104.0000\n",
      "Epoch 64/100\n",
      "2767/2767 [==============================] - ETA: 0s - loss: 30563885056.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30563885056.0000 - val_loss: 32131063808.0000\n",
      "Epoch 65/100\n",
      "2766/2767 [============================>.] - ETA: 0s - loss: 30471514112.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30469328896.0000 - val_loss: 32375961600.0000\n",
      "Epoch 66/100\n",
      "2748/2767 [============================>.] - ETA: 0s - loss: 30442244096.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30334730240.0000 - val_loss: 31983134720.0000\n",
      "Epoch 67/100\n",
      "2739/2767 [============================>.] - ETA: 0s - loss: 30331635712.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30338623488.0000 - val_loss: 31999686656.0000\n",
      "Epoch 68/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 30333126656.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30347235328.0000 - val_loss: 31911280640.0000\n",
      "Epoch 69/100\n",
      "2766/2767 [============================>.] - ETA: 0s - loss: 30111412224.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30107277312.0000 - val_loss: 32369532928.0000\n",
      "Epoch 70/100\n",
      "2754/2767 [============================>.] - ETA: 0s - loss: 30136989696.0000\n",
      "val/train: 1.05\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 30253496320.0000 - val_loss: 31894384640.0000\n",
      "Epoch 71/100\n",
      "2743/2767 [============================>.] - ETA: 0s - loss: 30219632640.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30185377792.0000 - val_loss: 32052254720.0000\n",
      "Epoch 72/100\n",
      "2739/2767 [============================>.] - ETA: 0s - loss: 30027069440.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 30029385728.0000 - val_loss: 31748857856.0000\n",
      "Epoch 73/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 30086135808.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 30067877888.0000 - val_loss: 32392364032.0000\n",
      "Epoch 74/100\n",
      "2756/2767 [============================>.] - ETA: 0s - loss: 29975816192.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 29957253120.0000 - val_loss: 31734482944.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100\n",
      "2752/2767 [============================>.] - ETA: 0s - loss: 29905819648.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29870923776.0000 - val_loss: 31613073408.0000\n",
      "Epoch 76/100\n",
      "2735/2767 [============================>.] - ETA: 0s - loss: 29856270336.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 29887883264.0000 - val_loss: 31646791680.0000\n",
      "Epoch 77/100\n",
      "2743/2767 [============================>.] - ETA: 0s - loss: 29862535168.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 29791559680.0000 - val_loss: 31756222464.0000\n",
      "Epoch 78/100\n",
      "2756/2767 [============================>.] - ETA: 0s - loss: 29768783872.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29731201024.0000 - val_loss: 31605450752.0000\n",
      "Epoch 79/100\n",
      "2753/2767 [============================>.] - ETA: 0s - loss: 29778837504.0000- ETA: 1s - \n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29700681728.0000 - val_loss: 31534155776.0000\n",
      "Epoch 80/100\n",
      "2743/2767 [============================>.] - ETA: 0s - loss: 29683380224.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29606473728.0000 - val_loss: 31431262208.0000\n",
      "Epoch 81/100\n",
      "2750/2767 [============================>.] - ETA: 0s - loss: 29645543424.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29575600128.0000 - val_loss: 31400099840.0000\n",
      "Epoch 82/100\n",
      "2762/2767 [============================>.] - ETA: 0s - loss: 29488293888.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29469014016.0000 - val_loss: 31560896512.0000\n",
      "Epoch 83/100\n",
      "2764/2767 [============================>.] - ETA: 0s - loss: 29410205696.0000\n",
      "val/train: 1.06\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29476677632.0000 - val_loss: 31371237376.0000\n",
      "Epoch 84/100\n",
      "2751/2767 [============================>.] - ETA: 0s - loss: 29242974208.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29407346688.0000 - val_loss: 31396745216.0000\n",
      "Epoch 85/100\n",
      "2747/2767 [============================>.] - ETA: 0s - loss: 29374554112.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29299056640.0000 - val_loss: 31366678528.0000\n",
      "Epoch 86/100\n",
      "2765/2767 [============================>.] - ETA: 0s - loss: 29246224384.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29293903872.0000 - val_loss: 31243063296.0000\n",
      "Epoch 87/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 29264158720.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29203421184.0000 - val_loss: 31376259072.0000\n",
      "Epoch 88/100\n",
      "2751/2767 [============================>.] - ETA: 0s - loss: 29234784256.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29222742016.0000 - val_loss: 31614062592.0000\n",
      "Epoch 89/100\n",
      "2734/2767 [============================>.] - ETA: 0s - loss: 29062246400.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29164351488.0000 - val_loss: 31349880832.0000\n",
      "Epoch 90/100\n",
      "2745/2767 [============================>.] - ETA: 0s - loss: 28974292992.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 6s 2ms/step - loss: 29071370240.0000 - val_loss: 31148417024.0000\n",
      "Epoch 91/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 29066842112.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 29070098432.0000 - val_loss: 31070015488.0000\n",
      "Epoch 92/100\n",
      "2749/2767 [============================>.] - ETA: 0s - loss: 28998227968.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 28952778752.0000 - val_loss: 31076218880.0000\n",
      "Epoch 93/100\n",
      "2750/2767 [============================>.] - ETA: 0s - loss: 28855230464.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 28870662144.0000 - val_loss: 31595964416.0000\n",
      "Epoch 94/100\n",
      "2734/2767 [============================>.] - ETA: 0s - loss: 28689096704.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 28856700928.0000 - val_loss: 31277889536.0000\n",
      "Epoch 95/100\n",
      "2757/2767 [============================>.] - ETA: 0s - loss: 28813410304.0000\n",
      "val/train: 1.09\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 28828157952.0000 - val_loss: 31300184064.0000\n",
      "Epoch 96/100\n",
      "2764/2767 [============================>.] - ETA: 0s - loss: 28782116864.0000\n",
      "val/train: 1.07\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 28769892352.0000 - val_loss: 30923462656.0000\n",
      "Epoch 97/100\n",
      "2755/2767 [============================>.] - ETA: 0s - loss: 28614248448.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 4s 2ms/step - loss: 28706613248.0000 - val_loss: 30942670848.0000\n",
      "Epoch 98/100\n",
      "2736/2767 [============================>.] - ETA: 0s - loss: 28746317824.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 4s 1ms/step - loss: 28677879808.0000 - val_loss: 30919550976.0000\n",
      "Epoch 99/100\n",
      "2763/2767 [============================>.] - ETA: 0s - loss: 28630026240.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 28614070272.0000 - val_loss: 30892810240.0000\n",
      "Epoch 100/100\n",
      "2754/2767 [============================>.] - ETA: 0s - loss: 28528119808.0000\n",
      "val/train: 1.08\n",
      "2767/2767 [==============================] - 5s 2ms/step - loss: 28529229824.0000 - val_loss: 30857459712.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train.values, \n",
    "                    validation_data=(X_valid, y_valid.values), \n",
    "                    batch_size=5, \n",
    "                    epochs=100,\n",
    "                    callbacks=[val_train_ratio_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'verbose': 1, 'epochs': 100, 'steps': 2767}\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]\n",
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    }
   ],
   "source": [
    "print(history.params)\n",
    "print(history.epoch)\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23427cbda00>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")\n",
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 273
    },
    "id": "VGOwsZjQcBVa",
    "outputId": "4bcec95b-b873-41c6-a514-1e191464f1c9"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 28283637760.00, Test score: 27232856064.00\n",
      "RMSE: 165023.803\n",
      "MSE: 27232855538.651\n",
      "MAE: 101594.192\n",
      "r2: 0.800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "\n",
    "model = keras.models.load_model('kc_house.h5')  # roll back to the best model\n",
    "\n",
    "# Train score, test score\n",
    "training_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "test_predictions = model.predict(X_test)\n",
    "print(\"Train score: %.2f\" % training_score + \", Test score: %.2f\" % test_score)\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, test_predictions)\n",
    "print(\"MAE: %.3f\"  % mae)\n",
    "      \n",
    "# r2 - coefficient of determination\n",
    "r2 = explained_variance_score(y_test, test_predictions)\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6jOKFUecc1wf",
    "outputId": "8fd4aa33-c456-46dc-f709-38a854790f7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[516705.38],\n",
       "       [602669.7 ],\n",
       "       [486389.  ]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new = X_test[:3]\n",
    "y_pred = model.predict(X_new)\n",
    "y_pred[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "woAMc1NrtPhj",
    "outputId": "92c0d3a7-30c9-4794-c69e-e84feca6c664"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>Model Prediction</th>\n",
       "      <th>Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>349950.0</td>\n",
       "      <td>516705.375000</td>\n",
       "      <td>-166755.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>450000.0</td>\n",
       "      <td>602669.687500</td>\n",
       "      <td>-152669.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>635000.0</td>\n",
       "      <td>486389.000000</td>\n",
       "      <td>148611.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>355500.0</td>\n",
       "      <td>314836.906250</td>\n",
       "      <td>40663.093750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>246950.0</td>\n",
       "      <td>237527.390625</td>\n",
       "      <td>9422.609375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      price  Model Prediction          Error\n",
       "0  349950.0     516705.375000 -166755.375000\n",
       "1  450000.0     602669.687500 -152669.687500\n",
       "2  635000.0     486389.000000  148611.000000\n",
       "3  355500.0     314836.906250   40663.093750\n",
       "4  246950.0     237527.390625    9422.609375"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction\n",
    "test_predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate error\n",
    "pred_df = pd.DataFrame(y_test)\n",
    "pred_df['Model Prediction'] =pd.Series(test_predictions.reshape(len(test_predictions),))\n",
    "pred_df['Error'] = pred_df['price'] - pred_df['Model Prediction']\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Saving and Restoring**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rmfeUJa5dF5f",
    "outputId": "4be48a96-245d-4458-c228-e63d5bc82677"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[516705.38],\n",
       "       [602669.7 ],\n",
       "       [486389.  ]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"kc_house.h5\")\n",
    "model = keras.models.load_model(\"kc_house.h5\")\n",
    "model.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gjsuBbExfmqF",
    "outputId": "652c74b0-fbab-4d87-e286-7f9d80697917"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23426961970>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights(\"kc_house_weights.ckpt\")\n",
    "model.load_weights(\"kc_house_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**5. Tuning Model**</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**Early Stopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 255936839680.0000 - val_loss: 101041479680.0000\n",
      "Epoch 2/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 83153207296.0000 - val_loss: 87529750528.0000\n",
      "Epoch 3/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 69744869376.0000 - val_loss: 72163246080.0000\n",
      "Epoch 4/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 57396125696.0000 - val_loss: 60994945024.0000\n",
      "Epoch 5/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 50507022336.0000 - val_loss: 55292928000.0000\n",
      "Epoch 6/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 46909988864.0000 - val_loss: 51911929856.0000\n",
      "Epoch 7/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 44155572224.0000 - val_loss: 49493254144.0000\n",
      "Epoch 8/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 42204516352.0000 - val_loss: 46915829760.0000\n",
      "Epoch 9/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 40786620416.0000 - val_loss: 45044977664.0000\n",
      "Epoch 10/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 39622098944.0000 - val_loss: 43657146368.0000\n",
      "Epoch 11/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 38397050880.0000 - val_loss: 42156249088.0000\n",
      "Epoch 12/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 37424779264.0000 - val_loss: 40868327424.0000\n",
      "Epoch 13/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 36634361856.0000 - val_loss: 39794249728.0000\n",
      "Epoch 14/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 35908804608.0000 - val_loss: 39530692608.0000\n",
      "Epoch 15/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 35643518976.0000 - val_loss: 38487797760.0000\n",
      "Epoch 16/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 35308236800.0000 - val_loss: 37977432064.0000\n",
      "Epoch 17/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 34967404544.0000 - val_loss: 37272821760.0000\n",
      "Epoch 18/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 34499903488.0000 - val_loss: 36857864192.0000\n",
      "Epoch 19/100\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 34257448960.0000 - val_loss: 36472664064.0000\n",
      "Epoch 20/100\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 34041225216.0000 - val_loss: 36296523776.0000\n",
      "Epoch 21/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 33863219200.0000 - val_loss: 35695185920.0000\n",
      "Epoch 22/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 33748602880.0000 - val_loss: 35438854144.0000\n",
      "Epoch 23/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 33490270208.0000 - val_loss: 35259183104.0000\n",
      "Epoch 24/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 33166022656.0000 - val_loss: 35154309120.0000\n",
      "Epoch 25/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 32933672960.0000 - val_loss: 34556530688.0000\n",
      "Epoch 26/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 32982937600.0000 - val_loss: 34535133184.0000\n",
      "Epoch 27/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 32750909440.0000 - val_loss: 34250700800.0000\n",
      "Epoch 28/100\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 32554584064.0000 - val_loss: 34508410880.0000\n",
      "Epoch 29/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 32482486272.0000 - val_loss: 33897732096.0000\n",
      "Epoch 30/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 32291862528.0000 - val_loss: 34231648256.0000\n",
      "Epoch 31/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 32195328000.0000 - val_loss: 34143619072.0000\n",
      "Epoch 32/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 32116869120.0000 - val_loss: 33527572480.0000\n",
      "Epoch 33/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 31853385728.0000 - val_loss: 33255041024.0000\n",
      "Epoch 34/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 31899967488.0000 - val_loss: 33310754816.0000\n",
      "Epoch 35/100\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 31699218432.0000 - val_loss: 32999208960.0000\n",
      "Epoch 36/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 31796948992.0000 - val_loss: 32988426240.0000\n",
      "Epoch 37/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 31449907200.0000 - val_loss: 32855064576.0000\n",
      "Epoch 38/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 31374061568.0000 - val_loss: 32866205696.0000\n",
      "Epoch 39/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 31281707008.0000 - val_loss: 32865988608.0000\n",
      "Epoch 40/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 31157397504.0000 - val_loss: 32533293056.0000\n",
      "Epoch 41/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 31077543936.0000 - val_loss: 32499048448.0000\n",
      "Epoch 42/100\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 30873552896.0000 - val_loss: 32553261056.0000\n",
      "Epoch 43/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 30792404992.0000 - val_loss: 32327991296.0000\n",
      "Epoch 44/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 30678124544.0000 - val_loss: 32332957696.0000\n",
      "Epoch 45/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 30629093376.0000 - val_loss: 32144650240.0000\n",
      "Epoch 46/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 30510653440.0000 - val_loss: 31977922560.0000\n",
      "Epoch 47/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 30350600192.0000 - val_loss: 31908468736.0000\n",
      "Epoch 48/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 30282582016.0000 - val_loss: 31831009280.0000\n",
      "Epoch 49/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 30255353856.0000 - val_loss: 31736725504.0000\n",
      "Epoch 50/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 30061133824.0000 - val_loss: 31901366272.0000\n",
      "Epoch 51/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29990031360.0000 - val_loss: 32071266304.0000\n",
      "Epoch 52/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 30108936192.0000 - val_loss: 31555979264.0000\n",
      "Epoch 53/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29849104384.0000 - val_loss: 31850909696.0000\n",
      "Epoch 54/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 29758822400.0000 - val_loss: 31825080320.0000\n",
      "Epoch 55/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29587689472.0000 - val_loss: 31476979712.0000\n",
      "Epoch 56/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29472444416.0000 - val_loss: 31525337088.0000\n",
      "Epoch 57/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29347543040.0000 - val_loss: 31377776640.0000\n",
      "Epoch 58/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29269141504.0000 - val_loss: 32004270080.0000\n",
      "Epoch 59/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29350131712.0000 - val_loss: 31258843136.0000\n",
      "Epoch 60/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29159778304.0000 - val_loss: 31204157440.0000\n",
      "Epoch 61/100\n",
      "433/433 [==============================] - 0s 1ms/step - loss: 29000368128.0000 - val_loss: 31534424064.0000\n",
      "Epoch 62/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 28986839040.0000 - val_loss: 31072931840.0000\n",
      "Epoch 63/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 29009604608.0000 - val_loss: 31306729472.0000\n",
      "Epoch 64/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 28814055424.0000 - val_loss: 30997471232.0000\n",
      "Epoch 65/100\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 28730931200.0000 - val_loss: 31098210304.0000\n",
      "Epoch 66/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 28498565120.0000 - val_loss: 31306012672.0000\n",
      "Epoch 67/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 28536705024.0000 - val_loss: 30842269696.0000\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433/433 [==============================] - 1s 2ms/step - loss: 28474619904.0000 - val_loss: 30839848960.0000\n",
      "Epoch 69/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 28180043776.0000 - val_loss: 30736877568.0000\n",
      "Epoch 70/100\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 28331008000.0000 - val_loss: 30686662656.0000\n",
      "Epoch 71/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 28114681856.0000 - val_loss: 30699986944.0000\n",
      "Epoch 72/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 28100009984.0000 - val_loss: 30782525440.0000\n",
      "Epoch 73/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 28005857280.0000 - val_loss: 31439587328.0000\n",
      "Epoch 74/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27957456896.0000 - val_loss: 30596063232.0000\n",
      "Epoch 75/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27845703680.0000 - val_loss: 30514520064.0000\n",
      "Epoch 76/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27786936320.0000 - val_loss: 30512373760.0000\n",
      "Epoch 77/100\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 27621330944.0000 - val_loss: 30511224832.0000\n",
      "Epoch 78/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27585980416.0000 - val_loss: 30559619072.0000\n",
      "Epoch 79/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27524927488.0000 - val_loss: 30761740288.0000\n",
      "Epoch 80/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27464679424.0000 - val_loss: 30472841216.0000\n",
      "Epoch 81/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27313324032.0000 - val_loss: 30643300352.0000\n",
      "Epoch 82/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27442489344.0000 - val_loss: 30618646528.0000\n",
      "Epoch 83/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27293304832.0000 - val_loss: 30710376448.0000\n",
      "Epoch 84/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27270696960.0000 - val_loss: 30936639488.0000\n",
      "Epoch 85/100\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 27239161856.0000 - val_loss: 30431459328.0000\n",
      "Epoch 86/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27331790848.0000 - val_loss: 30439618560.0000\n",
      "Epoch 87/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27065278464.0000 - val_loss: 30941771776.0000\n",
      "Epoch 88/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27124369408.0000 - val_loss: 30658539520.0000\n",
      "Epoch 89/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 27019460608.0000 - val_loss: 30447591424.0000\n",
      "Epoch 90/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26960027648.0000 - val_loss: 30625454080.0000\n",
      "Epoch 91/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26930145280.0000 - val_loss: 30054748160.0000\n",
      "Epoch 92/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26901692416.0000 - val_loss: 30275919872.0000\n",
      "Epoch 93/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26720131072.0000 - val_loss: 30459717632.0000\n",
      "Epoch 94/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26735282176.0000 - val_loss: 30728730624.0000\n",
      "Epoch 95/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26901428224.0000 - val_loss: 30615291904.0000\n",
      "Epoch 96/100\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 26786457600.0000 - val_loss: 30174994432.0000\n",
      "Epoch 97/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26624911360.0000 - val_loss: 30075330560.0000\n",
      "Epoch 98/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26661949440.0000 - val_loss: 30554056704.0000\n",
      "Epoch 99/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26660354048.0000 - val_loss: 30396684288.0000\n",
      "Epoch 100/100\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 26638104576.0000 - val_loss: 30382649344.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2342a28a160>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(99)\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "def build_model(n_hidden=5, n_neurons=30, learning_rate=3e-3, input_shape=X_train.shape[1:], optimizer='adam'):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "keras_reg.fit(X_train, y_train, epochs=100,\n",
    "             validation_data=(X_valid, y_valid),\n",
    "             callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 25510371328.0000\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-26241673216.0 -25510371328.0\n",
      "RMSE: 159719.654\n",
      "MSE: 25510367930.333\n",
      "MAE: 99520.227\n",
      "r2: 0.813\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "\n",
    "model = keras_reg\n",
    "# Train score, test score\n",
    "training_score = keras_reg.score(X_train, y_train, verbose=0)\n",
    "test_score = keras_reg.score(X_test, y_test, verbose=0)\n",
    "test_predictions = keras_reg.predict(X_test)\n",
    "print(training_score, test_score)\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, test_predictions)\n",
    "print(\"MAE: %.3f\"  % mae)\n",
    "      \n",
    "# r2 - coefficient of determination\n",
    "r2 = explained_variance_score(y_test, test_predictions)\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### <font color=blue>**RandomizedSearchCV**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] n_neurons=26, n_hidden=5, learning_rate=0.013792597135557657 ....\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 2ms/step - loss: 358467010560.0000 - val_loss: 111002378240.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 93520551936.0000 - val_loss: 101588353024.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 86279864320.0000 - val_loss: 93012893696.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 78372380672.0000 - val_loss: 84889362432.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 69882347520.0000 - val_loss: 74908917760.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 61041364992.0000 - val_loss: 65543675904.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 54387654656.0000 - val_loss: 59407351808.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 50943201280.0000 - val_loss: 56268017664.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 48787640320.0000 - val_loss: 54274531328.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 47109812224.0000 - val_loss: 52490063872.0000\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 45394481152.0000\n",
      "[CV]  n_neurons=26, n_hidden=5, learning_rate=0.013792597135557657, total=   7.8s\n",
      "[CV] n_neurons=26, n_hidden=5, learning_rate=0.013792597135557657 ....\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 2ms/step - loss: 398260076544.0000 - val_loss: 220672802816.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 101976014848.0000 - val_loss: 102462570496.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87250501632.0000 - val_loss: 95656312832.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 80605052928.0000 - val_loss: 88304549888.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 73400532992.0000 - val_loss: 80435396608.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 66153967616.0000 - val_loss: 72306180096.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 59318681600.0000 - val_loss: 65755217920.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 54175555584.0000 - val_loss: 60780482560.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 50779607040.0000 - val_loss: 57533181952.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 48486543360.0000 - val_loss: 54999080960.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 48917151744.0000\n",
      "[CV]  n_neurons=26, n_hidden=5, learning_rate=0.013792597135557657, total=   7.6s\n",
      "[CV] n_neurons=26, n_hidden=5, learning_rate=0.013792597135557657 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 388817715200.0000 - val_loss: 198421954560.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 97676845056.0000 - val_loss: 101286494208.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 86430679040.0000 - val_loss: 94750941184.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 80124166144.0000 - val_loss: 88051081216.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 73248096256.0000 - val_loss: 79288803328.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 64802095104.0000 - val_loss: 70069190656.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 57488068608.0000 - val_loss: 63105028096.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 53048881152.0000 - val_loss: 58892374016.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 50474778624.0000 - val_loss: 56283504640.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 48516476928.0000 - val_loss: 54532235264.0000\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 46951858176.0000\n",
      "[CV]  n_neurons=26, n_hidden=5, learning_rate=0.013792597135557657, total=   8.1s\n",
      "[CV] n_neurons=25, n_hidden=5, learning_rate=0.008968771088278454 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 371604520960.0000 - val_loss: 124872933376.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 92587335680.0000 - val_loss: 100077395968.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 84362854400.0000 - val_loss: 90597564416.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 75575427072.0000 - val_loss: 81610694656.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 66741899264.0000 - val_loss: 71796785152.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 59079806976.0000 - val_loss: 64496377856.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 53932912640.0000 - val_loss: 59325911040.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 50731823104.0000 - val_loss: 56143114240.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 48443985920.0000 - val_loss: 53902356480.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 46545170432.0000 - val_loss: 51797016576.0000\n",
      "145/145 [==============================] - 0s 961us/step - loss: 44694409216.0000\n",
      "[CV]  n_neurons=25, n_hidden=5, learning_rate=0.008968771088278454, total=   7.2s\n",
      "[CV] n_neurons=25, n_hidden=5, learning_rate=0.008968771088278454 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 401662541824.0000 - val_loss: 235373543424.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 103945920512.0000 - val_loss: 102614097920.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87502045184.0000 - val_loss: 95957508096.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 80952426496.0000 - val_loss: 88645402624.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 73711853568.0000 - val_loss: 80681533440.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 66290733056.0000 - val_loss: 72313077760.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 59218264064.0000 - val_loss: 65548099584.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 53981274112.0000 - val_loss: 60573589504.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 50628931584.0000 - val_loss: 57407619072.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 48450752512.0000 - val_loss: 55048253440.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 48981704704.0000\n",
      "[CV]  n_neurons=25, n_hidden=5, learning_rate=0.008968771088278454, total=   7.8s\n",
      "[CV] n_neurons=25, n_hidden=5, learning_rate=0.008968771088278454 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 401044144128.0000 - val_loss: 269445529600.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 109453320192.0000 - val_loss: 103873257472.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 88889950208.0000 - val_loss: 97266343936.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 82046164992.0000 - val_loss: 89638985728.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 74143793152.0000 - val_loss: 80017014784.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 65334349824.0000 - val_loss: 70855049216.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 57925357568.0000 - val_loss: 63645810688.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 53172363264.0000 - val_loss: 59095535616.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 50475606016.0000 - val_loss: 56432857088.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 48688525312.0000 - val_loss: 54957686784.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 47337062400.0000\n",
      "[CV]  n_neurons=25, n_hidden=5, learning_rate=0.008968771088278454, total=   7.9s\n",
      "[CV] n_neurons=27, n_hidden=5, learning_rate=0.0009765770523923107 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 413325000704.0000 - val_loss: 329260924928.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 123718049792.0000 - val_loss: 103689519104.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 89245106176.0000 - val_loss: 97278869504.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 83452133376.0000 - val_loss: 91395457024.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 77413662720.0000 - val_loss: 84379664384.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 70884163584.0000 - val_loss: 77297205248.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 64365342720.0000 - val_loss: 69937233920.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 58647330816.0000 - val_loss: 64231272448.0000\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 2ms/step - loss: 54529941504.0000 - val_loss: 60600954880.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 51876847616.0000 - val_loss: 57927974912.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 50160779264.0000\n",
      "[CV]  n_neurons=27, n_hidden=5, learning_rate=0.0009765770523923107, total=   6.9s\n",
      "[CV] n_neurons=27, n_hidden=5, learning_rate=0.0009765770523923107 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 385238368256.0000 - val_loss: 152743280640.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 94069489664.0000 - val_loss: 100632363008.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 85094121472.0000 - val_loss: 92986908672.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 77534838784.0000 - val_loss: 84495360000.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 69223686144.0000 - val_loss: 75371683840.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 61153910784.0000 - val_loss: 66682658816.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 54670520320.0000 - val_loss: 61158404096.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 50728628224.0000 - val_loss: 57393283072.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 48141672448.0000 - val_loss: 54847393792.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 46284025856.0000 - val_loss: 52749541376.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 47076364288.0000\n",
      "[CV]  n_neurons=27, n_hidden=5, learning_rate=0.0009765770523923107, total=   6.9s\n",
      "[CV] n_neurons=27, n_hidden=5, learning_rate=0.0009765770523923107 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 400461266944.0000 - val_loss: 265588146176.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 108351332352.0000 - val_loss: 103332388864.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 88578424832.0000 - val_loss: 97183268864.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 82649579520.0000 - val_loss: 90897965056.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 76260835328.0000 - val_loss: 83079094272.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 68989902848.0000 - val_loss: 75330084864.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 62130974720.0000 - val_loss: 68033921024.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 56607367168.0000 - val_loss: 62354210816.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 52894138368.0000 - val_loss: 58652545024.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 50465849344.0000 - val_loss: 56519471104.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 48916377600.0000\n",
      "[CV]  n_neurons=27, n_hidden=5, learning_rate=0.0009765770523923107, total=   7.4s\n",
      "[CV] n_neurons=25, n_hidden=3, learning_rate=0.0017186579953863928 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 424517140480.0000 - val_loss: 427965480960.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 392889532416.0000 - val_loss: 348645195776.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 247115235328.0000 - val_loss: 163994288128.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 111830376448.0000 - val_loss: 106777182208.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 94017527808.0000 - val_loss: 104281645056.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 92101173248.0000 - val_loss: 102366904320.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 90282016768.0000 - val_loss: 100436606976.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 88423817216.0000 - val_loss: 98440806400.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 86466838528.0000 - val_loss: 96398614528.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 84457709568.0000 - val_loss: 94164000768.0000\n",
      "145/145 [==============================] - 0s 918us/step - loss: 81840644096.0000\n",
      "[CV]  n_neurons=25, n_hidden=3, learning_rate=0.0017186579953863928, total=   6.6s\n",
      "[CV] n_neurons=25, n_hidden=3, learning_rate=0.0017186579953863928 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 428638273536.0000 - val_loss: 429757169664.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 411118338048.0000 - val_loss: 384738885632.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 312965365760.0000 - val_loss: 237383073792.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 158015832064.0000 - val_loss: 119264075776.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 97349427200.0000 - val_loss: 105463832576.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 92402294784.0000 - val_loss: 103690526720.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 90659995648.0000 - val_loss: 101845131264.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 88863776768.0000 - val_loss: 99899228160.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87013457920.0000 - val_loss: 97965129728.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 85103599616.0000 - val_loss: 95893266432.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 85143732224.0000\n",
      "[CV]  n_neurons=25, n_hidden=3, learning_rate=0.0017186579953863928, total=   7.3s\n",
      "[CV] n_neurons=25, n_hidden=3, learning_rate=0.0017186579953863928 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 421424463872.0000 - val_loss: 428615860224.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 394856726528.0000 - val_loss: 360378368000.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 262541197312.0000 - val_loss: 181178613760.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 119601225728.0000 - val_loss: 108745007104.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 93953572864.0000 - val_loss: 104965857280.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 91866415104.0000 - val_loss: 103203389440.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 90196885504.0000 - val_loss: 101279989760.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 88442773504.0000 - val_loss: 99393904640.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 86638379008.0000 - val_loss: 97422147584.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 84827570176.0000 - val_loss: 95420776448.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 84425850880.0000\n",
      "[CV]  n_neurons=25, n_hidden=3, learning_rate=0.0017186579953863928, total=   7.3s\n",
      "[CV] n_neurons=26, n_hidden=3, learning_rate=0.0027625401580359888 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 424363982848.0000 - val_loss: 427299241984.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 391484637184.0000 - val_loss: 347287781376.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 247519444992.0000 - val_loss: 166186401792.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 113643249664.0000 - val_loss: 107709947904.0000\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 2ms/step - loss: 94782881792.0000 - val_loss: 105096519680.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 92901269504.0000 - val_loss: 103269933056.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 91168030720.0000 - val_loss: 101436252160.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 89404350464.0000 - val_loss: 99547512832.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87553179648.0000 - val_loss: 97622671360.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 85661556736.0000 - val_loss: 95523528704.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 83086491648.0000\n",
      "[CV]  n_neurons=26, n_hidden=3, learning_rate=0.0027625401580359888, total=   7.0s\n",
      "[CV] n_neurons=26, n_hidden=3, learning_rate=0.0027625401580359888 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 428402606080.0000 - val_loss: 428368887808.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 401222795264.0000 - val_loss: 360672428032.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 269413679104.0000 - val_loss: 184688099328.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 122920108032.0000 - val_loss: 108552110080.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 94031880192.0000 - val_loss: 104924168192.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 91898314752.0000 - val_loss: 103188668416.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 90161799168.0000 - val_loss: 101339611136.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 88381677568.0000 - val_loss: 99403603968.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 86561046528.0000 - val_loss: 97500405760.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 84697063424.0000 - val_loss: 95469076480.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 84765687808.0000\n",
      "[CV]  n_neurons=26, n_hidden=3, learning_rate=0.0027625401580359888, total=   7.4s\n",
      "[CV] n_neurons=26, n_hidden=3, learning_rate=0.0027625401580359888 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 421298110464.0000 - val_loss: 428109824000.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 394260971520.0000 - val_loss: 360828829696.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 266103046144.0000 - val_loss: 186895843328.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 123162001408.0000 - val_loss: 109921959936.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 94599176192.0000 - val_loss: 105525952512.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 92403998720.0000 - val_loss: 103792852992.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 90765664256.0000 - val_loss: 101907906560.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 89045590016.0000 - val_loss: 100060905472.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87277756416.0000 - val_loss: 98131402752.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 85504868352.0000 - val_loss: 96173203456.0000\n",
      "145/145 [==============================] - 0s 957us/step - loss: 85170405376.0000\n",
      "[CV]  n_neurons=26, n_hidden=3, learning_rate=0.0027625401580359888, total=   7.1s\n",
      "[CV] n_neurons=28, n_hidden=4, learning_rate=0.02209900403553094 .....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 417305886720.0000 - val_loss: 377328599040.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 171605016576.0000 - val_loss: 106146201600.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 92346998784.0000 - val_loss: 101117173760.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87685185536.0000 - val_loss: 96268050432.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 82958131200.0000 - val_loss: 91086921728.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 78041456640.0000 - val_loss: 85797666816.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 72985354240.0000 - val_loss: 80078454784.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 67845545984.0000 - val_loss: 74487595008.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 62861979648.0000 - val_loss: 69455888384.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 58519003136.0000 - val_loss: 64893026304.0000\n",
      "145/145 [==============================] - 0s 976us/step - loss: 55736451072.0000\n",
      "[CV]  n_neurons=28, n_hidden=4, learning_rate=0.02209900403553094, total=   7.7s\n",
      "[CV] n_neurons=28, n_hidden=4, learning_rate=0.02209900403553094 .....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 419013787648.0000 - val_loss: 366864728064.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 165871665152.0000 - val_loss: 105309757440.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 90770284544.0000 - val_loss: 100206641152.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 85718679552.0000 - val_loss: 94664450048.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 80140312576.0000 - val_loss: 88623071232.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 74289864704.0000 - val_loss: 81988796416.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 68081889280.0000 - val_loss: 75494039552.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 62213767168.0000 - val_loss: 69348851712.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 57364652032.0000 - val_loss: 64569176064.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 53809143808.0000 - val_loss: 60896657408.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 53753872384.0000\n",
      "[CV]  n_neurons=28, n_hidden=4, learning_rate=0.02209900403553094, total=   7.6s\n",
      "[CV] n_neurons=28, n_hidden=4, learning_rate=0.02209900403553094 .....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 416096944128.0000 - val_loss: 393257484288.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 207116369920.0000 - val_loss: 107123892224.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 92961062912.0000 - val_loss: 103257088000.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 89502597120.0000 - val_loss: 99683581952.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 85999992832.0000 - val_loss: 95650283520.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 82126618624.0000 - val_loss: 91684020224.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 78302838784.0000 - val_loss: 87243415552.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 74225950720.0000 - val_loss: 82580652032.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 69945057280.0000 - val_loss: 77747970048.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 65760841728.0000 - val_loss: 73142779904.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 63396319232.0000\n",
      "[CV]  n_neurons=28, n_hidden=4, learning_rate=0.02209900403553094, total=   7.9s\n",
      "[CV] n_neurons=29, n_hidden=4, learning_rate=0.005322072406114402 ....\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 2ms/step - loss: 420595269632.0000 - val_loss: 398079852544.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 198268944384.0000 - val_loss: 105546899456.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 91984977920.0000 - val_loss: 101039742976.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87791009792.0000 - val_loss: 96679428096.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 83547299840.0000 - val_loss: 92026011648.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 79100239872.0000 - val_loss: 87213441024.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 74448666624.0000 - val_loss: 81914527744.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 69601402880.0000 - val_loss: 76577595392.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 64733822976.0000 - val_loss: 71586422784.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 60284456960.0000 - val_loss: 66744791040.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 57316950016.0000\n",
      "[CV]  n_neurons=29, n_hidden=4, learning_rate=0.005322072406114402, total=   6.4s\n",
      "[CV] n_neurons=29, n_hidden=4, learning_rate=0.005322072406114402 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 421474467840.0000 - val_loss: 381358604288.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 182899490816.0000 - val_loss: 105701818368.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 91508031488.0000 - val_loss: 101533663232.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87537614848.0000 - val_loss: 97312522240.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 83358048256.0000 - val_loss: 92884041728.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 79113895936.0000 - val_loss: 88124506112.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 74555400192.0000 - val_loss: 83288678400.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 69834113024.0000 - val_loss: 78058143744.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 65128210432.0000 - val_loss: 73002754048.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 60727140352.0000 - val_loss: 68178972672.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 60016058368.0000\n",
      "[CV]  n_neurons=29, n_hidden=4, learning_rate=0.005322072406114402, total=   7.1s\n",
      "[CV] n_neurons=29, n_hidden=4, learning_rate=0.005322072406114402 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 413375397888.0000 - val_loss: 372703625216.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 169559769088.0000 - val_loss: 104696094720.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 90523443200.0000 - val_loss: 100267859968.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 86244327424.0000 - val_loss: 95696674816.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 81714470912.0000 - val_loss: 90390814720.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 76660998144.0000 - val_loss: 85110005760.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 71653638144.0000 - val_loss: 79391408128.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 66561949696.0000 - val_loss: 73665355776.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 61719924736.0000 - val_loss: 68406546432.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 57706897408.0000 - val_loss: 64356401152.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 55503818752.0000\n",
      "[CV]  n_neurons=29, n_hidden=4, learning_rate=0.005322072406114402, total=   8.0s\n",
      "[CV] n_neurons=28, n_hidden=5, learning_rate=0.0006072369137415534 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 396149522432.0000 - val_loss: 218505609216.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 100594622464.0000 - val_loss: 102115794944.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 86817234944.0000 - val_loss: 93797588992.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 78854324224.0000 - val_loss: 85362008064.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 70173646848.0000 - val_loss: 75444322304.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 61792206848.0000 - val_loss: 67161825280.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 55780978688.0000 - val_loss: 61339807744.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 52337094656.0000 - val_loss: 58149269504.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 50193391616.0000 - val_loss: 56154628096.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 48522301440.0000 - val_loss: 54310637568.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 46847234048.0000\n",
      "[CV]  n_neurons=28, n_hidden=5, learning_rate=0.0006072369137415534, total=   7.3s\n",
      "[CV] n_neurons=28, n_hidden=5, learning_rate=0.0006072369137415534 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 407376003072.0000 - val_loss: 270700150784.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 110077632512.0000 - val_loss: 102827745280.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87608115200.0000 - val_loss: 96356802560.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 81243750400.0000 - val_loss: 89236447232.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 73821937664.0000 - val_loss: 80596598784.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 65660080128.0000 - val_loss: 71442702336.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 58194489344.0000 - val_loss: 64632033280.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 53149237248.0000 - val_loss: 59895513088.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 50033295360.0000 - val_loss: 56958603264.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 47966511104.0000 - val_loss: 54665396224.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 48594292736.0000\n",
      "[CV]  n_neurons=28, n_hidden=5, learning_rate=0.0006072369137415534, total=   7.8s\n",
      "[CV] n_neurons=28, n_hidden=5, learning_rate=0.0006072369137415534 ...\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 375877861376.0000 - val_loss: 141064093696.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 93712867328.0000 - val_loss: 101069586432.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 85949833216.0000 - val_loss: 93861568512.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 78956511232.0000 - val_loss: 86378536960.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 71323721728.0000 - val_loss: 76966010880.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 63033286656.0000 - val_loss: 68489248768.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 56554254336.0000 - val_loss: 62397808640.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 52518588416.0000 - val_loss: 58329853952.0000\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 2ms/step - loss: 49958920192.0000 - val_loss: 55668699136.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 47983833088.0000 - val_loss: 53964357632.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 46577610752.0000\n",
      "[CV]  n_neurons=28, n_hidden=5, learning_rate=0.0006072369137415534, total=   7.3s\n",
      "[CV] n_neurons=26, n_hidden=3, learning_rate=0.001185833199732416 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 424653291520.0000 - val_loss: 428931219456.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 402467553280.0000 - val_loss: 373634236416.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 292020092928.0000 - val_loss: 216339922944.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 142378336256.0000 - val_loss: 114838519808.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 97300152320.0000 - val_loss: 106218094592.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 94006837248.0000 - val_loss: 104489361408.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 92418465792.0000 - val_loss: 102827917312.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 90819108864.0000 - val_loss: 101118820352.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 89144991744.0000 - val_loss: 99375775744.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87436042240.0000 - val_loss: 97491697664.0000\n",
      "145/145 [==============================] - 0s 761us/step - loss: 84937916416.0000\n",
      "[CV]  n_neurons=26, n_hidden=3, learning_rate=0.001185833199732416, total=   7.6s\n",
      "[CV] n_neurons=26, n_hidden=3, learning_rate=0.001185833199732416 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 428245909504.0000 - val_loss: 427840962560.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 401061740544.0000 - val_loss: 362457989120.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 275977175040.0000 - val_loss: 194310520832.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 129167818752.0000 - val_loss: 110238883840.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 94787780608.0000 - val_loss: 105372893184.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 92392488960.0000 - val_loss: 103706853376.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 90724368384.0000 - val_loss: 101930909696.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 89014517760.0000 - val_loss: 100073684992.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 87266336768.0000 - val_loss: 98249146368.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 85478752256.0000 - val_loss: 96305176576.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 85555445760.0000\n",
      "[CV]  n_neurons=26, n_hidden=3, learning_rate=0.001185833199732416, total=   7.4s\n",
      "[CV] n_neurons=26, n_hidden=3, learning_rate=0.001185833199732416 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 421253840896.0000 - val_loss: 427690950656.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 0s 2ms/step - loss: 389563678720.0000 - val_loss: 348317024256.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 245425127424.0000 - val_loss: 164601380864.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 111814344704.0000 - val_loss: 107482513408.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 93469499392.0000 - val_loss: 104655028224.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 91502125056.0000 - val_loss: 102818308096.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 89757163520.0000 - val_loss: 100803280896.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 87921631232.0000 - val_loss: 98825535488.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 86028640256.0000 - val_loss: 96753172480.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 84124106752.0000 - val_loss: 94644797440.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 83668344832.0000\n",
      "[CV]  n_neurons=26, n_hidden=3, learning_rate=0.001185833199732416, total=   7.3s\n",
      "[CV] n_neurons=25, n_hidden=4, learning_rate=0.003002342934630235 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 420944314368.0000 - val_loss: 402609176576.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 217400983552.0000 - val_loss: 107067367424.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 93740163072.0000 - val_loss: 103053819904.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 89932685312.0000 - val_loss: 99088900096.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 86094217216.0000 - val_loss: 94933106688.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 82104934400.0000 - val_loss: 90635214848.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 77924843520.0000 - val_loss: 85896708096.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 73499344896.0000 - val_loss: 80996442112.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 68844388352.0000 - val_loss: 76124086272.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 64257585152.0000 - val_loss: 71065411584.0000\n",
      "145/145 [==============================] - 0s 977us/step - loss: 60997836800.0000\n",
      "[CV]  n_neurons=25, n_hidden=4, learning_rate=0.003002342934630235, total=   8.0s\n",
      "[CV] n_neurons=25, n_hidden=4, learning_rate=0.003002342934630235 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 425012461568.0000 - val_loss: 404614610944.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 230022152192.0000 - val_loss: 107649409024.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 93185916928.0000 - val_loss: 103450869760.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 89621061632.0000 - val_loss: 99743195136.0000\n",
      "Epoch 5/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 85949792256.0000 - val_loss: 95893422080.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 82261745664.0000 - val_loss: 91809865728.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 78314176512.0000 - val_loss: 87631724544.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 74191699968.0000 - val_loss: 83048603648.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 69956730880.0000 - val_loss: 78456299520.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 65739862016.0000 - val_loss: 73743597568.0000\n",
      "145/145 [==============================] - 0s 2ms/step - loss: 64912797696.0000\n",
      "[CV]  n_neurons=25, n_hidden=4, learning_rate=0.003002342934630235, total=   8.0s\n",
      "[CV] n_neurons=25, n_hidden=4, learning_rate=0.003002342934630235 ....\n",
      "Epoch 1/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 418081046528.0000 - val_loss: 404108574720.0000\n",
      "Epoch 2/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 224343687168.0000 - val_loss: 107479089152.0000\n",
      "Epoch 3/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 92938387456.0000 - val_loss: 103296393216.0000\n",
      "Epoch 4/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 89514835968.0000 - val_loss: 99808714752.0000\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289/289 [==============================] - 1s 2ms/step - loss: 86102147072.0000 - val_loss: 95891423232.0000\n",
      "Epoch 6/10\n",
      "289/289 [==============================] - 1s 3ms/step - loss: 82337472512.0000 - val_loss: 92053602304.0000\n",
      "Epoch 7/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 78636236800.0000 - val_loss: 87755046912.0000\n",
      "Epoch 8/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 74694107136.0000 - val_loss: 83260432384.0000\n",
      "Epoch 9/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 70550028288.0000 - val_loss: 78584356864.0000\n",
      "Epoch 10/10\n",
      "289/289 [==============================] - 1s 2ms/step - loss: 66482302976.0000 - val_loss: 74100285440.0000\n",
      "145/145 [==============================] - 0s 1ms/step - loss: 64250609664.0000\n",
      "[CV]  n_neurons=25, n_hidden=4, learning_rate=0.003002342934630235, total=   7.2s\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433/433 [==============================] - 2s 2ms/step - loss: 286214815744.0000 - val_loss: 105473204224.0000\n",
      "Epoch 2/10\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 88276123648.0000 - val_loss: 93647847424.0000\n",
      "Epoch 3/10\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 76114763776.0000 - val_loss: 79377416192.0000\n",
      "Epoch 4/10\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 62954237952.0000 - val_loss: 65849458688.0000\n",
      "Epoch 5/10\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 53587509248.0000 - val_loss: 58300977152.0000\n",
      "Epoch 6/10\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 49528315904.0000 - val_loss: 55113732096.0000\n",
      "Epoch 7/10\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 47066644480.0000 - val_loss: 53110923264.0000\n",
      "Epoch 8/10\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 45262000128.0000 - val_loss: 50732785664.0000\n",
      "Epoch 9/10\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 43696312320.0000 - val_loss: 48796938240.0000\n",
      "Epoch 10/10\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 42171408384.0000 - val_loss: 47016488960.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000023430E4CE80>,\n",
       "                   param_distributions={'learning_rate': [0.006632517002633693,\n",
       "                                                          0.002839736562766998,\n",
       "                                                          0.01343110062400909,\n",
       "                                                          0.00034674805203849273,\n",
       "                                                          0.01239427652823042,\n",
       "                                                          0.004058411630862063,\n",
       "                                                          0.0011813164513855326,\n",
       "                                                          0.00037197409492428747,\n",
       "                                                          0.028732674546994283,\n",
       "                                                          0.0003095798751...\n",
       "                                                          0.026609324415177625,\n",
       "                                                          0.0033569949309863725,\n",
       "                                                          0.00046168678237205657,\n",
       "                                                          0.012698080625995697,\n",
       "                                                          0.0007952337912132701,\n",
       "                                                          0.0038531225657069514,\n",
       "                                                          0.0011525492345672978,\n",
       "                                                          0.012864886964429521,\n",
       "                                                          0.013589591030537787,\n",
       "                                                          0.0008322925327068152,\n",
       "                                                          0.005845082669132452,\n",
       "                                                          0.000465033777269494,\n",
       "                                                          0.001997320375303963,\n",
       "                                                          0.00046865340554593345, ...],\n",
       "                                        'n_hidden': [3, 4, 5],\n",
       "                                        'n_neurons': [25, 26, 27, 28, 29]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(99)\n",
    "tf.random.set_seed(99)\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [3,4,5],\n",
    "    \"n_neurons\": np.arange(25,30).tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2).rvs(1000).tolist(),\n",
    "}\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=10,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433/433 [==============================] - 1s 1ms/step - loss: 41056059392.0000\n",
      "136/136 [==============================] - 0s 2ms/step - loss: 40819191808.0000\n",
      "-41056059392.0 -40819191808.0\n",
      "RMSE: 202037.602\n",
      "MSE: 40819192454.242\n",
      "MAE: 119948.173\n",
      "r2: 0.701\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "\n",
    "model = rnd_search_cv\n",
    "# Train score, test score\n",
    "training_score = model.score(X_train, y_train)\n",
    "test_score = model.score(X_test, y_test)\n",
    "test_predictions = model.predict(X_test)\n",
    "print(training_score, test_score)\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, test_predictions)\n",
    "print(\"MAE: %.3f\"  % mae)\n",
    "      \n",
    "# r2 - coefficient of determination\n",
    "r2 = explained_variance_score(y_test, test_predictions)\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28283637760.0 27232856064.0\n",
      "RMSE: 165023.803\n",
      "MSE: 27232855538.651\n",
      "MAE: 101594.192\n",
      "r2: 0.800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, explained_variance_score\n",
    "\n",
    "model = keras.models.load_model('kc_house.h5')  # roll back to the best model\n",
    "# Train score, test score\n",
    "training_score = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_score = model.evaluate(X_test, y_test, verbose=0)\n",
    "test_predictions = model.predict(X_test)\n",
    "print(training_score, test_score)\n",
    "\n",
    "# Root Mean Square Error\n",
    "rmse = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "print(\"RMSE: %.3f\" % rmse)\n",
    "\n",
    "# Mean Square Error\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "print(\"MSE: %.3f\" % mse)\n",
    "\n",
    "# Mean Absolute Error\n",
    "mae = mean_absolute_error(y_test, test_predictions)\n",
    "print(\"MAE: %.3f\"  % mae)\n",
    "      \n",
    "# r2 - coefficient of determination\n",
    "r2 = explained_variance_score(y_test, test_predictions)\n",
    "print(\"r2: %.3f\" %r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u4ZRgWyxq-iO",
    "outputId": "f05ce743-37a4-4295-b4c1-774aaf0b271f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 34, 'n_hidden': 5, 'learning_rate': 0.001795529118450432}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WcHT7W_zKbaS",
    "outputId": "631692b6-62d5-4444-c553-4b782fd61641"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-44276626773.333336"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6wYZAWg0KbaS",
    "outputId": "c12b7e54-d31e-410f-dbfe-df0d0035945f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.wrappers.scikit_learn.KerasRegressor at 0x2342a3160d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hUovM1pwKbaT",
    "outputId": "a866a3b4-7d01-424d-e1fb-6e06f1cb4249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 41842290688.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-41842290688.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXOvffS0KbaT",
    "outputId": "c4c2229c-d415-4644-e107-bb9ba51f9ead"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x2342e941d90>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = rnd_search_cv.best_estimator_.model\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OlJtmGXEKbaT",
    "outputId": "8a6a5420-97b9-4c90-b4ee-ce042356c043",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 1ms/step - loss: 41842290688.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41842290688.0"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=red>**6. TensorBoard**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2025_04_13-05_48_42'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1509432439605151296207707963392.0000 - val_loss: 747683135647690366746886144.0000\n",
      "Epoch 2/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 356184934692300759272259584.0000 - val_loss: 132058608286836156723625984.0000\n",
      "Epoch 3/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 62910734483804888984715264.0000 - val_loss: 23324683478567835546943488.0000\n",
      "Epoch 4/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 11111517349556932134830080.0000 - val_loss: 4119685701478076660056064.0000\n",
      "Epoch 5/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1962555154839858382372864.0000 - val_loss: 727635927270333425385472.0000\n",
      "Epoch 6/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 346633776695392715407360.0000 - val_loss: 128517295025631329779712.0000\n",
      "Epoch 7/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 61223622184334786560000.0000 - val_loss: 22699175698061781368832.0000\n",
      "Epoch 8/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10813533392584235286528.0000 - val_loss: 4009209096976551903232.0000\n",
      "Epoch 9/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1909922699509787262976.0000 - val_loss: 708121798559739674624.0000\n",
      "Epoch 10/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 337338083885396787200.0000 - val_loss: 125071066140636086272.0000\n",
      "Epoch 11/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 59581809431507107840.0000 - val_loss: 22090580583740604416.0000\n",
      "Epoch 12/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10523568725955706880.0000 - val_loss: 3901726412570099712.0000\n",
      "Epoch 13/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1858707776641957888.0000 - val_loss: 689144751231860736.0000\n",
      "Epoch 14/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 328292594138218496.0000 - val_loss: 121722749012934656.0000\n",
      "Epoch 15/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 57984618296508416.0000 - val_loss: 21500524679397376.0000\n",
      "Epoch 16/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10241653386248192.0000 - val_loss: 3798186682482688.0000\n",
      "Epoch 17/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1809054183718912.0000 - val_loss: 671185813635072.0000\n",
      "Epoch 18/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 319622070927360.0000 - val_loss: 118749931765760.0000\n",
      "Epoch 19/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 56559975530496.0000 - val_loss: 21127365656576.0000\n",
      "Epoch 20/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10094672609280.0000 - val_loss: 3865662455808.0000\n",
      "Epoch 21/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1891601612800.0000 - val_loss: 810380427264.0000\n",
      "Epoch 22/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 442595082240.0000 - val_loss: 265459482624.0000\n",
      "Epoch 23/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 186436878336.0000 - val_loss: 168220344320.0000\n",
      "Epoch 24/30\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 141340475392.0000 - val_loss: 150146826240.0000\n",
      "Epoch 25/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 133258240000.0000 - val_loss: 146675597312.0000\n",
      "Epoch 26/30\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 131833675776.0000 - val_loss: 145922162688.0000\n",
      "Epoch 27/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131585482752.0000 - val_loss: 145770889216.0000\n",
      "Epoch 28/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131550453760.0000 - val_loss: 145734254592.0000\n",
      "Epoch 29/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131543851008.0000 - val_loss: 145714462720.0000\n",
      "Epoch 30/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131540385792.0000 - val_loss: 145704730624.0000\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start the TensorBoard server, one option is to open a terminal, if needed activate the virtualenv where you installed TensorBoard, go to this notebook's directory, then type:\n",
    "\n",
    "```bash\n",
    "$ tensorboard --logdir=./my_logs --port=6006\n",
    "```\n",
    "\n",
    "You can then open your web browser to [localhost:6006](http://localhost:6006) and use TensorBoard. Once you are done, press Ctrl-C in the terminal window, this will shutdown the TensorBoard server.\n",
    "\n",
    "Alternatively, you can load TensorBoard's Jupyter extension and run it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 23820), started 3 days, 23:42:29 ago. (Use '!kill 23820' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-c26990923cd49aa\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-c26990923cd49aa\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2025_04_13-05_49_08'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])    \n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1509432439605151296207707963392.0000 - val_loss: 747683135647690366746886144.0000\n",
      "Epoch 2/30\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 356184934692300759272259584.0000 - val_loss: 132058608286836156723625984.0000\n",
      "Epoch 3/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 62910734483804888984715264.0000 - val_loss: 23324683478567835546943488.0000\n",
      "Epoch 4/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 11111517349556932134830080.0000 - val_loss: 4119685701478076660056064.0000\n",
      "Epoch 5/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1962555154839858382372864.0000 - val_loss: 727635927270333425385472.0000\n",
      "Epoch 6/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 346633776695392715407360.0000 - val_loss: 128517295025631329779712.0000\n",
      "Epoch 7/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 61223622184334786560000.0000 - val_loss: 22699175698061781368832.0000\n",
      "Epoch 8/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10813533392584235286528.0000 - val_loss: 4009209096976551903232.0000\n",
      "Epoch 9/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1909922699509787262976.0000 - val_loss: 708121798559739674624.0000\n",
      "Epoch 10/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 337338083885396787200.0000 - val_loss: 125071066140636086272.0000\n",
      "Epoch 11/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 59581809431507107840.0000 - val_loss: 22090580583740604416.0000\n",
      "Epoch 12/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10523568725955706880.0000 - val_loss: 3901726412570099712.0000\n",
      "Epoch 13/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1858707776641957888.0000 - val_loss: 689144751231860736.0000\n",
      "Epoch 14/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 328292594138218496.0000 - val_loss: 121722749012934656.0000\n",
      "Epoch 15/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 57984618296508416.0000 - val_loss: 21500524679397376.0000\n",
      "Epoch 16/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10241653386248192.0000 - val_loss: 3798186682482688.0000\n",
      "Epoch 17/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1809054183718912.0000 - val_loss: 671185813635072.0000\n",
      "Epoch 18/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 319622070927360.0000 - val_loss: 118749931765760.0000\n",
      "Epoch 19/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 56559975530496.0000 - val_loss: 21127365656576.0000\n",
      "Epoch 20/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 10094672609280.0000 - val_loss: 3865662455808.0000\n",
      "Epoch 21/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 1891601612800.0000 - val_loss: 810380427264.0000\n",
      "Epoch 22/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 442595082240.0000 - val_loss: 265459482624.0000\n",
      "Epoch 23/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 186436878336.0000 - val_loss: 168220344320.0000\n",
      "Epoch 24/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 141340475392.0000 - val_loss: 150146826240.0000\n",
      "Epoch 25/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 133258240000.0000 - val_loss: 146675597312.0000\n",
      "Epoch 26/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131833675776.0000 - val_loss: 145922162688.0000\n",
      "Epoch 27/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131585482752.0000 - val_loss: 145770889216.0000\n",
      "Epoch 28/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131550453760.0000 - val_loss: 145734254592.0000\n",
      "Epoch 29/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131543851008.0000 - val_loss: 145714462720.0000\n",
      "Epoch 30/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131540385792.0000 - val_loss: 145704730624.0000\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539173376.0000 - val_loss: 145696817152.0000\n",
      "Epoch 2/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131540017152.0000 - val_loss: 145691557888.0000\n",
      "Epoch 3/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538165760.0000 - val_loss: 145697030144.0000\n",
      "Epoch 4/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539099648.0000 - val_loss: 145682644992.0000\n",
      "Epoch 5/30\n",
      "433/433 [==============================] - 1s 3ms/step - loss: 131539337216.0000 - val_loss: 145674502144.0000\n",
      "Epoch 6/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538493440.0000 - val_loss: 145680465920.0000\n",
      "Epoch 7/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538509824.0000 - val_loss: 145671634944.0000\n",
      "Epoch 8/30\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 131538509824.0000 - val_loss: 145678843904.0000\n",
      "Epoch 9/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537682432.0000 - val_loss: 145682808832.0000\n",
      "Epoch 10/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538157568.0000 - val_loss: 145686069248.0000\n",
      "Epoch 11/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538067456.0000 - val_loss: 145687035904.0000\n",
      "Epoch 12/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537207296.0000 - val_loss: 145674190848.0000\n",
      "Epoch 13/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539435520.0000 - val_loss: 145686937600.0000\n",
      "Epoch 14/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131536838656.0000 - val_loss: 145698930688.0000\n",
      "Epoch 15/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538960384.0000 - val_loss: 145694588928.0000\n",
      "Epoch 16/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539255296.0000 - val_loss: 145697406976.0000\n",
      "Epoch 17/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539386368.0000 - val_loss: 145692344320.0000\n",
      "Epoch 18/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537690624.0000 - val_loss: 145684758528.0000\n",
      "Epoch 19/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539050496.0000 - val_loss: 145679794176.0000\n",
      "Epoch 20/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539165184.0000 - val_loss: 145678106624.0000\n",
      "Epoch 21/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537985536.0000 - val_loss: 145692065792.0000\n",
      "Epoch 22/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131537788928.0000 - val_loss: 145680695296.0000\n",
      "Epoch 23/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538665472.0000 - val_loss: 145694277632.0000\n",
      "Epoch 24/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538993152.0000 - val_loss: 145688428544.0000\n",
      "Epoch 25/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538747392.0000 - val_loss: 145686151168.0000\n",
      "Epoch 26/30\n",
      "433/433 [==============================] - 1s 1ms/step - loss: 131538698240.0000 - val_loss: 145676484608.0000\n",
      "Epoch 27/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539558400.0000 - val_loss: 145687576576.0000\n",
      "Epoch 28/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131538001920.0000 - val_loss: 145700831232.0000\n",
      "Epoch 29/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539632128.0000 - val_loss: 145701191680.0000\n",
      "Epoch 30/30\n",
      "433/433 [==============================] - 1s 2ms/step - loss: 131539066880.0000 - val_loss: 145699356672.0000\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_valid, y_valid),\n",
    "                    callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how TensorBoard now sees two runs, and you can compare the learning curves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the other available logging options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, write_steps_per_second=False, update_freq='epoch', profile_batch=0, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
